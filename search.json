[{"title":"Mysql事务","url":"/2025/05/05/A1-%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql%E4%BA%8B%E5%8A%A1/","content":"事务四大特性原子性：保障：undo log\n定义：一系列操作要么全执行，要么全不执行；\n原理：通过undo log实现，undo log属于逻辑日志，保证事务原子性，记录 sql执行相关的信息，当发生回滚时，会根据undo log内容做与之前相反的工作。例如：对于每个insert，回滚时会执行delete；对于每个update，回滚时会执行一个相反的update，把数据改回去。\n\n\n持久性保障：redo log\n定义：保证事务提交后不会因为宕机等原因造成数据的丢失； \n背景InnoDB存储引擎的数据存放在磁盘中，如果每次读写数据都需要磁盘IO，效率会很低。因此，InnoDB提供了缓存Buffer Pool，Buffer Pool作为访问磁盘的缓冲区。当从数据库读取数据时，首先从Buffer Pool中读取，如果Buffer Pool中没有，再从磁盘读取后放入Buffer Pool；写入数据时，首先写入Buffer Pool，Buffer Pool中修改的数据会 定期刷新到磁盘（刷脏）。\nBuffer Pool虽然提高了读写数据的效率，但也存在问题：如果Mysql宕机，此时Buffer Pool中修改的数据还没刷新到磁盘，就会导致数据丢失，事务的持久性也就无法保证。\n解决方式数据修改时，先在redo log中记录这次操作，然后修改 Buffer Pool中的数据。当事务提交时，会调用 fsync接口对redo log进行刷盘。如果Mysql宕机，重启时会读取redo log数据进行恢复。redo log是预写日志，所有修改先写入日志，再更新到Buffer Pool，保证数据不会因Mysql宕机而丢失。\nredo log在事务提交时写入磁盘，但比刷脏快，具体原因\n刷脏是随机IO（寻道+旋转+寻址），每次修改的数据位置随机，但写 redo log是追加操作，属于顺序IO；\n刷脏是以数据页（默认16k）为单位，一个数据页Page上一个小修改都要整页写入；而 redo log中只包含真正需要写入的部分，无效IO 减少。\n\n隔离性保障：加锁\n定义：保证事务间的执行互不影响\n两方面考虑：读、写\n加锁： 一个事务写操作，对另一个事务写操作；\nMVCC： 一个事务写操作，对另一个事务读操作；\n一致性保障：数据库层面 + 应用层面\n定义：对于同一份数据的不同操作，要保证一致性；\nredo log与binlog区别1.作用不同redo log保证Mysql宕机也不会影响持久性，保证事务持久性。\nbinlog 保证服务器可以基于时间点恢复数据，binlog还用于主从复制；\nundo log 保证事务原子性、隔离性；\n2.层次不同redo log是 InnoDB存储引擎实现的；\nbinlog 是Mysql 服务器层实现的，同时支持InnoDB和其他存储引擎；\n3.内容不同redo log是物理日志，内容基于磁盘的Page；\nbinlog 是二进制，根据binlog_format参数的不同，可能基于 sql语句，基于数据本身或者二者的混合；\n锁类型行锁1.共享锁（S Lock）可以和其他锁共存，多个事务可以同时访问同一份数据，但只能读，不能修改；\n2.排他锁（X Lock）排他锁和其他锁不能共存，一个事务获取一个数据行的排他锁，其他事务不能再获取该行的 共享锁和排他锁，获取排他锁的事务可以对数据进行读取和修改；\n总结：读时加共享锁，其他事务可以并发读，但不能写；写时加排它锁，其他事务不能并发写，也不能并发读。\n表锁对整个表都加锁，绝大部分情况都使用行锁，便于事务处理，但在个别特殊事务中，也考虑使用表锁，例如：当事务需要更新大部分或全部数据时，表比较大，如果使用默认的行锁，不仅这个事务执行效率低，而且可能造成其他事务长时间锁等待和锁冲突，这种情况下考虑使用表锁来提高该事务的执行速度。\n间隙锁（Gap锁）定义：使用范围条件检索数据，请求共享锁或排他锁时，InnoDB会给符合条件的已有数据的索引项加锁。对于键值在条件范围内但并不存在的记录，叫做 “间隙(GAP)”，InnoDB也会对这个“间隙”加锁，这就是间隙锁（GAP锁）。\nSELECT c1 FROM t  WHERE c1 BETWEEN 10 and 20 FOR UPDATE;\n\n解释：意思是锁住 10~15间的数据，如果id&#x3D;10的数据已存在，别的用户不可以修改这条数据。但如果 id&#x3D;15的数据并不存在，也是不可以插入的，因为无论该列中是否已有这样的值，该范围中id在（10，15），现有值的间隙也是锁定的。\n间隙锁作用：防止幻读，不使用间隙锁，其他事务可以将数据插入到查询区间，本事务再次查询就会发生幻读；Record Lock： 锁定一个记录上的索引，而不是记录本身；\nGap Lock：锁定索引之间的间隙，但不包含索引本身；\nNext-Key Lock： Record Locks + Gap Locks 结合，不仅锁定一个记录上的索引，也锁定索引之间的间隙。\nMVCC多版本并发控制（Multi-Version Concurrency Control）定义：MVCC是InnoDB 存储引擎实现 已提交读、可重复读 隔离级别的一种具体方式；\n实现MVCC在 Undo log日志中存储快照信息，通过日志中的回滚指针把一个数据行（Record）的所有快照连接起来；\n\n\n版本号\n系统版本号：一个递增的数字，每开始一个新的事务，系统版本号就会自动递增；\n事务版本号：事务开始时的系统版本号；\n\n隐藏的列：MVCC 在每行记录后面都保存着 两个隐藏的列，用来存储两个版本号。\n\n创建版本号：指示创建一个数据行的快照时的系统版本号； \n删除版本号：如果该快照的删除版本号 &gt; 当前事务版本号，表示该快照有效，否则表示该快照已经被删除。\n\nMvcc总结A 事务读取数据，记录此时刻的快照 id 值， 放在 ReadView 中保存，每次对数据修改都会改变快照 id 值，此id 值保持递增，当后来再次读取 数据时，会比较此时的数据版本 id 值，是否 &gt; 之前的 id 值，如果 &gt; , 说明已经被修改；\n通 undo log 日志，查询之前记录数据的快照，访问那个版本时的数据。\nRR隔离级别1.已提交读（RC）隔离级别下的非加锁读RC与 RR一样，都使用了 MVCC，其主要区别在于：\nRR 是在事务开始后第一次执行select前创建ReadView，直到事务提交都不会再创建；RR可以避免脏读，不可重复读\nRC 每次执行select前都会重新建立一个新的ReadView，如果事务 A第一次select后，事务B对数据进行修改并提交，那么事务A第二次select 时会重新建立新的ReadView，此时事务 B的修改对事务 A是可见的；所以RC隔离级别可以避免脏读，但是无法避免不可重复读和幻读。\n2.加锁读 与 next-key lock按照是否加锁，Mysql 读可以分为两种： \n1.非加锁读（快照读，一致性读），使用普通 select语句，这种情况下使用 MVCC避免了脏读，不可重复读，幻读，保证了隔离性。\n2.加锁读，在查询时会对查询数据加锁（共享锁或排它锁）；由于锁的特性，当某事务对数据进行加锁读后，其他事务无法对数据进行写操作，因此可以 避免脏读和不可重复读。\n避免幻读需要通过 next-key lock，它是一种行锁，相当于 record lock(记录锁) + gap lock(间隙锁)；其不仅会锁住 记录本身(record lock功能)，还会 锁定一个范围(gap lock功能)；因此，加锁读同样可以避免脏读，不可重复读和幻读，保证隔离性。\n快照读&amp;当前读快照读 读取历史数据； MVCC 的 select 操作是快照中的数据，不需要进行加锁操作。 \n当前读读取数据库当前版本最新数据，MVCC 对数据库进行修改的操作（insert、update、delete）需要进行加锁操作，从而读取最新的数据。\n总结：MVCC使用加锁，但避免了 select 加锁 , Mysql为了减少锁处理的时间，提升并发能力，引入了快照读的概念，使得 select不用加锁。而 update，insert ，delete 这些 “当前读”的隔离性，需要通过加锁来实现。\n事务在执行普通select 操作时，在访问记录版本链的过程中，可以使用不同事务的读-写，写-读操作并发执行，从而提升系统性能。\n事务隔离级别\n\n未提交读定义：总是 读取最新的数据行，没有任何加锁，更新数据就会被读取到，直接返回记录的最新值，脏读、幻读、不可重复读都有可能发生。\n问题：事务可以读取 其他未提交事务的执行结果。\n已提交读RC定义：根据 MVCC实现，事务每次查询开始时，会生成一个独立的 ReadView，在数据库表中看到的一行记录可能有多个版本，每个版本记录除了有数据本身外，还有一个表示版本的字段（row trx_id），在事务开始时，向事务系统申请，按时间先后顺序递增。\n问题：事务可以读取 已经提交事务所做的改变。\n可重复读RR定义：在事务开始时生成一个当前事务全局性的快照，同一事务在 多次读取数据时，可以读取到相同的结果。\n可串行化定义：各个事务间串行执行，对所有读取的数据行都加共享锁，避免并行访问。通过MVCC + Next-Key Lock共同实现，这个级别可能 导致大量的超时现象和锁竞争。\n各隔离级别的问题脏读：不同事务下，当前事务可以读取到另外事务未提交的数据。\n不可重复读：同一事务内多次读取同一数据，读取到的数据可能不一样。\n幻读：一个事务读取某一范围的数据行时，另一个事务在该范围内插入新行，此事务再次读取范围内的数据行时，会返回之前不存在的数据行（新插入的数据行）。\nRC&#x2F;RR区别RC 在每一次进行 普通 select 操作前都会生成一个ReadView。\nRR 只在第一次进行普通 select 操作前生成一个ReadView，数据的可重复读就是 ReadView的重复使用。\n因为 B线程修改数据提交后，A线程第二次 select时，不再进行 id 值的比较，会重建ReadView，使得数据丢失。\n可重复读\nselect 操作不可重复读的问题，通过 MVCC 得到解决；\nupdate，delete不可重复读问题，通过 Record Lock 解决；\ninsert 不可重复读问题，通过 Next-Key Lock解决；\n\n根据 MVCC实现，只会根据事务中第一次查询时生成的 ReadView。\n已提交读\n当前事务内的更新，可以读到；\n版本 未提交，不能读到； \n版本 已提交，但是却在快照创建后提交的不能读到； \n版本 已提交，且在快照创建前提交的可以读到；\n\n已提交读&amp;可重复读区别：在快照的创建上，可重复读仅在事务开始时创建一次，已提交读每次执行语句时都重新创建一次。\n","categories":["Mysql","事务"],"tags":["Mysql"]},{"title":"Mysql底层原理","url":"/2025/05/11/A1-%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/","content":"BufferPool原理原理：对于数据的修改，Mysql不会直接去修改磁盘数据，这样做太慢了，Mysql会先记录 redo log，再改内存BufferPool，等空闲时再刷磁盘，查询时如果内存 BufferPool里没有数据就去磁盘 load；\nMysql以16KB「页」为读取和写入单位，一「页」里有多行数据，写数据时，Mysql会先写内存中的页，然后再刷新到磁盘。\n结构：BufferPool是以页(16kb)为元素的链表结构，基于LRU，和缓存一样，需要淘汰算法来管理数据；\n持久化： 宕机时，BufferPool会丢失数据（在内存中），需要重做 redo log； 执行时先写redo log, 再写BufferPool。\n\n\n\n\nChangeBuffer原理背景：Mysql查询数据时，如果内存里没有对应页的数据，会从磁盘里load；如果每次需要的页都不同（不是相邻的页），那每次都要去 load，效率会降低；\n原理：更新一个数据页时，如果数据页在内存中，就直接更新；但如果这个数据页没在内存中，InooDB会将这些更新操作缓存在 change buffer中，这样就不需要从磁盘读入这个数据页。在下次查询需要访问这个数据页时，再将数据页读入内存，执行change buffer中与这个页有关的操作，通过这种方式就能保证数据逻辑的正确性。\n使用条件：普通索引可以使用 Changebuffer，唯一索引（或主键）更新不能使用 change buffer，因为唯一索引更新操作要先判断这个操作 是否违反唯一性约束，判断表中是否存在这个数据，就必须要将数据页读入内存才能判断，已经读到内存中，直接更新内存会更快，就没必要使用change buffer。\n关系：change buffer 是 buffer pool里的内存，不能无限增大；\n使用场景适合：写多读少业务，在写完后马上被访问到的概率比较小，此时change buffer使用效果最好，业务模型常见：账单类，日志类的系统。\n不适合：读多写少（写入后马上会做查询）将更新先记录在change buffer，但由于马上要访问这个数据页，会立即触发merge操作，访问IO次数不会减少，反而增加 change buffer维护代价。\n优劣：数据库进行 Merge 时，是真正进行 数据更新的时刻，change buffer目的就是将记录的变更动作缓存下来，所以在一个数据页做merge前，change buffer 记录变更数越多（页面要更新的数据越多），收益就越大。\nmerge：ChangeBuffer –&gt; BufferPool\npurge（刷脏）: BufferPool –&gt; disk\n脏页：在更新之前，当内存数据页跟磁盘数据页内容不一致的时候\nFlush &lt;–&gt; purge过程将内存缓冲区BufferPool中的脏页写入磁盘，保障事务持久性\n触发条件：\n缓存池脏页比例超过阈值\n事务提交\nMySQL正常关闭，会把内存中的脏页都flush到磁盘上\n\nMerge触发条件\n访问这个数据页\n系统后台线程定期 merge\n数据库正常关闭（shutdown）过程中会执行merge\n\nMysql底层结构示意图\n\nDoublewriteBuffer原理在purge操作之前，Mysql会先把数据写到另外一个地方 DoubleWrite Buffer，写完后再开始写磁盘；Doublewrite Buffer是一个备份，当发生 crash时可以利用它来修复磁盘数据。\n\n刷数据之前宕机：内存—&gt; 磁盘，重做 redo log日志。\n刷数据时宕机：利用Doublewrite Buffer修复磁盘数据。\n\nMysql中数据存储各个“数据页(16K)”组成一个 双向链表，每个 数据页中的记录又组成一个 单向链表。每个数据页都会为存储记录 生成页目录，一个数据页内：主键查找，二分法快速定位 ； 其他非主键列查找，从最小记录开始依次遍历单链表。\n","categories":["Mysql","底层原理"],"tags":["Mysql"]},{"title":"Mysql查询优化","url":"/2025/05/18/A1-%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/","content":"Explain查询语句分析主要字段含义\nselect_type：常用 SIMPLE 简单查询，UNION 联合查询，SUBQUERY子查询等\n\npossible_keys：可选择的索引 \n\nkey：实际使用的索引\n\nrows：扫描的行数  \n\ntype：索引查询类型，经常用到的索引查询类型\n\nconst：使用 主键或 唯一索引进行查询时，只有一行匹配\n\n**ref：使用 非唯一索引\n\nrange：使用“主键”、单个字段的辅助索引、多个字段的辅助索引的最后一个字段进行范围查询\n\nall：扫描全表\n\nindex：和 all 区别：只扫描索引树，查询字段是索引的一部分，使用主键进行排序\n\n\n\n\n\n\n查询优化技巧1.只返回必要的列&amp;行不要使用 SELECT * 语句，只返回必要的列；多使用  LIMIT 语句来限制返回的数据，只有一条数据实用 limit 1。\n2.多使用普通索引背景：写多读少，对唯一性要求不高或由业务代码来保证唯一性时，普通索引会使用Changebuffer，会把一些写操作缓存下来，在读取时做merge操作，以此避免频繁的磁盘操作。\n3.建立联合索引出现频率较高，常在一起作 where条件的字段，多考虑建立联合索引，减少建立索引的数量，并借助索引覆盖减少回表。\n4.开启 MRR（mult-range Read）此操作会在回表之前进行一个排序，把原来一个随机操作变成一个顺序操作。\n原理：根据辅助索引的叶子结点，找到主键值的集合，并存储到read_rnd_buffer中，在该buffer中对主键值进行排序，最后利用已经排序好的主键值集合，去访问表中数据，这样在第二次根据主键去回表时，由原来的随机&#x2F;O变为顺序I&#x2F;O，以提高查询速度。\n5.分解大连接查询将一个大连接查询分解成每一个表的单表查询，然后在业务代码中进行关联，优势：\n\n让缓存更高效：连接查询，如果一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然有效；\n减少锁的竞争：多表联接查询会锁住更多的数据，而在业务代码中进行关联，更容易对数据库进行拆分，加锁粒度降低，提高整体查询性能。\n\n6.分页查询优化\n控制返回的总页数； \n\n对超过特定阈值的页数进行 SQL 改写，借助主键 id 索引覆盖，对 where条件增加索引，并设置分页起始位置、页数。子查询只返回主键（不需要回表），外查询根据主键id值，直接定位到具体分页起始点。\n\nSELECT a.* \nFROM user a  \nINNER JOIN  \n    (SELECT id \n    FROM user \n    WHERE age = 10 LIMIT 100000,10) b  \nON a.id = b.id\n\n\n使用Redis 来保存lastMaxtId，下一次分页查询时直接拼接在 where 条件后边，直接跨过 offset 行数据。\n\n设置游标字段（订单号），分页查询时直接根据游标字段直接检索；\n\n\n7.索引字段调整索引选取越长，占用磁盘空间越大，相同数据页能放下的索引值就越少，增加B+树高度，搜索效率也会越低。\n1.短长度：把字段 hash为另外一个字段，缩小索引字段长度，保证hash后差异大\n2.高区分：通过函数处理增加索引区分度（倒序，删减字符等）\n如：身份证区域开头，同区域人很多，REVERSE() 函数翻转一下，提高区分度\n8.批量SQL优化\n在事务中进行插入处理\n\n​\t\t使用事务可以提高数据的插入效率，Mysql进行一个INSERT操作时，内部会建立一个事务，在事务内才进行插入操作。通过使用事务可以减少创建事务的消耗（类似线程池的思想），使得所有插入都执行后才进行提交。\n\n数据有序插入\n\n​\t\t插入记录在主键上是有序排列，由于数据库插入时，需要维护索引数据，有序插入可以有效降低索引B+tree的合并调整操作成本。如果每次插入记录都在索引的最后面，索引的定位效率很高，并且对索引调整较小；如果插入的记录在索引中间，需要B+tree进行分裂合并等处理，会消耗比较多计算资源，并且插入记录的索引定位效率会下降，数据量较大时会有频繁的磁盘操作。\n\n数据批量执行\n\n​\t\t批量执行更新sql语句的分析：\n情况一：mysql 默认autocommit＝on，默认开启自动提交事务。此时一条sql会开启一个事务，这时候同时执行一万条update，会导致实际开启一万个事务，然后一个个执行，挨个开启，挨个提交。\n缺点：同时锁住数据较少，但是数据库资源占用严重，对外提供操作性能下降。\n情况二：当autocommit＝off时，同时执行一万条update，只会开启一个事务，所有update语句一起commit。\n缺点：同时锁住数据较多，其他select查询进不来，大量连接等待获取行锁，也会影响数据库对外服务能力。\n最优方案：设置autocommit&#x3D;off，然后update时，手动分批commit，分批条数限制100，比如一万条update，按照每100条commit一次，1w个update总共需要100个事务，每次锁住100条数据，性能也会得到很大提升。\n","categories":["Mysql","查询优化"],"tags":["Mysql"]},{"title":"Mysql索引","url":"/2025/05/04/A1-%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql%E7%B4%A2%E5%BC%95/","content":"InnoDB索引\n支持 事务、外键、行锁\n聚簇索引，叶子节点data域存行记录\n\nInnoDB采用 MVCC方式支持高并发，实现四个标准隔离级别(未提交读、已提交读、可重复读-默认、可串行化)。\n\n\n\n\n\n\n\n\nMyIsam索引\n不支持 事务，外键，行锁；   \n非聚簇索引，叶子节点data域中存引用地址；\n\n\n\n索引优缺点索引优点\n提高数据查询效率，降低数据库 IO成本；\n被索引的列会自动排序，包括单列索引&amp;组合索引，按照索引列排序，order by语句效率更高；\n\n索引缺点\n索引会占磁盘空间；\n索引会降低更新表的效率，每次对表增删改，不仅要更新数据，还要更新对应的索引；\n\n索引结构Hash :  不适合范围查找；无法用于排序与分组；\n二叉树：根节点的取值，容易导致 二叉树不分叉，降低查询效率；\n平衡二叉树：不支持 范围查询，范围查询时需要从根节点多次遍历，效率低；\nB树：\nB树不支持范围查询，在非叶子节点中也保存数据记录；\n每个节点的 data域存储 行记录，行的大小随着列数的增多而变大，这时页中可存储的数据量会变少，树结构会变高，磁盘IO次数就会变多；\n\nB+树结构：\n支持范围查询，只在叶子节点data域中存数据；且主键具备唯一性，不需再向后查找，&lt;&#x3D;终止；\nIO读取一页（默认16K）数据，数据存储在磁盘中，查询数据时，需要先把 磁盘中的数据加载到内存，磁盘IO操作很耗时，所以优化重点就是 尽量减少磁盘 IO 操作。B+树在非叶子中仅保存索引（不保存数据），相比B树存储同样多的数据，树的高度会更低，从而减少磁盘IO；\n\n各种索引主键索引主键索引 &#x3D;&#x3D; 聚簇索引，当一个表没有创建主键索引时，InnoDB会自动构建聚簇索引。\n\n在表上定义 主键 PRIMARY KEY，InnoDB 将 主键索引用作聚簇索引；                                                     \n如果表没有定义主键，InnoDB会选择 第一个不为NULL的唯一索引列  用作聚簇索引；\n以上两个都没有，会使用一个 6 字节长整型字段构建聚簇索引，该 ROWID字段会在插入新行时自动递增；\n\n辅助索引聚簇索引之外的所有其他索引。\n索引查询过程：非主键索引（辅助索引）的其他索引查询，需要先根据辅助索引B+树找到叶子节点data域中存储的主键索引，再根据主键索引找到实际数据。\n\n\n前缀索引定义字符串的一部分作为索引，如果创建索引的语句不指定前缀长度，索引默认包含整个字符串。\n优点：定义好长度可以做到节省空间，又不用额外增加太多的查询成本。\n注意：有前缀索引的联合索引一定会回表，虽然联合索引已包含相关信息，但还是会回表，因为有前缀索引，不确定到底是不是一个完整的信息。例如： www.aobing@mogu.com 一个完整的邮箱去查询，但无法判断后续是否有数据，不知道是否是完整的数据，所以需要回表去判断。\n联合索引联合索引设计原则\n频繁使用的列、区分度高的列放在前面；\n范围查询的列放在复合索引的最后面，例如 idx_status_create_time；\n将常需要作为 查询返回的字段，增加到联合索引中，通过联合索引上增加字段来使用覆盖索引；\n\n联合索引优势1.减少开销： 建联合索引(col1,col2,col3)，实际相当于建 (col1),(col1,col2),(col1,col2,col3)三个索引,每多一个索引，都会增加写操作的开销和磁盘空间的开销。对于大量数据的表，使用联合索引可以有效的减少开销！\n2.覆盖索引：联合索引通过遍历索引取得数据，无需回表，减少io操作，提升性能；\n3.效率高： 索引列越多，通过索引筛选出的数据越少。\n例如：有1000W条数据的表，有如下sql：select from table where col1&#x3D;1 and col2&#x3D;2 and col3&#x3D;3, 假设每个条件可以筛选出10%数据，如果只有单值索引，那么通过该索引能筛选出1000W10%&#x3D;100w条数据，然后再回表从 100w条数据中找到符合col2&#x3D;2 and col3&#x3D; 3的数据，然后再排序，再分页；\n如果是联合索引，通过索引筛选出1000w10% 10% *10%&#x3D;1w，效率明显提升。\n联合索引查询过程\n覆盖索引由多个字段组合成的联合索引，如：idx_abc(a,b,c)索引，在查询时，如果只需要 abc字段，则查询到联合索引的叶子节点就可以直接返回，不需要回表。\n注：Mysql优化器会根据联合索引字段位置，调整where 后边的查询条件，让其满足索引顺序。\n示例：创建 idx_abc(a,b,c)索引，相当于创建 (a)、（a,b）（a,b,c）三个索引，节省空间。在执行sql时，优化器会调整where后a,b,c的顺序，让其用上索引。\nSELECT * FROM table WHERE a IN (1,2,3) and b &gt; 1; 还是对(a，b)建立索引，因为 IN可视为等值引用，不会中止索引匹配，所以还是(a,b)SELECT * FROM table WHERE a &gt; 1 and b = 2 and c &gt; 3; (b,a)或者(b,c)都可以，要结合具体情况具体分析。select * from t where a=1 and b=1 and c =1;  #这样可以利用到定义的索引（a,b,c）,用上a,b,c select * from t where a=1 and b=1;           #这样可以利用到定义的索引（a,b,c）,用上a,b select * from t where b=1 and a=1;     #这样可以利用到定义的索引（a,b,c）,用上a,b（mysql有查询优化器） select * from t where a=1;             #这样也可以利用到定义的索引（a,b,c）,用上a select * from t where b=1 and c=1;     #这样不可以利用到定义的索引（a,b,c）； 最左 a 不匹配select * from t where a=1 and c=1;     #这样可以利用到定义的索引（a,b,c），但只用上a索引，b,c索引用不到 \n\n\n\n最左匹配原则\n联合索引查询时，Mysql一直向右匹配，直至遇到范围查询 ( &gt;、&lt;、between、like ) 停止匹配。推荐使用联合索引替代多个单列索引使用。\n联合索引只有先确定前一个（左侧的值）后，才能确定下一个值。如果有范围查询，联合索引中使用范围查询的字段后的索引在该条 SQL 中都不会起作用。\n注意：in 和 &#x3D;  都可以乱序，比如有索引（a,b,c），语句 select * from t where c &#x3D;1 and a&#x3D;1 and b&#x3D;1，这样的语句也可以用到最左匹配，因为 MySQL优化器会分析 SQL 语句，将其优化成索引可以匹配的形式，即 select * from t where a &#x3D;1 and a&#x3D;1 and c&#x3D;1。\n\n索引设置建议\n尽量保持自增；\n差异性大的字段；\n出现频率高的字段，或常在where条件中出现的字段；\n小字段（减少所占用的空间）；\n\n破坏索引方式1.索引列 有函数运算\n2.索引列 有  !&#x3D;   &lt;&gt;    not in    not exist \n3.like 条件使索引生效，like后不能以%开头， like %字段名%、like %字段名 这类语句会使索引失效；\n4.字符型索引列；  \n5.隐式类型转换；\n示例：select * from t where id &#x3D; 1; 如果 id 是字符类型的，1是数字类型的，Mysql底层会对 比较进行转换，相当于加了 cast( id AS signed int ) 这样的函数，函数会导致走不上索引。 \n示例：FROM_UNIXTIME(create_time) &#x3D; ‘2016-06-06’ ，不会使用索引，B+树中存储的都是数据表中的字段值，但是进行检索时，需要把所有元素都应用函数才能比较；\n优化：create_time &#x3D; UNIX_TIMESTAMP(‘2016-06-06’)；\n","categories":["Mysql","索引"],"tags":["Mysql"]},{"title":"学习方法论","url":"/2025/05/02/%E6%96%B9%E6%B3%95%E8%AE%BA/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E8%AE%BA/","content":"深度 – 链式学习法从一个技术点出发，不断的输入挖掘，不断的下探一步，问问自己为什么？\n宽度 – 比较学习法类似技术选项的调研，当前市面上还有哪些其他类型的技术，横向对比。\n\n\n5W1H方法what：问题的类型及标准&amp;依据\nwho：问题的主题是谁\nwhich：问题的具体表现&amp;特定的状况（定向描述）\nwhere：问题的空间范围&amp;特定领域\nwhen：问题的时间范围\nhow：问题到了何种程度（怎样、多少…定量描述）\n个人写作模板1.问题是什么？（背景）\n2.当前现状？\n3.预期效果？\n4.面临的挑战？\n5.拆分问题？（分治–实现细节）\n6.横向方案对比？\n7.复盘总结（优点、缺点、后续改进）\n时间管理精力专注1.抵制手机诱惑，固定时间看手机\n2.番茄工作法\n3.工作时间高度专注\n固定深造1.工作日：早起1h、晚睡1h\n2.周末时间选择\n3.通勤时间利用\n沉淀总结1.浅尝即止是大忌：为啥这么写，这么写有啥好处，有啥坏处，多问自己几个为什么?\n2.保持好奇心：勤于在项目中发现问题，挖掘问题，多思考（深度、宽度）。\n","categories":["学习","学习方法论"],"tags":["方法论"]},{"title":"职场工作","url":"/2025/05/02/%E6%96%B9%E6%B3%95%E8%AE%BA/%E8%81%8C%E5%9C%BA%E6%B1%87%E6%8A%A5%E6%96%B9%E6%B3%95%E8%AE%BA/","content":"接受工作–只问标准*具体化\n*可衡量\n*可实现\n*相关性\n*有时限\n\n\n请示工作–必带方案*风险\n*利益\n*差异\n*影响\n汇报工作–突出结果*结论先行\n*再讲理由\n*拿出事例\n*重述结论\n分享工作–细说流程*What：产品背景\n*Who：目标人群\n*Why：预期目标\n*Where：使用场景\n*When：需求节点\n*How：如何验证\n*How much：多少资源\n复盘工作–总结SOP*回顾目标\n*评估结果，数据验证\n*分析成功、失败原因，表层&#x2F;深层原因\n*总结方法论\n","categories":["学习","职场汇报方法论"],"tags":["方法论"]}]