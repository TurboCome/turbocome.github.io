[{"title":"Mysql主从架构","url":"/2025/05/19/A1-%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql%E4%B8%BB%E4%BB%8E%E6%9E%B6%E6%9E%84/","content":"主从复制异步过程1.Mysql主库在收到客户端提交事务的请求后，先写bin log，然后再提交事务，更新数据；\n2.事务提交完成后，给客户端返回操作成功的响应。此时从库会启动一个复制 IO线程，从主库接收 binlog；\n3.把binlog 写到一个中继日志里，再给主库返回一个复制成功的响应；\n4.从库有一个 SQL线程，去读中继日志，回放 binlog内容，以此实现数据的同步； \n\n\n总结：异步复制时：主库提交事务之后，就会给客户端返回响应。\n同步复制时：主库在提交事务时，会等待数据复制到所有从库之后，再给客户端返回响应。\n\nMysql主从复制类型1.异步复制主库执行完提交的事务后，立即将结果返给客户端，并不关心从库是否已经接收并处理。如果主宕机了，此时主上已经提交的事务可能并没有传到从库上，此时强行将从库提升为主库，就可能导致新主上的数据不完整。\n2.半同步复制主库执行完客户端提交的事务后，不会立刻返回给客户端，而是等待 至少一个从库接收到bin log日志后才返回给客户端。半同步复制提高了数据的安全性，同时也造成了一定程度的延迟，这个延迟最少是一个TCP&#x2F;IP往返的时间，所以，半同步复制最好在低延时的网络中使用。\n3.增强半同步复制增强半同步复制，是mysql 5.7.2后的版本，对半同步复制做的一个改进，原理上几乎是一样的，主要解决幻读的问题。主库在存储引擎 提交事务前，必须先收到从库数据同步完成的确认信息，才能提交事务，以此来解决幻读问题。\n4.全同步复制当主库执行完一个事务，所有从库都执行该事务后，主库才返回给客户端。需要等待所有从库执行完该事务，才能返回，全同步复制的性能必然会受到严重的影响。\n半同步&amp;增强半同步区别半同步：等待ACK的点是Commit之后，此时Master已经完成数据变更，用户已经可以看到最新数据，但binlog还未同步到Slave时，发生主从切换后，此时从库是没有这个最新数据的，用户看到的是老数据。\n增强半同步：将等待ACK的点放在提交Commit之前，此时数据还未被提交，外界看不到数据变更，此时如果发送主从切换，新库依然还是老数据，不存在数据不一致的问题。\n总结：等待slave 已经同步完数据，再做commit提交！主库提交事务的时间点是有差别的。\n\n\n\n\n读写分离\n主服务器：写 +  读 （实时性要求高） \n从服务器：读\n\n读写分离提高性能原因1.主从服务器负责各自的 读和写，缓解了锁的竞争；\n2.从服务器可以使用 Myisam引擎，提升查询性能，以及节约系统开销；\n主机宕机恢复机制1.确保所有从节点 relay log全部更新完毕（数据都已同步完），在每个从库上执行 show processlist 查看。\n2.登录所有从节点，查看 master.info文件， 找最大的  pos节点作为新主库，数据最全。\n3.登录 pos最大从节点，执行 stop slave，删 relay-log.info 等相关文件，开启 bin-log来记录sql 日志；执行 reset master。\n4.创建用于同步的用户，并授权slave。\n5.登录其他从节点，执行 stop slave停止同步，再执行 start slave。\n6.测试 新master 和 slave 数据是否同步。\n参考：MySQL主从同步参考\nMysql集群配置单库性能极限：1W TPS\n100库性能极限：100W TPS\n实际Mysql集群部署情况：1主5从双机房，单机房3个实例，在大型互联网公司会以这种集群部署方式来部署Mysql集群。\n\n\n\n\n\n\n","categories":["Mysql"],"tags":["Mysql"]},{"title":"Mysql事务","url":"/2025/05/05/A1-%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql%E4%BA%8B%E5%8A%A1/","content":"事务四大特性原子性：保障：undo log\n定义：一系列操作要么全执行，要么全不执行；\n原理：通过undo log实现，undo log属于逻辑日志，保证事务原子性，记录 sql执行相关的信息，当发生回滚时，会根据undo log内容做与之前相反的工作。例如：对于每个insert，回滚时会执行delete；对于每个update，回滚时会执行一个相反的update，把数据改回去。\n\n\n持久性保障：redo log\n定义：保证事务提交后不会因为宕机等原因造成数据的丢失； \n背景InnoDB存储引擎的数据存放在磁盘中，如果每次读写数据都需要磁盘IO，效率会很低。因此，InnoDB提供了缓存Buffer Pool，Buffer Pool作为访问磁盘的缓冲区。当从数据库读取数据时，首先从Buffer Pool中读取，如果Buffer Pool中没有，再从磁盘读取后放入Buffer Pool；写入数据时，首先写入Buffer Pool，Buffer Pool中修改的数据会 定期刷新到磁盘（刷脏）。\nBuffer Pool虽然提高了读写数据的效率，但也存在问题：如果Mysql宕机，此时Buffer Pool中修改的数据还没刷新到磁盘，就会导致数据丢失，事务的持久性也就无法保证。\n解决方式数据修改时，先在redo log中记录这次操作，然后修改 Buffer Pool中的数据。当事务提交时，会调用 fsync接口对redo log进行刷盘。如果Mysql宕机，重启时会读取redo log数据进行恢复。redo log是预写日志，所有修改先写入日志，再更新到Buffer Pool，保证数据不会因Mysql宕机而丢失。\nredo log在事务提交时写入磁盘，但比刷脏快，具体原因\n刷脏是随机IO（寻道+旋转+寻址），每次修改的数据位置随机，但写 redo log是追加操作，属于顺序IO；\n刷脏是以数据页（默认16k）为单位，一个数据页Page上一个小修改都要整页写入；而 redo log中只包含真正需要写入的部分，无效IO 减少。\n\n隔离性保障：加锁\n定义：保证事务间的执行互不影响\n两方面考虑：读、写\n加锁： 一个事务写操作，对另一个事务写操作；\nMVCC： 一个事务写操作，对另一个事务读操作；\n一致性保障：数据库层面 + 应用层面\n定义：对于同一份数据的不同操作，要保证一致性；\nredo log与binlog区别1.作用不同redo log保证Mysql宕机也不会影响持久性，保证事务持久性。\nbinlog 保证服务器可以基于时间点恢复数据，binlog还用于主从复制；\nundo log 保证事务原子性、隔离性；\n2.层次不同redo log是 InnoDB存储引擎实现的；\nbinlog 是Mysql 服务器层实现的，同时支持InnoDB和其他存储引擎；\n3.内容不同redo log是物理日志，内容基于磁盘的Page；\nbinlog 是二进制，根据binlog_format参数的不同，可能基于 sql语句，基于数据本身或者二者的混合；\n锁类型行锁1.共享锁（S Lock）可以和其他锁共存，多个事务可以同时访问同一份数据，但只能读，不能修改；\n2.排他锁（X Lock）排他锁和其他锁不能共存，一个事务获取一个数据行的排他锁，其他事务不能再获取该行的 共享锁和排他锁，获取排他锁的事务可以对数据进行读取和修改；\n总结：读时加共享锁，其他事务可以并发读，但不能写；写时加排它锁，其他事务不能并发写，也不能并发读。\n表锁对整个表都加锁，绝大部分情况都使用行锁，便于事务处理，但在个别特殊事务中，也考虑使用表锁，例如：当事务需要更新大部分或全部数据时，表比较大，如果使用默认的行锁，不仅这个事务执行效率低，而且可能造成其他事务长时间锁等待和锁冲突，这种情况下考虑使用表锁来提高该事务的执行速度。\n间隙锁（Gap锁）定义：使用范围条件检索数据，请求共享锁或排他锁时，InnoDB会给符合条件的已有数据的索引项加锁。对于键值在条件范围内但并不存在的记录，叫做 “间隙(GAP)”，InnoDB也会对这个“间隙”加锁，这就是间隙锁（GAP锁）。\nSELECT c1 FROM t  WHERE c1 BETWEEN 10 and 20 FOR UPDATE;\n\n解释：意思是锁住 10~15间的数据，如果id&#x3D;10的数据已存在，别的用户不可以修改这条数据。但如果 id&#x3D;15的数据并不存在，也是不可以插入的，因为无论该列中是否已有这样的值，该范围中id在（10，15），现有值的间隙也是锁定的。\n间隙锁作用：防止幻读，不使用间隙锁，其他事务可以将数据插入到查询区间，本事务再次查询就会发生幻读；Record Lock： 锁定一个记录上的索引，而不是记录本身；\nGap Lock：锁定索引之间的间隙，但不包含索引本身；\nNext-Key Lock： Record Locks + Gap Locks 结合，不仅锁定一个记录上的索引，也锁定索引之间的间隙。\nMVCC多版本并发控制（Multi-Version Concurrency Control）定义：MVCC是InnoDB 存储引擎实现 已提交读、可重复读 隔离级别的一种具体方式；\n实现MVCC在 Undo log日志中存储快照信息，通过日志中的回滚指针把一个数据行（Record）的所有快照连接起来；\n\n\n版本号\n系统版本号：一个递增的数字，每开始一个新的事务，系统版本号就会自动递增；\n事务版本号：事务开始时的系统版本号；\n\n隐藏的列：MVCC 在每行记录后面都保存着 两个隐藏的列，用来存储两个版本号。\n\n创建版本号：指示创建一个数据行的快照时的系统版本号； \n删除版本号：如果该快照的删除版本号 &gt; 当前事务版本号，表示该快照有效，否则表示该快照已经被删除。\n\nMvcc总结A 事务读取数据，记录此时刻的快照 id 值， 放在 ReadView 中保存，每次对数据修改都会改变快照 id 值，此id 值保持递增，当后来再次读取 数据时，会比较此时的数据版本 id 值，是否 &gt; 之前的 id 值，如果 &gt; , 说明已经被修改；\n通 undo log 日志，查询之前记录数据的快照，访问那个版本时的数据。\nRR隔离级别1.已提交读（RC）隔离级别下的非加锁读RC与 RR一样，都使用了 MVCC，其主要区别在于：\nRR 是在事务开始后第一次执行select前创建ReadView，直到事务提交都不会再创建；RR可以避免脏读，不可重复读\nRC 每次执行select前都会重新建立一个新的ReadView，如果事务 A第一次select后，事务B对数据进行修改并提交，那么事务A第二次select 时会重新建立新的ReadView，此时事务 B的修改对事务 A是可见的；所以RC隔离级别可以避免脏读，但是无法避免不可重复读和幻读。\n2.加锁读 与 next-key lock按照是否加锁，Mysql 读可以分为两种： \n1.非加锁读（快照读，一致性读），使用普通 select语句，这种情况下使用 MVCC避免了脏读，不可重复读，幻读，保证了隔离性。\n2.加锁读，在查询时会对查询数据加锁（共享锁或排它锁）；由于锁的特性，当某事务对数据进行加锁读后，其他事务无法对数据进行写操作，因此可以 避免脏读和不可重复读。\n避免幻读需要通过 next-key lock，它是一种行锁，相当于 record lock(记录锁) + gap lock(间隙锁)；其不仅会锁住 记录本身(record lock功能)，还会 锁定一个范围(gap lock功能)；因此，加锁读同样可以避免脏读，不可重复读和幻读，保证隔离性。\n快照读&amp;当前读快照读 读取历史数据； MVCC 的 select 操作是快照中的数据，不需要进行加锁操作。 \n当前读读取数据库当前版本最新数据，MVCC 对数据库进行修改的操作（insert、update、delete）需要进行加锁操作，从而读取最新的数据。\n总结：MVCC使用加锁，但避免了 select 加锁 , Mysql为了减少锁处理的时间，提升并发能力，引入了快照读的概念，使得 select不用加锁。而 update，insert ，delete 这些 “当前读”的隔离性，需要通过加锁来实现。\n事务在执行普通select 操作时，在访问记录版本链的过程中，可以使用不同事务的读-写，写-读操作并发执行，从而提升系统性能。\n事务隔离级别\n\n未提交读定义：总是 读取最新的数据行，没有任何加锁，更新数据就会被读取到，直接返回记录的最新值，脏读、幻读、不可重复读都有可能发生。\n问题：事务可以读取 其他未提交事务的执行结果。\n已提交读RC定义：根据 MVCC实现，事务每次查询开始时，会生成一个独立的 ReadView，在数据库表中看到的一行记录可能有多个版本，每个版本记录除了有数据本身外，还有一个表示版本的字段（row trx_id），在事务开始时，向事务系统申请，按时间先后顺序递增。\n问题：事务可以读取 已经提交事务所做的改变。\n可重复读RR定义：在事务开始时生成一个当前事务全局性的快照，同一事务在 多次读取数据时，可以读取到相同的结果。\n可串行化定义：各个事务间串行执行，对所有读取的数据行都加共享锁，避免并行访问。通过MVCC + Next-Key Lock共同实现，这个级别可能 导致大量的超时现象和锁竞争。\n各隔离级别的问题脏读：不同事务下，当前事务可以读取到另外事务未提交的数据。\n不可重复读：同一事务内多次读取同一数据，读取到的数据可能不一样。\n幻读：一个事务读取某一范围的数据行时，另一个事务在该范围内插入新行，此事务再次读取范围内的数据行时，会返回之前不存在的数据行（新插入的数据行）。\nRC&#x2F;RR区别RC 在每一次进行 普通 select 操作前都会生成一个ReadView。\nRR 只在第一次进行普通 select 操作前生成一个ReadView，数据的可重复读就是 ReadView的重复使用。\n因为 B线程修改数据提交后，A线程第二次 select时，不再进行 id 值的比较，会重建ReadView，使得数据丢失。\n可重复读\nselect 操作不可重复读的问题，通过 MVCC 得到解决；\nupdate，delete不可重复读问题，通过 Record Lock 解决；\ninsert 不可重复读问题，通过 Next-Key Lock解决；\n\n根据 MVCC实现，只会根据事务中第一次查询时生成的 ReadView。\n已提交读\n当前事务内的更新，可以读到；\n版本 未提交，不能读到； \n版本 已提交，但是却在快照创建后提交的不能读到； \n版本 已提交，且在快照创建前提交的可以读到；\n\n已提交读&amp;可重复读区别：在快照的创建上，可重复读仅在事务开始时创建一次，已提交读每次执行语句时都重新创建一次。\n","categories":["Mysql"],"tags":["Mysql"]},{"title":"Mysql优化实践","url":"/2025/05/20/A1-%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5/","content":"1.Mysql更新大量数据问题点：主从延迟数据不一致一个SQL 只能使用一个cpu core去处理，如果SQL很复杂或执行很慢，会阻塞后面的 SQL请求，造成Mysql活动连接数暴增，MySQL CPU100%，相关业务接口Timeout。\n同时对于 主从复制架构，做了业务读写分离，更新500w数据需要5分钟，Master上执行5分钟，binlog传到slave也需要执行5分钟，Slave节点就会延迟5分钟，在这期间会造成业务脏数据，比如重复下单等问题。\n\n\n传统Sql示例：\nupdate “业务表” set status = 1 where status= 0 and create_time &gt;= &#x27;2020-10-01 00:00:00&#x27; and create_time &lt;= &#x27;2020-10-07 23:59:59&#x27;&#x27;\n\n解决方案：1.先获取where条件中的最小、最大id。\n2.然后分批次去更新，每批次 1000条，这样既能快速完成更新，又能保证主从复制不会出现延迟。\n具体实现：充分利用普通索引包含主键id特点，先通过索引获取主键 id走覆盖索引扫描，不需要回表。然后再通过id去关联操作，同时根据 Mysql特性，使用分而治之的思想既能高效完成操作，又避免主从复制延迟产生的业务数据混乱。\nselect min(id) min_id, max(id) max_id from coupons where status=0 and create_time &gt;= &#x27;2020-10-01 00:00:00&#x27; and create_time &lt;= &#x27;2020-10-07 23:59:59&#x27;current_id = min_id;for current_id &lt; max_id do    update coupons set status=1     where id &gt;= current_id     and id &lt;= current_id + 1000;    //通过主键id更新1000条很快commit;current_id += 1000;done\n\n\n\n2.分解多表连接使用 in() 代替连接查询（in 等价于等值查询），让 Mysql按照 ID 顺序进行查询，比随机连接要更高效。每个单表查询数据后，会有bufferPool缓存，有利于后续数据查询。业务代码中做过滤，拼接处理：\nSELECT * FROM tag     JOIN tag_post ON tag_post.tag_id= tag.id     JOIN post ON tag_post.post_id= post.id     WHERE tag.tag=&#x27;mysql&#x27;SELECT * FROM tag WHERE tag=&#x27;mysql&#x27;;           --&gt; tag_id = 1234 SELECT * FROM tag_post WHERE tag_id=1234;      —&gt; (123,456,567,9098,8904) SELECT * FROM post WHERE post.id IN (123,456,567,9098,8904);\n\n\n\n3.MRR优化应用实例1Mysql优化器改变where 条件顺序 —&gt; 匹配联合索引\nSELECT * FROM t WHERE key_part1&gt;=1000 and key_part1&lt;2000 and key_part2=1000; \n\n表 t 有 ( key_part1,  key_part2 ) 联合索引，索引根据 key_part1,  key_part2位置关系进行排序。\n没有MRR：SQL优化器会先将 key_part1 &gt;1000 and key_part2 &lt;2000 的数据查询出来，待取出的数据后再根据key_part2的条件进行过滤。如果有大量的数据是 key_part2 !&#x3D;1000，会严重降低查询性能。\n启用MRR优化：优化器会先将查询条件进行拆分，再进行数据查询。将查询条件拆分为(1000,1000),(1001,1000),(1002,1000),…,(1999,1000)，然后在根据这些拆分出的条件，使用索引下推进行数据查询，避免回表。\n应用实例2没开MRR时查询示意图\n\n由于 Mysql存储数据的方式：辅助索引的存储顺序并非与主键的顺序一致，从图中可以看出，根据辅助索引获取的主键来访问表中的数据会导致随机 IO，不同主键不在同一个page 里面时，必然导致多次 IO 和 随机读。 \n基于辅助索引的MRR查询策略第一步：先根据 where条件中的 辅助索引获取辅助索引与主键的集合，结果集为rest。\nselect key_column, pk_column from tb where key_column = x order by key_columnselect non_key_column fromtb where pk_column in ( rest_sort ) \n\n第二步：将结果集rest 放在buffer里面(read_rnd_buffer_size 大小直到buffer满了)，然后对结果集 rest按照pk_column排序得到结果集是rest_sort。\n第三步 利用已经排序过的结果集，访问表中的数据，此时是顺序IO。\n开MRR时查询示意图\n\n从图示MRR原理，Mysql将根据 辅助索引获取的结果集，根据主键进行排序，将乱序化为有序，可以用-主键顺序访问基表，将随机读转化为顺序读，多页数据记录可一次性读入或根据此次的主键范围分次读入，以减少IO操作，提高查询效率。\nMRR使用与否，是由 Mysql中的开关控制，只要设置开启，它会自动在 read_rnd_buffer_size 缓冲区内，对primaryKey进行排序。但这个开关并不是一直开着，因为对于大多数的单条查询，在中间添加一步排序，是对性能的损失，没有必要。\n4.大数据量下分页优化具体问题分页查询时，Mysql并不是跳过 offset 行，而是取 offset+N 行，然后放弃前 offset 行，返回 N 行，在取offset+N 行数据时，因为是select * … 操作，需要回表，查询到索引叶子节点数据，根据叶子节点上的主键值去主键索引上查询需要的全部字段值。当 offset 特别大时，此时使用 limit m,n 效率就非常低下，因为回表 M 行无用的数据，并且占用了大量的 buffer pool 缓存。 \n解决方案表 trade_info中有索引 idx_status_create_time(status, create_time)，等价于索引（status, create_time, id)\n对于深分页 limit m, n来说，越往后翻页越慢( m越大会越慢)。因为要定位 m位置需要扫描的数据越来越多，导致IO开销比较大。利用 辅助索引的索引覆盖，先获取id，不需要回表，然后通过 id 跟原表 trade_info进行关联。\nselect * from trade_info  where status = 0 and create_time &gt;= &#x27;2020-10-01 00:00:00&#x27; and create_time &lt;= &#x27;2020-10-07 23:59:59&#x27;order by id desc  limit 102120, 20; // 改写后的SQL如下： select * from trade_info a,      (select id from trade_info          where status = 0         and create_time &gt;= &#x27;2020-10-01 00:00:00&#x27; and create_time &lt;= &#x27;2020-10-07 23:59:59&#x27;        order by id desc limit 102120, 20) as b    //这一步走的是索引覆盖扫描，不需要回表 where a.id = b.id;// 2个表通过id做join操作，或者in select a.* from user a  inner join  (select id  from user where age = 10 LIMIT 100000,10) b  ON a.id = b.idselect * from userwhere id in (select id from user where age=10 limit 100000, 10);\n\n\n\n5.大数据下 In查询优化如果某张表包含100万条记录，要查找其中10万个ID匹配的记录，使用where in 语句可能比较慢。因为Mysql需要执行一个全表扫描，然后将表中每个记录 id 与where in语句中指定的每个 id 进行匹配，性能较低。\n为提高where in语句的性能，可以使用合适的索引来优化查询，或选择其他更合适的查询方式来实现相同的目的，比如使用JOIN或子查询等。\n具体问题如果mytable表很小，那么查询会非常快。但如果mytable表很大，该查询会变得非常慢，因为Mysql会扫描整个表来查找包含每个指定值的记录。如果您指定了大量值，则查询可能需要扫描整个表。\n解决方案1.创建索引：对mycolumn列创建索引，因为Mysql不需要扫描整个表来查找匹配的记录，而是只需扫描索引。\n2.使用子查询：将 IN子句替换为一个子查询可以显著提高查询性能。Mysql 需要扫描myothertable表来查找匹配的记录，而不需要扫描整个 mytable 表。\nselect * from mytable where mycolumn IN (1,2,3,4,5)select * from mytable where mycolumn IN     (select mycolumn from myothertable where condition)\n\n3.使用JOIN：JOIN语句可以将查询速度提高几倍，Mysql只需扫描mytable和myothertable表中的匹配记录，而不需要扫描整个表。\nselect * from mytable join myothertable ON mytable.mycolumn = myothertable.mycolumn where condition\n\n4.分批查询：将查询拆分成多个独立的查询，每次查询一部分数据，并使用 union 将结果组合在一起，这样可以降低加锁粒度，以提高查询性能。\nselect * from table where id in (100个id) union select * from table where id in (另外100个id)。\n\n\n\n\n\n","categories":["Mysql"],"tags":["Mysql"]},{"title":"Mysql底层原理","url":"/2025/05/11/A1-%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/","content":"BufferPool原理原理：对于数据的修改，Mysql不会直接去修改磁盘数据，这样做太慢了，Mysql会先记录 redo log，再改内存BufferPool，等空闲时再刷磁盘，查询时如果内存 BufferPool里没有数据就去磁盘 load；\nMysql以16KB「页」为读取和写入单位，一「页」里有多行数据，写数据时，Mysql会先写内存中的页，然后再刷新到磁盘。\n\n\n结构：BufferPool是以页(16kb)为元素的链表结构，基于LRU，和缓存一样，需要淘汰算法来管理数据；\n持久化： 宕机时，BufferPool会丢失数据（在内存中），需要重做 redo log； 执行时先写redo log, 再写BufferPool。\n\n\nChangeBuffer原理背景：Mysql查询数据时，如果内存里没有对应页的数据，会从磁盘里load；如果每次需要的页都不同（不是相邻的页），那每次都要去 load，效率会降低；\n原理：更新一个数据页时，如果数据页在内存中，就直接更新；但如果这个数据页没在内存中，InooDB会将这些更新操作缓存在 change buffer中，这样就不需要从磁盘读入这个数据页。在下次查询需要访问这个数据页时，再将数据页读入内存，执行change buffer中与这个页有关的操作，通过这种方式就能保证数据逻辑的正确性。\n使用条件：普通索引可以使用 Changebuffer，唯一索引（或主键）更新不能使用 change buffer，因为唯一索引更新操作要先判断这个操作 是否违反唯一性约束，判断表中是否存在这个数据，就必须要将数据页读入内存才能判断，已经读到内存中，直接更新内存会更快，就没必要使用change buffer。\n关系：change buffer 是 buffer pool里的内存，不能无限增大；\n使用场景适合：写多读少业务，在写完后马上被访问到的概率比较小，此时change buffer使用效果最好，业务模型常见：账单类，日志类的系统。\n不适合：读多写少（写入后马上会做查询）将更新先记录在change buffer，但由于马上要访问这个数据页，会立即触发merge操作，访问IO次数不会减少，反而增加 change buffer维护代价。\n优劣：数据库进行 Merge 时，是真正进行 数据更新的时刻，change buffer目的就是将记录的变更动作缓存下来，所以在一个数据页做merge前，change buffer 记录变更数越多（页面要更新的数据越多），收益就越大。\nmerge：ChangeBuffer –&gt; BufferPool\npurge（刷脏）: BufferPool –&gt; disk\n脏页：在更新之前，当内存数据页跟磁盘数据页内容不一致的时候\nFlush &lt;–&gt; purge过程将内存缓冲区BufferPool中的脏页写入磁盘，保障事务持久性\n触发条件：\n缓存池脏页比例超过阈值\n事务提交\nMySQL正常关闭，会把内存中的脏页都flush到磁盘上\n\nMerge触发条件\n访问这个数据页\n系统后台线程定期 merge\n数据库正常关闭（shutdown）过程中会执行merge\n\nMysql底层结构示意图\nDoublewriteBuffer原理在purge操作之前，Mysql会先把数据写到另外一个地方 DoubleWrite Buffer，写完后再开始写磁盘；Doublewrite Buffer是一个备份，当发生 crash时可以利用它来修复磁盘数据。\n\n刷数据之前宕机：内存—&gt; 磁盘，重做 redo log日志。\n刷数据时宕机：利用Doublewrite Buffer修复磁盘数据。\n\nMysql中数据存储各个“数据页(16K)”组成一个 双向链表，每个 数据页中的记录又组成一个 单向链表。每个数据页都会为存储记录 生成页目录，一个数据页内：主键查找，二分法快速定位 ； 其他非主键列查找，从最小记录开始依次遍历单链表。\n","categories":["Mysql"],"tags":["Mysql"]},{"title":"Mysql查询优化","url":"/2025/05/18/A1-%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/","content":"Explain查询语句分析主要字段含义\nselect_type：常用 SIMPLE 简单查询，UNION 联合查询，SUBQUERY子查询等\n\npossible_keys：可选择的索引 \n\nkey：实际使用的索引\n\nrows：扫描的行数  \n\n\ntype：索引查询类型，经常用到的索引查询类型\n\nconst：使用 主键或 唯一索引进行查询时，只有一行匹配\n\n**ref：使用 非唯一索引\n\nrange：使用“主键”、单个字段的辅助索引、多个字段的辅助索引的最后一个字段进行范围查询\n\nall：扫描全表\n\nindex：和 all 区别：只扫描索引树，查询字段是索引的一部分，使用主键进行排序\n\n\n\n\n查询优化技巧1.只返回必要的列&amp;行不要使用 SELECT * 语句，只返回必要的列；多使用  LIMIT 语句来限制返回的数据，只有一条数据实用 limit 1。\n2.多使用普通索引背景：写多读少，对唯一性要求不高或由业务代码来保证唯一性时，普通索引会使用Changebuffer，会把一些写操作缓存下来，在读取时做merge操作，以此避免频繁的磁盘操作。\n3.建立联合索引出现频率较高，常在一起作 where条件的字段，多考虑建立联合索引，减少建立索引的数量，并借助索引覆盖减少回表。\n4.开启 MRR（mult-range Read）此操作会在回表之前进行一个排序，把原来一个随机操作变成一个顺序操作。\n原理：根据辅助索引的叶子结点，找到主键值的集合，并存储到read_rnd_buffer中，在该buffer中对主键值进行排序，最后利用已经排序好的主键值集合，去访问表中数据，这样在第二次根据主键去回表时，由原来的随机&#x2F;O变为顺序I&#x2F;O，以提高查询速度。\n5.分解大连接查询将一个大连接查询分解成每一个表的单表查询，然后在业务代码中进行关联，优势：\n\n让缓存更高效：连接查询，如果一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然有效；\n减少锁的竞争：多表联接查询会锁住更多的数据，而在业务代码中进行关联，更容易对数据库进行拆分，加锁粒度降低，提高整体查询性能。\n\n6.分页查询优化\n控制返回的总页数； \n\n对超过特定阈值的页数进行 SQL 改写，借助主键 id 索引覆盖，对 where条件增加索引，并设置分页起始位置、页数。子查询只返回主键（不需要回表），外查询根据主键id值，直接定位到具体分页起始点。\n\nSELECT a.* \nFROM user a  \nINNER JOIN  \n    (SELECT id \n    FROM user \n    WHERE age = 10 LIMIT 100000,10) b  \nON a.id = b.id\n\n\n使用Redis 来保存lastMaxtId，下一次分页查询时直接拼接在 where 条件后边，直接跨过 offset 行数据。\n\n设置游标字段（订单号），分页查询时直接根据游标字段直接检索；\n\n\n7.索引字段调整索引选取越长，占用磁盘空间越大，相同数据页能放下的索引值就越少，增加B+树高度，搜索效率也会越低。\n1.短长度：把字段 hash为另外一个字段，缩小索引字段长度，保证hash后差异大\n2.高区分：通过函数处理增加索引区分度（倒序，删减字符等）\n如：身份证区域开头，同区域人很多，REVERSE() 函数翻转一下，提高区分度\n8.批量SQL优化\n在事务中进行插入处理\n\n​\t\t使用事务可以提高数据的插入效率，Mysql进行一个INSERT操作时，内部会建立一个事务，在事务内才进行插入操作。通过使用事务可以减少创建事务的消耗（类似线程池的思想），使得所有插入都执行后才进行提交。\n\n数据有序插入\n\n​\t\t插入记录在主键上是有序排列，由于数据库插入时，需要维护索引数据，有序插入可以有效降低索引B+tree的合并调整操作成本。如果每次插入记录都在索引的最后面，索引的定位效率很高，并且对索引调整较小；如果插入的记录在索引中间，需要B+tree进行分裂合并等处理，会消耗比较多计算资源，并且插入记录的索引定位效率会下降，数据量较大时会有频繁的磁盘操作。\n\n数据批量执行\n\n​\t\t批量执行更新sql语句的分析：\n情况一：mysql 默认autocommit＝on，默认开启自动提交事务。此时一条sql会开启一个事务，这时候同时执行一万条update，会导致实际开启一万个事务，然后一个个执行，挨个开启，挨个提交。\n缺点：同时锁住数据较少，但是数据库资源占用严重，对外提供操作性能下降。\n情况二：当autocommit＝off时，同时执行一万条update，只会开启一个事务，所有update语句一起commit。\n缺点：同时锁住数据较多，其他select查询进不来，大量连接等待获取行锁，也会影响数据库对外服务能力。\n最优方案：设置autocommit&#x3D;off，然后update时，手动分批commit，分批条数限制100，比如一万条update，按照每100条commit一次，1w个update总共需要100个事务，每次锁住100条数据，性能也会得到很大提升。\n","categories":["Mysql"],"tags":["Mysql"]},{"title":"Mysql索引","url":"/2025/05/04/A1-%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql%E7%B4%A2%E5%BC%95/","content":"InnoDB索引\n支持 事务、外键、行锁\n聚簇索引，叶子节点data域存行记录\n\nInnoDB采用 MVCC方式支持高并发，实现四个标准隔离级别(未提交读、已提交读、可重复读-默认、可串行化)。\n\n\n\n\n\n\n\n\nMyIsam索引\n不支持 事务，外键，行锁；   \n非聚簇索引，叶子节点data域中存引用地址；\n\n索引优缺点索引优点\n提高数据查询效率，降低数据库 IO成本；\n被索引的列会自动排序，包括单列索引&amp;组合索引，按照索引列排序，order by语句效率更高；\n\n索引缺点\n索引会占磁盘空间；\n索引会降低更新表的效率，每次对表增删改，不仅要更新数据，还要更新对应的索引；\n\n索引结构Hash :  不适合范围查找；无法用于排序与分组；\n二叉树：根节点的取值，容易导致 二叉树不分叉，降低查询效率；\n平衡二叉树：不支持 范围查询，范围查询时需要从根节点多次遍历，效率低；\nB树：\nB树不支持范围查询，在非叶子节点中也保存数据记录；\n每个节点的 data域存储 行记录，行的大小随着列数的增多而变大，这时页中可存储的数据量会变少，树结构会变高，磁盘IO次数就会变多；\n\nB+树结构：\n支持范围查询，只在叶子节点data域中存数据；且主键具备唯一性，不需再向后查找，&lt;&#x3D;终止；\nIO读取一页（默认16K）数据，数据存储在磁盘中，查询数据时，需要先把 磁盘中的数据加载到内存，磁盘IO操作很耗时，所以优化重点就是 尽量减少磁盘 IO 操作。B+树在非叶子中仅保存索引（不保存数据），相比B树存储同样多的数据，树的高度会更低，从而减少磁盘IO；\n\n各种索引主键索引主键索引 &#x3D;&#x3D; 聚簇索引，当一个表没有创建主键索引时，InnoDB会自动构建聚簇索引。\n\n在表上定义 主键 PRIMARY KEY，InnoDB 将 主键索引用作聚簇索引；                                                     \n如果表没有定义主键，InnoDB会选择 第一个不为NULL的唯一索引列  用作聚簇索引；\n以上两个都没有，会使用一个 6 字节长整型字段构建聚簇索引，该 ROWID字段会在插入新行时自动递增；\n\n辅助索引聚簇索引之外的所有其他索引。\n索引查询过程：非主键索引（辅助索引）的其他索引查询，需要先根据辅助索引B+树找到叶子节点data域中存储的主键索引，再根据主键索引找到实际数据。\n\n\n前缀索引定义字符串的一部分作为索引，如果创建索引的语句不指定前缀长度，索引默认包含整个字符串。\n优点：定义好长度可以做到节省空间，又不用额外增加太多的查询成本。\n注意：有前缀索引的联合索引一定会回表，虽然联合索引已包含相关信息，但还是会回表，因为有前缀索引，不确定到底是不是一个完整的信息。例如： www.aobing@mogu.com 一个完整的邮箱去查询，但无法判断后续是否有数据，不知道是否是完整的数据，所以需要回表去判断。\n联合索引联合索引设计原则\n频繁使用的列、区分度高的列放在前面；\n范围查询的列放在复合索引的最后面，例如 idx_status_create_time；\n将常需要作为 查询返回的字段，增加到联合索引中，通过联合索引上增加字段来使用覆盖索引；\n\n联合索引优势1.减少开销： 建联合索引(col1,col2,col3)，实际相当于建 (col1),(col1,col2),(col1,col2,col3)三个索引,每多一个索引，都会增加写操作的开销和磁盘空间的开销。对于大量数据的表，使用联合索引可以有效的减少开销！\n2.覆盖索引：联合索引通过遍历索引取得数据，无需回表，减少io操作，提升性能；\n3.效率高： 索引列越多，通过索引筛选出的数据越少。\n例如：有1000W条数据的表，有如下sql：select from table where col1&#x3D;1 and col2&#x3D;2 and col3&#x3D;3, 假设每个条件可以筛选出10%数据，如果只有单值索引，那么通过该索引能筛选出1000W10%&#x3D;100w条数据，然后再回表从 100w条数据中找到符合col2&#x3D;2 and col3&#x3D; 3的数据，然后再排序，再分页；\n如果是联合索引，通过索引筛选出1000w10% 10% *10%&#x3D;1w，效率明显提升。\n联合索引查询过程\n覆盖索引由多个字段组合成的联合索引，如：idx_abc(a,b,c)索引，在查询时，如果只需要 abc字段，则查询到联合索引的叶子节点就可以直接返回，不需要回表。\n注：Mysql优化器会根据联合索引字段位置，调整where 后边的查询条件，让其满足索引顺序。\n示例：创建 idx_abc(a,b,c)索引，相当于创建 (a)、（a,b）（a,b,c）三个索引，节省空间。在执行sql时，优化器会调整where后a,b,c的顺序，让其用上索引。\nSELECT * FROM table WHERE a IN (1,2,3) and b &gt; 1; 还是对(a，b)建立索引，因为 IN可视为等值引用，不会中止索引匹配，所以还是(a,b)SELECT * FROM table WHERE a &gt; 1 and b = 2 and c &gt; 3; (b,a)或者(b,c)都可以，要结合具体情况具体分析。select * from t where a=1 and b=1 and c =1;  #这样可以利用到定义的索引（a,b,c）,用上a,b,c select * from t where a=1 and b=1;           #这样可以利用到定义的索引（a,b,c）,用上a,b select * from t where b=1 and a=1;     #这样可以利用到定义的索引（a,b,c）,用上a,b（mysql有查询优化器） select * from t where a=1;             #这样也可以利用到定义的索引（a,b,c）,用上a select * from t where b=1 and c=1;     #这样不可以利用到定义的索引（a,b,c）； 最左 a 不匹配select * from t where a=1 and c=1;     #这样可以利用到定义的索引（a,b,c），但只用上a索引，b,c索引用不到 \n\n\n\n索引下推Mysql将部分过滤操作从Server层下推到存储引擎，减少数据访问层级和IO开销，在高并发或大数据量场景下效果显著。\n具体示例假设表中有100万行数据，索引为(name, age)\n\n无ICP：存储引擎返回所有 name&#x3D;’一灯’ 的1000条主键ID，Server层再筛选age&gt;20的100条，回表1000次。\n有ICP：存储引擎直接在索引中过滤 name&#x3D;’一灯’ AND age&gt;20，返回100条主键ID，回表100次，减少了900次无效回表和数据传输。\n\n最左匹配原则\n联合索引查询时，Mysql一直向右匹配，直至遇到范围查询 ( &gt;、&lt;、between、like ) 停止匹配。推荐使用联合索引替代多个单列索引使用。\n联合索引只有先确定前一个（左侧的值）后，才能确定下一个值。如果有范围查询，联合索引中使用范围查询的字段后的索引在该条 SQL 中都不会起作用。\n注意：in 和 &#x3D;  都可以乱序，比如有索引（a,b,c），语句 select * from t where c &#x3D;1 and a&#x3D;1 and b&#x3D;1，这样的语句也可以用到最左匹配，因为 MySQL优化器会分析 SQL 语句，将其优化成索引可以匹配的形式，即 select * from t where a &#x3D;1 and a&#x3D;1 and c&#x3D;1。\n\n索引设置建议\n尽量保持自增；\n差异性大的字段；\n出现频率高的字段，或常在where条件中出现的字段；\n小字段（减少所占用的空间）；\n\n破坏索引方式1.索引列 有函数运算\n2.索引列 有  !&#x3D;   &lt;&gt;    not in    not exist \n3.like 条件使索引生效，like后不能以%开头， like %字段名%、like %字段名 这类语句会使索引失效；\n4.字符型索引列；  \n5.隐式类型转换；\n示例：select * from t where id &#x3D; 1; 如果 id 是字符类型的，1是数字类型的，Mysql底层会对 比较进行转换，相当于加了 cast( id AS signed int ) 这样的函数，函数会导致走不上索引。 \n示例：FROM_UNIXTIME(create_time) &#x3D; ‘2016-06-06’ ，不会使用索引，B+树中存储的都是数据表中的字段值，但是进行检索时，需要把所有元素都应用函数才能比较；\n优化：create_time &#x3D; UNIX_TIMESTAMP(‘2016-06-06’)；\n","categories":["Mysql"],"tags":["Mysql"]},{"title":"学习方法论","url":"/2025/05/02/%E6%96%B9%E6%B3%95%E8%AE%BA/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E8%AE%BA/","content":"深度 – 链式学习法从一个技术点出发，不断的输入挖掘，不断的下探一步，问问自己为什么？\n宽度 – 比较学习法类似技术选项的调研，当前市面上还有哪些其他类型的技术，横向对比。\n\n\n5W1H方法what：问题的类型及标准&amp;依据\nwho：问题的主题是谁\nwhich：问题的具体表现&amp;特定的状况（定向描述）\nwhere：问题的空间范围&amp;特定领域\nwhen：问题的时间范围\nhow：问题到了何种程度（怎样、多少…定量描述）\n个人写作模板1.问题是什么？（背景）\n2.当前现状？\n3.预期效果？\n4.面临的挑战？\n5.拆分问题？（分治–实现细节）\n6.横向方案对比？\n7.复盘总结（优点、缺点、后续改进）\n时间管理精力专注1.抵制手机诱惑，固定时间看手机\n2.番茄工作法\n3.工作时间高度专注\n固定深造1.工作日：早起1h、晚睡1h\n2.周末时间选择\n3.通勤时间利用\n沉淀总结1.浅尝即止是大忌：为啥这么写，这么写有啥好处，有啥坏处，多问自己几个为什么?\n2.保持好奇心：勤于在项目中发现问题，挖掘问题，多思考（深度、宽度）。\n","categories":["学习","学习方法论"],"tags":["方法论"]},{"title":"Kafka性能优化","url":"/2025/06/08/A2-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/","content":"Kafka性能优化性能问题主要是三个方面：网络、磁盘、复杂度；\nKafka从以下六个方面来对性能进行优化。\n1.顺序IO读写磁盘一次读写磁盘IO需要经过 寻道、旋转、数据传输三个步骤，Kafka 采用顺序写文件的方式来提高磁盘写入性能，减少了磁盘寻道和旋转的操作。\nKafka每个分区是一个有序的，不可变的消息序列，新消息不断追加到 Partition末尾，Partition 只是一个逻辑概念，将 Partition划分为多个Segment，每个Segment对应一个物理文件，对 segment文件追加写入就是顺序写文件。 \n\n\n2.零拷贝网络和磁盘传统 IO流程，需要先读取网络IO，再写入磁盘IO，实际需要将数据 Copy 四次。\n\n\n主要流程\n读取 磁盘文件 到 操作系统 内核缓冲区； DMA搬运\n将 内核缓冲区数据，copy 到应用程序的 buffer； CPU \n将 应用程序 buffer中的数据，copy 到socket buffer (网络发送缓冲区);  CPU \n将 socket buffer数据，copy 到网卡，由网卡进行网络传输。  DMA\n\n总结：磁盘 —&gt; 内核 buf—&gt; 用户 buf—&gt; Socket buf—&gt; 网卡\n零拷贝：内核 buf —&gt; Socket buf —&gt; 网卡\n期间共发生 4次用户态与内核态的上下文切换，发生两次系统调用，一次是 read() ，一次是 write()，每次系统调用都得先从用户态切换到内核态，等内核完成任务后，再从内核态切换回用户态。一次上下文切换需要耗时几十纳秒到几微秒。这个过程中，存在冗余的上下文切换，要想提高文件传输的性能，就需要减少「用户态与内核态的上下文切换」和「内存拷贝」次数。\n零拷贝实现零拷贝：主要用来解决操作系统在处理 I&#x2F;O操作时，频繁复制数据的问题。实现上下文切换数量减少一倍，只有 2次copy，只有DMA进行数据搬运，而不需要CPU。\n\n\n零拷贝实现：上下文切换数量减少一倍，只有 2次copy，只有DMA进行数据搬运，而不需要CPU。\n第一次通过DMA：从 磁盘 —&gt; 内核读缓冲区\n第二次根据 Socket描述符信息，使用 DMA直接从 内核缓冲区—&gt;写入到 网卡缓冲区 \n零拷贝是尽量去减少上面数据的拷贝次数，CPU开销，减少用户态&lt;—&gt;内核态的上下文切换次数，从而优化数据传输的性能。同一份数据传输次数从 四次变成两次，并且没有通过 CPU进行数据搬运，所有的数据都是通过 DMA进行传输。没有在内存层面去复制数据，所以这个方法被称为零拷贝。 \nDMA（Direct Memory Access） 技术在主板上放⼀块独立芯片，进行 内存 和 I&#x2F;O设备数据传输 时，不再通过 CPU 控制数据传输，而直接通过 DMA控制器，传统的从硬盘读取数据，然后再通过 网卡向外发送，需要进行四次数据传输，其中有两次是发生在内存里的缓冲区和对应的硬件设备之间，没法节省掉。但是还有两次，完全是通过 CPU在内存里面进行数据复制。\n在 Kafka里，通过 Java的 NIO里面 FileChannel的 transferTo方法调用，可以不用把 数据复制到应用程序的内存里面。通过DMA方式可以把 数据从内存缓冲区 直接写到 网卡的缓冲****区里面。\nDMAC就是一个 协处理器芯片，通过这个芯片，CPU 只需要告诉 DMAC，要 传输什么数据，从哪里来，到哪里去，就可以放心离开了。后续数据传输工作都会由DMAC 来完成。随着现代计算机各种外设硬件越来越多， 光一个通用的 DMAC 芯片不够了，在各个外设上都加上了 DMAC 芯片，使得 CPU 很少再需要关心数据传输的工作。\n\n\nPageCache应用\n缓存最近被访问的数据 \n预读功能\n\n如果 producer 生产与 consumer消费 速度差不多，可以只对 broker page cache 读写来完成整个生产-消费过程，磁盘访问非常少，producer 生产消息到 Broker ，Broker 按偏移量写入数据，此时数据会先写入 page cache内存区域。consumer 消费消息时，Broker 将数据从  page cache 传输到 Socket buffer，再将 Socket Buffer的数据 copy到网卡，由网卡进行网络传输。 page cache数据会随着内核中 flusher 线程的调度写回到磁盘，不用担心数据丢失。如果 consumer要消费的消息不在page cache里，再去磁盘读取。\n\n\n\n\n3.批量发送与压缩Producer 向 Broker发送消息不是一条一条发送， 而是批量发送，将消息缓存在本地，等到一定条件时发送再发送到Broker。\n具体条件：****1、消息条数；  2、固定一段时间\nProducer 执行流程如图：\n\n\n\nSerialize：序列化传递的消息 (序列化后可提高网络传输效率)\nCompress：压缩消息，提高传输速度、吞吐量，降低延迟并提高磁盘利用率\nAccumulate：消息累计器，每个 Partition维护一个双端队列，队列保存将要发送的批次数据，Accumulate将数据累计到一定数量，或在一定时间内将数据以批次的方式发送出去，主题中每个分区都有一个单独的累加器 &#x2F; 缓冲区。\n\n压缩的作用：减少传输的数据量，减轻对网络的传输压力\nProducer、Broker、Consumer 使用相同的压缩算法， producer 向 Broker 写入数据，Consumer 向 Broker 读取数据时不用解压缩，当消息发送到Consumer 后才解压，这样将  节省大量网络开销。Producer 压缩之后，Consumer 需进行解压，虽然增加 CPU的工作，但在对大数据处理上，瓶颈在网络而不是CPU，所以这个成本是值得的\n注意：「批量发送」+「数据压缩」一起使用，单条做数据压缩的话，效果不明显。\n4.Partition 并行&amp;可扩展1.提高消费并发度：每个 Partition是一个队列，同一个 Group下不同 Consumer并发消费 Paritition，Paritition分区是并行度最小单元，每增加一个 Paritition就增加一个消费并发。 Kafka具有分区分配算法—StickyAssignor，保证分配尽量均衡，每次重分配结果尽量与上一次分配结果保持一致，各个Broker和Consumer处理不至于出现太大倾斜。\n\n\n多Partition缺点\n1.客户端&#x2F;服务端 需要使用更多内存：客户端 producer有个参数 batch.size，默认是 16KB。它会为每个分区缓存消息，一旦满了就打包将消息批量发出。因为这个参数是分区级别，如果分区数量变多，则缓存所需内存也会变得更多。\n2.恢复数据慢：分区越多，每个 Broker上分配的分区也会越多，当发生 Broker 宕机，则恢复时间将会更长。\n5.高效的文件数据结构消息以 Topic为单位进行归类，各个Topic之间彼此独立，互不影响。每个 Topic可以分为一个或多个分区，每个分区各自存在一个记录消息数据的日志文件，每个分区日志在物理上按大小被分成多个 Segment。\n\n\nsegment file 组成： index file 和 data file， 2 个文件一一对应，成对出现（索引文件 .index ，数据文件 .log）partition 全局的第一个 segment 从 0 开始，后续每个 segment 文件名为上一个 segment 文件最后一条消息的 offset 值。\nindex 采用稀疏索引，每个 index文件大小有限。Kafka 采用 mmap方式，将 index文件映射到内存，这样对 index 就不需要操作磁盘 IO。\nMmap(Memory Mapped Files) 内存映射文件方法文件磁盘地址 和 进程虚拟地址空间中一段虚拟地址 一一对映关系，实现这样的映射关系后，进程可以采用指针的方式读写操作这段内存，而系统会自动回写脏页到对应的文件磁盘上，即对文件进行操作，不必调用 read、write 等系统调用函数。相反，内核空间对这段区域的修改也直接反映用户空间，从而实现不同进程间的文件共享。\nmmap将磁盘文件映射到内存，用户通过修改内存达到修改磁盘文件的效果。接收来自socket buffer的网络数据，应用进程不需要中间处理、直接进行持久化。\n原理：直接利用操作系统的 Page来实现文件到物理内存的直接映射，完成映射后对物理内存的操作会被同步到硬盘上。 通过 mmap 进程像读写硬盘一样读写内存（虚拟机内存），省去了用户空间到 内核空间复制的开销。  \nmmap缺点：不可靠，写到 mmap中的数据并没有被真正的写到硬盘，操作系统会在程序主动调用 flush的时候才把数据真正的写到硬盘。 \n6.优秀的网络模型（基于JavaNIO）Kafka 底层基于Java NIO，采用Reactor 线程模型，做的网络模型 RPC。\nReactor线程模型详见：链接\n7.二分法查找对应 offset位置具体查询过程\n按照二分法找到小于offset的 segment 的.log 和.index；\n用目标 offset减去文件名中的 offset得到消息在这个 segment 中的偏移量；\n再次用二分法在 index 文件中找到对应的索引；\n到 log文件中，顺序查找直到找到 offset对应的消息；\n\n","categories":["消息队列MQ"],"tags":["消息队列MQ"]},{"title":"职场工作","url":"/2025/05/02/%E6%96%B9%E6%B3%95%E8%AE%BA/%E8%81%8C%E5%9C%BA%E6%B1%87%E6%8A%A5%E6%96%B9%E6%B3%95%E8%AE%BA/","content":"接受工作–只问标准*具体化\n*可衡量\n*可实现\n*相关性\n*有时限\n\n\n请示工作–必带方案*风险\n*利益\n*差异\n*影响\n汇报工作–突出结果*结论先行\n*再讲理由\n*拿出事例\n*重述结论\n分享工作–细说流程*What：产品背景\n*Who：目标人群\n*Why：预期目标\n*Where：使用场景\n*When：需求节点\n*How：如何验证\n*How much：多少资源\n复盘工作–总结SOP*回顾目标\n*评估结果，数据验证\n*分析成功、失败原因，表层&#x2F;深层原因\n*总结方法论\n","categories":["学习","职场汇报方法论"],"tags":["方法论"]},{"title":"消息队列简介","url":"/2025/05/25/A2-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/","content":"消息队列作用：异步，解耦，削峰\n缺点：可用性降低，增加系统复杂性（重复消费，消息丢失，顺序消费），数据一致性问题\n\n系统可用性降低：加MQ 进来，万一 MQ 挂了，整套系统崩溃；\n系统复杂度提高：怎么限制消息重复消费？怎么处理消息丢失？怎么保证消息顺序？\n数据一致性：A系统处理完后直接返回成功，别人以为这个请求成功了；但问题是，如果有ABC 三个系统，AB两个系统写库成功，结果 C系统写库失败，会导致数据不一致。\n\n\n\n1.异步：提高处理速度\n\n2.解耦：降低模块间耦合、依赖\n\n3.削峰：削峰填谷，平衡流量\n\n\n\n如何保证消息不丢失？\n1.生产消息阶段生产者发送消息到Broker，需要处理 Broker的响应 ack，如果 Broker返回写入失败，需要重试发送，当多次发送失败，需要作报警，日志记录等。\n2.存储消息阶段单机时：存储消息阶段需要在消息刷盘之后，再给生产者响应。假设消息写入缓存中就返回响应，那么机器突然断电会造成消息丢失，而生产者以为已经发送成功。\n集群部署时：有多副本机制，消息不仅要写入当前Broker，还需要写入副本中，需要配置成至少写入1台副本机子后，再给生产者响应。\n3.消费消息阶段消费者执行完业务逻辑后，再发送给 Broker消费成功的ack响应。\n个人总结\n生产者需要处理好 Broker响应，出错情况下利用 重试、报警等手段。\nBroker 需要控制响应的时机，单机：消息刷盘后返回响应； 集群多副本：发送至1个副本及以上后再返回响应。\n消费者需要在执行完真正的业务逻辑后，再返回ack响应给Broker。\n\n注意：消息可靠性增强，性能就下降，等待消息刷盘，多副本同步后返回都会影响性能，需要根据具体场景区别对待，例如：日志的传输可能丢那么一两条关系不大，因此没必要等消息刷盘再响应。\n如何处理重复消息？1.业务幂等消息重复关键点就是 幂等，在业务上处理重复消息所带来的影响。记录关键key，比如记录订单ID，假如有重复消息过来，先判断这个ID是否已经被处理过。\n2.接口幂等分场景去考虑，强校验、弱校验；如跟金钱相关场景就做强校验。\n强校验：多个操作放在一个事务里，成功一起成功，失败一起失败。每次消息过来都根据 订单号+业务场景 唯一标识去流水表查，确认有没有这条流水，有就直接return，没有则执行后面逻辑。\n弱校验：一些不重要的场景，把 id+场景唯一标识作为Redis的key，放到缓存里面（失效时间看场景），一定时间内这个消息就去 Redis判断。\n3.数据库约束唯一索引、主键，重复数据插入会失败。\n如何保证顺序消费？顺序性保证分为：全局有序，部分有序，消费方都不能开启并行消费。\n1.全局有序一个生产者，一个队列分区，一个消费者；\n全局有序只能有一个生产者往Topic发送消息，并且一个Topic内部只能有一个队列（分区），消费者必须是单线程消费这个队列，生产者通过指定 partKey的方式将消息发送到某一个集群的某一个 partition，以实现消息的全局有序，一般情况下不需要全局有序，因为会严重影响MQ的吞吐量。\n\n\n2.部分有序核心：把消息通过特定的策略发往固定的队列中，将 Topic内部划分成需要的队列数，然后每个队列对应一个单线程处理的消费者，这样即完成部分有序的需求，又可以通过 队列数量的并发，提高消息处理效率。\n使用Hash取模法，让同一个订单发送到同一个队列中，同一个订单多步操作同步进行；顺序消费由消费者业务保证!\n\n\n\n\n如何处理消息堆积？1.消费能力弱，时间长造成消息积压解决方案批量消费：本身消费能力较弱，优化消费逻辑尝试批量消费，多线程消费；\n水平扩容：增加Topic的队列数和消费者数量，队列数一定增加，不然新增加消费者是没东西消费的，一个Topic中一个队列只会分配给一个消费者；\n2.消费失败反复重试制定合理的重试策略：1,2,4,8, 2^n，最大重试次数；\n如果失败，落DB重试表，后续再进行报警、日志等处理；\n消息队列对比RabbitMQ、RocketMQ、Kafka 区别\n\n\n\n特性\nRabbitMQ\nRocketMQ\nKafka\n\n\n\n单机吞吐量\n万级\n10 万级，支撑高吞吐\n10 万级，高吞吐，一般配合大数据类的系统进行实时数据计算、日志采集等场景\n\n\ntopic 数量对吞吐量的影响\n\ntopic达几百&#x2F;几千级别，吞吐量会有较小幅度的下降，这是 RocketMQ一大优势，在同等机器下，可以支撑大量的 topic。\ntopic 从几十到几百时，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic数量不要过多。要支撑大规模 topic，需要增加更多机器资源。\n\n\n时效性\n微秒级，这是 RabbitMQ 的一大特点，延迟最低\nms 级\n延迟在 ms 级以内\n\n\n可用性\n高，基于主从架构实现高可用\n非常高，分布式架构\n非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用\n\n\n消息可靠性\n基本不丢\n经过参数优化配置，可以做到 0 丢失\n同 RocketMQ\n\n\n功能支持\n基于 erlang 开发，并发能力很强，性能极好，延时很低\nMQ 功能较为完善，还是分布式的，扩展性好\n功能较为简单，主要支持简单的 MQ功能，在大数据领域的实时计算，以及日志采集被大规模使用\n\n\n","categories":["消息队列MQ"],"tags":["消息队列MQ"]},{"title":"Kafka消息队列","url":"/2025/06/02/A2-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%AE%80%E4%BB%8B/","content":"Kafka消息队列结构队列topic多个生产者往同一个队列 topic丢数据，多个消费者往同一个队列(topic)拿数据。\n队列分区Partition为提高一个队列topic吞吐量，Kafka把topic进行分区 Partition，生产者往一个发布订阅的topic分区 Partition中发数据，消费者从分区Partition中取数据。每个Topic 可以有多个分区，分区是最小的读取和存储结构。每个partition对应一个消费者，多个消费者同时进行消费，以此来提高并发量。消息是发往一个主题下的某个分区中。\n\n\n每个消费组会有自己的 offset（消费点位）来标识消费到的位置， 在消费点位之前表明已经消费过。 offset是分区级别，每个消费组都会维护订阅的 Topic下的每个分区的offset。offset 表示消费者的消费进度，每次消费者消费时都会提交这个offset。一个消费者组中的某个消费者挂了，但其所在分区可能有存活的消费者，存活的消费者继续去消费，但需要知道挂掉的消费者具体消费到了哪里，就需要知道offset。\n\n\n每个 Partition都是一个文件，收到消息后 Kafka会把数据插入到文件末尾。\n缺点：没办法删除数据，所以 Kafka 是不会删除数据的，它会把所有的数据都保留下来，每个消费者对每个 Topic都有一个 offset 用来表示读取到第几条数据， offset 是由对应的消费者维护，保存到 Zookeeper 里面。 \n\n\n数据发往哪个partition？\n发送时可以指定 partition，如果有指定，则写入对应的 partition；\n没有指定partition，但设置了数据key，则会根据key的值 hash出一个partition；\n没有指定 partition，也没有指定 key ， 会随机选择一个分区，并尽可能一直使用该分区，待该分区已满或过了间隔时间，再随机一个分区进行使用；\n\n服务器BrokerKafka服务器叫 Broker，集群是由多个broker组成。分区Partition是分布在不同broker中，实现多机均匀负载。如果其中一台 broker挂了，会丢失其中 partition上的数据，但 kafka把这些 partition都做了备份。如现有三个partition，分别存在三台broker上，每个partition都会备份，这些备份散落在不同的broker上，如下图红色的 partition代表是主分区，紫色partition代表的是备份分区。\n生产者，消费者都是与主分区交互，备份分区仅用作于备份不做读写，如果某个Broker挂了，就会选举出其他 Broker的 partition来作为主分区，实现高可用。\n\n\n消费者都是属于某个消费组的，一条消息会发往多个订阅这个主题的消费组；例如：两个消费组分别是Group 1 和 Group 2，它们都订阅 Topic-a，此时有一条消息发往 Topic-a，那么这两个消费组都能接收到这条消息。这条消息实际 写入Topic中的某个分区，消费组中的某个消费者对应消费一个 Topic 的某个分区。\n\n\nBroker副本（Replica）为更好的做 负载均衡，Kafka 尽量将所有的 Partition均匀分配到整个集群上。 \n为提高Kafka的容错能力，需要将同一个 Partition的 Replica尽量分散到不同的机器。 实际上，如果所有的 Replica都在同一个Broker上，那一旦该 Broker宕机，该 Partition所有 Replica都无法工作，也就达不到 备份的效果。 同时如果某个Broker宕机了，需要保证它上面的负载可以被均匀的分配到其它幸存的所有Broker上。 \n删除数据策略目的：为避免磁盘被撑满，Kakfa 提供两种策略来删除数据\n\n基于时间 （默认七天）\n基于 Partition 文件大小\n\n消息轮询消费者组 是采用Pull 拉方式来消费消息，消费者通过轮询 API(poll) 向服务器定时请求数据。\n重新分区分配Partition 可以水平无限扩展，随着 Partition扩容， Consumer消费 Partition也会重新分配，这里涉及到消息消费分配策略，在 Kafka内部存在两种默认的分区分配策略：Range 和RoundRobin，当以下事件发生时，Kafka将会进行一次分区分配。\n\n同一个Consumer Group内新增消费者；\n订阅的主题新增Partition；\n消费者离开当前所属Group，包括Shuts Down或Crashes；\n\n消息持久化Kafka将partition数据写在磁盘，是追加写入，避免随机 I&#x2F;O操作，寻址磁盘效率低。\n持久化时，partition会先缓存一部分, 放在page cache中，等到足够多数据量&#x2F;等待一定的时间后，再批量写入(flush)。 消费者实际上也是从partition中取数据。\n\n\n生产者，消费者都可以有多个，多个消费者可以组成一个消费者组，如果一个消费者消费三个分区，消费者组就可以每个消费者去消费一个分区，消费者组中各个消费者并发消费，以此来提高吞吐量。\n如果消费者组中的某个消费者挂了，那么其中有一个消费者就要消费两个 partition；如果只有三个partition，而消费者组有4个消费者，那一个消费者会空闲。消费者组之间从逻辑上是独立的，如果多加入一个消费者组，无论是新增的消费者组，还是原本的消费者组，都能消费topic的全部数据。\n\n\n消息顺序性Kafka是分布式结构，往一个 topic中存数据，实际上是 往多个 broker的 partition中存储数据，将 partition以消息日志的方式存储起来，通过顺序访问IO和缓存，才真正把数据写到磁盘上。\n要保证全局有序只能写入一个partition；要保证消费有序则消费者也只能有一个。\n分布式无法避免 网络抖动&#x2F;机器宕机 等问题的发生，很有可能消费者A读取数据，没来得及消费就挂了，Zookeeper 发现消费者A挂了，让消费者B 去消费原本A的分区，等消费者A重连的时候，发现已经重复消费同一条数据了(或消费者超时等)。如果 业务上不允许重复消费，最好是让消费者在业务上做重复性校验。\n消息不丢失1.生产者ackKafka 支持在生产者一侧进行 本地 buffer，累积到一定数量才发送，如果这里设置不当会丢消息。当设置为async，会大幅提升性能，因为生产者会在本地缓冲消息，并适时批量发送。\n如果对可靠性要求高，设置sync同步发送，Kafka 采用至少一次保证消息不会丢，但可能会重复传输。acks默认值即为1，代表消息被partitioin接收之后才算成功发送，也可以配置 acks &#x3D; all 代表所有副本都接收到该消息之后，才算真正成功发送。\n2.队列设置（副本&#x2F;持久化）集群：一般会设置 replication.factor &gt;&#x3D; 3，这样就可以保证每个分区(partition) 至少有 3个副本，以确保消息队列的安全性。\n单机：通过持久化到磁盘来保证消息不丢失。\n3.消费者ack消费端是否异步ack设置：消息处理完成前提交offset，可能造成数据丢失；Consumer默认自动提交 offset(位移)，在后台提交位移前一定要保证消息被正常处理。 \n如果处理耗时很长，建议把逻辑放到另一个线程中去做，异步提交ack会提高消费者的响应速度，但容易造成消息丢失。为避免消息丢失，设置 enable.auto.commit&#x3D;false，关闭自动提交位移，在消息被完整处理后再手动提交位移。\n","categories":["消息队列MQ"],"tags":["消息队列MQ"]}]