[{"title":"Mysql主从架构","url":"/2025/05/19/A1-%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql%E4%B8%BB%E4%BB%8E%E6%9E%B6%E6%9E%84/","content":"主从复制异步过程1.Mysql主库在收到客户端提交事务的请求后，先写bin log，然后再提交事务，更新数据；\n2.事务提交完成后，给客户端返回操作成功的响应。此时从库会启动一个复制 IO线程，从主库接收 binlog；\n3.把binlog 写到一个中继日志里，再给主库返回一个复制成功的响应；\n4.从库有一个 SQL线程，去读中继日志，回放 binlog内容，以此实现数据的同步； \n\n\n总结：异步复制时：主库提交事务之后，就会给客户端返回响应。\n同步复制时：主库在提交事务时，会等待数据复制到所有从库之后，再给客户端返回响应。\n\nMysql主从复制类型1.异步复制主库执行完提交的事务后，立即将结果返给客户端，并不关心从库是否已经接收并处理。如果主宕机了，此时主上已经提交的事务可能并没有传到从库上，此时强行将从库提升为主库，就可能导致新主上的数据不完整。\n2.半同步复制主库执行完客户端提交的事务后，不会立刻返回给客户端，而是等待 至少一个从库接收到bin log日志后才返回给客户端。半同步复制提高了数据的安全性，同时也造成了一定程度的延迟，这个延迟最少是一个TCP&#x2F;IP往返的时间，所以，半同步复制最好在低延时的网络中使用。\n3.增强半同步复制增强半同步复制，是mysql 5.7.2后的版本，对半同步复制做的一个改进，原理上几乎是一样的，主要解决幻读的问题。主库在存储引擎 提交事务前，必须先收到从库数据同步完成的确认信息，才能提交事务，以此来解决幻读问题。\n4.全同步复制当主库执行完一个事务，所有从库都执行该事务后，主库才返回给客户端。需要等待所有从库执行完该事务，才能返回，全同步复制的性能必然会受到严重的影响。\n半同步&amp;增强半同步区别半同步：等待ACK的点是Commit之后，此时Master已经完成数据变更，用户已经可以看到最新数据，但binlog还未同步到Slave时，发生主从切换后，此时从库是没有这个最新数据的，用户看到的是老数据。\n增强半同步：将等待ACK的点放在提交Commit之前，此时数据还未被提交，外界看不到数据变更，此时如果发送主从切换，新库依然还是老数据，不存在数据不一致的问题。\n总结：等待slave 已经同步完数据，再做commit提交！主库提交事务的时间点是有差别的。\n\n\n\n\n读写分离\n主服务器：写 +  读 （实时性要求高） \n从服务器：读\n\n读写分离提高性能原因1.主从服务器负责各自的 读和写，缓解了锁的竞争；\n2.从服务器可以使用 Myisam引擎，提升查询性能，以及节约系统开销；\n主机宕机恢复机制1.确保所有从节点 relay log全部更新完毕（数据都已同步完），在每个从库上执行 show processlist 查看。\n2.登录所有从节点，查看 master.info文件， 找最大的  pos节点作为新主库，数据最全。\n3.登录 pos最大从节点，执行 stop slave，删 relay-log.info 等相关文件，开启 bin-log来记录sql 日志；执行 reset master。\n4.创建用于同步的用户，并授权slave。\n5.登录其他从节点，执行 stop slave停止同步，再执行 start slave。\n6.测试 新master 和 slave 数据是否同步。\n参考：MySQL主从同步参考\nMysql集群配置单库性能极限：1W TPS\n100库性能极限：100W TPS\n实际Mysql集群部署情况：1主5从双机房，单机房3个实例，在大型互联网公司会以这种集群部署方式来部署Mysql集群。\n\n\n\n\n\n\n","categories":["Mysql"],"tags":["Mysql"]},{"title":"Mysql事务","url":"/2025/05/05/A1-%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql%E4%BA%8B%E5%8A%A1/","content":"事务四大特性原子性：保障：undo log\n定义：一系列操作要么全执行，要么全不执行；\n原理：通过undo log实现，undo log属于逻辑日志，保证事务原子性，记录 sql执行相关的信息，当发生回滚时，会根据undo log内容做与之前相反的工作。例如：对于每个insert，回滚时会执行delete；对于每个update，回滚时会执行一个相反的update，把数据改回去。\n\n\n持久性保障：redo log\n定义：保证事务提交后不会因为宕机等原因造成数据的丢失； \n背景InnoDB存储引擎的数据存放在磁盘中，如果每次读写数据都需要磁盘IO，效率会很低。因此，InnoDB提供了缓存Buffer Pool，Buffer Pool作为访问磁盘的缓冲区。当从数据库读取数据时，首先从Buffer Pool中读取，如果Buffer Pool中没有，再从磁盘读取后放入Buffer Pool；写入数据时，首先写入Buffer Pool，Buffer Pool中修改的数据会 定期刷新到磁盘（刷脏）。\nBuffer Pool虽然提高了读写数据的效率，但也存在问题：如果Mysql宕机，此时Buffer Pool中修改的数据还没刷新到磁盘，就会导致数据丢失，事务的持久性也就无法保证。\n解决方式数据修改时，先在redo log中记录这次操作，然后修改 Buffer Pool中的数据。当事务提交时，会调用 fsync接口对redo log进行刷盘。如果Mysql宕机，重启时会读取redo log数据进行恢复。redo log是预写日志，所有修改先写入日志，再更新到Buffer Pool，保证数据不会因Mysql宕机而丢失。\nredo log在事务提交时写入磁盘，但比刷脏快，具体原因\n刷脏是随机IO（寻道+旋转+寻址），每次修改的数据位置随机，但写 redo log是追加操作，属于顺序IO；\n刷脏是以数据页（默认16k）为单位，一个数据页Page上一个小修改都要整页写入；而 redo log中只包含真正需要写入的部分，无效IO 减少。\n\n隔离性保障：加锁\n定义：保证事务间的执行互不影响\n两方面考虑：读、写\n加锁： 一个事务写操作，对另一个事务写操作；\nMVCC： 一个事务写操作，对另一个事务读操作；\n一致性保障：数据库层面 + 应用层面\n定义：对于同一份数据的不同操作，要保证一致性；\nredo log与binlog区别1.作用不同redo log保证Mysql宕机也不会影响持久性，保证事务持久性。\nbinlog 保证服务器可以基于时间点恢复数据，binlog还用于主从复制；\nundo log 保证事务原子性、隔离性；\n2.层次不同redo log是 InnoDB存储引擎实现的；\nbinlog 是Mysql 服务器层实现的，同时支持InnoDB和其他存储引擎；\n3.内容不同redo log是物理日志，内容基于磁盘的Page；\nbinlog 是二进制，根据binlog_format参数的不同，可能基于 sql语句，基于数据本身或者二者的混合；\n锁类型行锁1.共享锁（S Lock）可以和其他锁共存，多个事务可以同时访问同一份数据，但只能读，不能修改；\n2.排他锁（X Lock）排他锁和其他锁不能共存，一个事务获取一个数据行的排他锁，其他事务不能再获取该行的 共享锁和排他锁，获取排他锁的事务可以对数据进行读取和修改；\n总结：读时加共享锁，其他事务可以并发读，但不能写；写时加排它锁，其他事务不能并发写，也不能并发读。\n表锁对整个表都加锁，绝大部分情况都使用行锁，便于事务处理，但在个别特殊事务中，也考虑使用表锁，例如：当事务需要更新大部分或全部数据时，表比较大，如果使用默认的行锁，不仅这个事务执行效率低，而且可能造成其他事务长时间锁等待和锁冲突，这种情况下考虑使用表锁来提高该事务的执行速度。\n间隙锁（Gap锁）定义：使用范围条件检索数据，请求共享锁或排他锁时，InnoDB会给符合条件的已有数据的索引项加锁。对于键值在条件范围内但并不存在的记录，叫做 “间隙(GAP)”，InnoDB也会对这个“间隙”加锁，这就是间隙锁（GAP锁）。\nSELECT c1 FROM t  WHERE c1 BETWEEN 10 and 20 FOR UPDATE;\n\n解释：意思是锁住 10~15间的数据，如果id&#x3D;10的数据已存在，别的用户不可以修改这条数据。但如果 id&#x3D;15的数据并不存在，也是不可以插入的，因为无论该列中是否已有这样的值，该范围中id在（10，15），现有值的间隙也是锁定的。\n间隙锁作用：防止幻读，不使用间隙锁，其他事务可以将数据插入到查询区间，本事务再次查询就会发生幻读；Record Lock： 锁定一个记录上的索引，而不是记录本身；\nGap Lock：锁定索引之间的间隙，但不包含索引本身；\nNext-Key Lock： Record Locks + Gap Locks 结合，不仅锁定一个记录上的索引，也锁定索引之间的间隙。\nMVCC多版本并发控制（Multi-Version Concurrency Control）定义：MVCC是InnoDB 存储引擎实现 已提交读、可重复读 隔离级别的一种具体方式；\n实现MVCC在 Undo log日志中存储快照信息，通过日志中的回滚指针把一个数据行（Record）的所有快照连接起来；\n\n\n版本号\n系统版本号：一个递增的数字，每开始一个新的事务，系统版本号就会自动递增；\n事务版本号：事务开始时的系统版本号；\n\n隐藏的列：MVCC 在每行记录后面都保存着 两个隐藏的列，用来存储两个版本号。\n\n创建版本号：指示创建一个数据行的快照时的系统版本号； \n删除版本号：如果该快照的删除版本号 &gt; 当前事务版本号，表示该快照有效，否则表示该快照已经被删除。\n\nMvcc总结A 事务读取数据，记录此时刻的快照 id 值， 放在 ReadView 中保存，每次对数据修改都会改变快照 id 值，此id 值保持递增，当后来再次读取 数据时，会比较此时的数据版本 id 值，是否 &gt; 之前的 id 值，如果 &gt; , 说明已经被修改；\n通 undo log 日志，查询之前记录数据的快照，访问那个版本时的数据。\nRR隔离级别1.已提交读（RC）隔离级别下的非加锁读RC与 RR一样，都使用了 MVCC，其主要区别在于：\nRR 是在事务开始后第一次执行select前创建ReadView，直到事务提交都不会再创建；RR可以避免脏读，不可重复读\nRC 每次执行select前都会重新建立一个新的ReadView，如果事务 A第一次select后，事务B对数据进行修改并提交，那么事务A第二次select 时会重新建立新的ReadView，此时事务 B的修改对事务 A是可见的；所以RC隔离级别可以避免脏读，但是无法避免不可重复读和幻读。\n2.加锁读 与 next-key lock按照是否加锁，Mysql 读可以分为两种： \n1.非加锁读（快照读，一致性读），使用普通 select语句，这种情况下使用 MVCC避免了脏读，不可重复读，幻读，保证了隔离性。\n2.加锁读，在查询时会对查询数据加锁（共享锁或排它锁）；由于锁的特性，当某事务对数据进行加锁读后，其他事务无法对数据进行写操作，因此可以 避免脏读和不可重复读。\n避免幻读需要通过 next-key lock，它是一种行锁，相当于 record lock(记录锁) + gap lock(间隙锁)；其不仅会锁住 记录本身(record lock功能)，还会 锁定一个范围(gap lock功能)；因此，加锁读同样可以避免脏读，不可重复读和幻读，保证隔离性。\n快照读&amp;当前读快照读 读取历史数据； MVCC 的 select 操作是快照中的数据，不需要进行加锁操作。 \n当前读读取数据库当前版本最新数据，MVCC 对数据库进行修改的操作（insert、update、delete）需要进行加锁操作，从而读取最新的数据。\n总结：MVCC使用加锁，但避免了 select 加锁 , Mysql为了减少锁处理的时间，提升并发能力，引入了快照读的概念，使得 select不用加锁。而 update，insert ，delete 这些 “当前读”的隔离性，需要通过加锁来实现。\n事务在执行普通select 操作时，在访问记录版本链的过程中，可以使用不同事务的读-写，写-读操作并发执行，从而提升系统性能。\n事务隔离级别\n\n未提交读定义：总是 读取最新的数据行，没有任何加锁，更新数据就会被读取到，直接返回记录的最新值，脏读、幻读、不可重复读都有可能发生。\n问题：事务可以读取 其他未提交事务的执行结果。\n已提交读RC定义：根据 MVCC实现，事务每次查询开始时，会生成一个独立的 ReadView，在数据库表中看到的一行记录可能有多个版本，每个版本记录除了有数据本身外，还有一个表示版本的字段（row trx_id），在事务开始时，向事务系统申请，按时间先后顺序递增。\n问题：事务可以读取 已经提交事务所做的改变。\n可重复读RR定义：在事务开始时生成一个当前事务全局性的快照，同一事务在 多次读取数据时，可以读取到相同的结果。\n可串行化定义：各个事务间串行执行，对所有读取的数据行都加共享锁，避免并行访问。通过MVCC + Next-Key Lock共同实现，这个级别可能 导致大量的超时现象和锁竞争。\n各隔离级别的问题脏读：不同事务下，当前事务可以读取到另外事务未提交的数据。\n不可重复读：同一事务内多次读取同一数据，读取到的数据可能不一样。\n幻读：一个事务读取某一范围的数据行时，另一个事务在该范围内插入新行，此事务再次读取范围内的数据行时，会返回之前不存在的数据行（新插入的数据行）。\nRC&#x2F;RR区别RC 在每一次进行 普通 select 操作前都会生成一个ReadView。\nRR 只在第一次进行普通 select 操作前生成一个ReadView，数据的可重复读就是 ReadView的重复使用。\n因为 B线程修改数据提交后，A线程第二次 select时，不再进行 id 值的比较，会重建ReadView，使得数据丢失。\n可重复读\nselect 操作不可重复读的问题，通过 MVCC 得到解决；\nupdate，delete不可重复读问题，通过 Record Lock 解决；\ninsert 不可重复读问题，通过 Next-Key Lock解决；\n\n根据 MVCC实现，只会根据事务中第一次查询时生成的 ReadView。\n已提交读\n当前事务内的更新，可以读到；\n版本 未提交，不能读到； \n版本 已提交，但是却在快照创建后提交的不能读到； \n版本 已提交，且在快照创建前提交的可以读到；\n\n已提交读&amp;可重复读区别：在快照的创建上，可重复读仅在事务开始时创建一次，已提交读每次执行语句时都重新创建一次。\n","categories":["Mysql"],"tags":["Mysql"]},{"title":"Mysql优化实践","url":"/2025/05/20/A1-%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5/","content":"1.Mysql更新大量数据问题点：主从延迟数据不一致一个SQL 只能使用一个cpu core去处理，如果SQL很复杂或执行很慢，会阻塞后面的 SQL请求，造成Mysql活动连接数暴增，MySQL CPU100%，相关业务接口Timeout。\n同时对于 主从复制架构，做了业务读写分离，更新500w数据需要5分钟，Master上执行5分钟，binlog传到slave也需要执行5分钟，Slave节点就会延迟5分钟，在这期间会造成业务脏数据，比如重复下单等问题。\n\n\n传统Sql示例：\nupdate “业务表” set status = 1 where status= 0 and create_time &gt;= &#x27;2020-10-01 00:00:00&#x27; and create_time &lt;= &#x27;2020-10-07 23:59:59&#x27;&#x27;\n\n解决方案：1.先获取where条件中的最小、最大id。\n2.然后分批次去更新，每批次 1000条，这样既能快速完成更新，又能保证主从复制不会出现延迟。\n具体实现：充分利用普通索引包含主键id特点，先通过索引获取主键 id走覆盖索引扫描，不需要回表。然后再通过id去关联操作，同时根据 Mysql特性，使用分而治之的思想既能高效完成操作，又避免主从复制延迟产生的业务数据混乱。\nselect min(id) min_id, max(id) max_id from coupons where status=0 and create_time &gt;= &#x27;2020-10-01 00:00:00&#x27; and create_time &lt;= &#x27;2020-10-07 23:59:59&#x27;current_id = min_id;for current_id &lt; max_id do    update coupons set status=1     where id &gt;= current_id     and id &lt;= current_id + 1000;    //通过主键id更新1000条很快commit;current_id += 1000;done\n\n\n\n2.分解多表连接使用 in() 代替连接查询（in 等价于等值查询），让 Mysql按照 ID 顺序进行查询，比随机连接要更高效。每个单表查询数据后，会有bufferPool缓存，有利于后续数据查询。业务代码中做过滤，拼接处理：\nSELECT * FROM tag     JOIN tag_post ON tag_post.tag_id= tag.id     JOIN post ON tag_post.post_id= post.id     WHERE tag.tag=&#x27;mysql&#x27;SELECT * FROM tag WHERE tag=&#x27;mysql&#x27;;           --&gt; tag_id = 1234 SELECT * FROM tag_post WHERE tag_id=1234;      —&gt; (123,456,567,9098,8904) SELECT * FROM post WHERE post.id IN (123,456,567,9098,8904);\n\n\n\n3.MRR优化应用实例1Mysql优化器改变where 条件顺序 —&gt; 匹配联合索引\nSELECT * FROM t WHERE key_part1&gt;=1000 and key_part1&lt;2000 and key_part2=1000; \n\n表 t 有 ( key_part1,  key_part2 ) 联合索引，索引根据 key_part1,  key_part2位置关系进行排序。\n没有MRR：SQL优化器会先将 key_part1 &gt;1000 and key_part2 &lt;2000 的数据查询出来，待取出的数据后再根据key_part2的条件进行过滤。如果有大量的数据是 key_part2 !&#x3D;1000，会严重降低查询性能。\n启用MRR优化：优化器会先将查询条件进行拆分，再进行数据查询。将查询条件拆分为(1000,1000),(1001,1000),(1002,1000),…,(1999,1000)，然后在根据这些拆分出的条件，使用索引下推进行数据查询，避免回表。\n应用实例2没开MRR时查询示意图\n\n由于 Mysql存储数据的方式：辅助索引的存储顺序并非与主键的顺序一致，从图中可以看出，根据辅助索引获取的主键来访问表中的数据会导致随机 IO，不同主键不在同一个page 里面时，必然导致多次 IO 和 随机读。 \n基于辅助索引的MRR查询策略第一步：先根据 where条件中的 辅助索引获取辅助索引与主键的集合，结果集为rest。\nselect key_column, pk_column from tb where key_column = x order by key_columnselect non_key_column fromtb where pk_column in ( rest_sort ) \n\n第二步：将结果集rest 放在buffer里面(read_rnd_buffer_size 大小直到buffer满了)，然后对结果集 rest按照pk_column排序得到结果集是rest_sort。\n第三步 利用已经排序过的结果集，访问表中的数据，此时是顺序IO。\n开MRR时查询示意图\n\n从图示MRR原理，Mysql将根据 辅助索引获取的结果集，根据主键进行排序，将乱序化为有序，可以用-主键顺序访问基表，将随机读转化为顺序读，多页数据记录可一次性读入或根据此次的主键范围分次读入，以减少IO操作，提高查询效率。\nMRR使用与否，是由 Mysql中的开关控制，只要设置开启，它会自动在 read_rnd_buffer_size 缓冲区内，对primaryKey进行排序。但这个开关并不是一直开着，因为对于大多数的单条查询，在中间添加一步排序，是对性能的损失，没有必要。\n4.大数据量下分页优化具体问题分页查询时，Mysql并不是跳过 offset 行，而是取 offset+N 行，然后放弃前 offset 行，返回 N 行，在取offset+N 行数据时，因为是select * … 操作，需要回表，查询到索引叶子节点数据，根据叶子节点上的主键值去主键索引上查询需要的全部字段值。当 offset 特别大时，此时使用 limit m,n 效率就非常低下，因为回表 M 行无用的数据，并且占用了大量的 buffer pool 缓存。 \n解决方案表 trade_info中有索引 idx_status_create_time(status, create_time)，等价于索引（status, create_time, id)\n对于深分页 limit m, n来说，越往后翻页越慢( m越大会越慢)。因为要定位 m位置需要扫描的数据越来越多，导致IO开销比较大。利用 辅助索引的索引覆盖，先获取id，不需要回表，然后通过 id 跟原表 trade_info进行关联。\nselect * from trade_info  where status = 0 and create_time &gt;= &#x27;2020-10-01 00:00:00&#x27; and create_time &lt;= &#x27;2020-10-07 23:59:59&#x27;order by id desc  limit 102120, 20; // 改写后的SQL如下： select * from trade_info a,      (select id from trade_info          where status = 0         and create_time &gt;= &#x27;2020-10-01 00:00:00&#x27; and create_time &lt;= &#x27;2020-10-07 23:59:59&#x27;        order by id desc limit 102120, 20) as b    //这一步走的是索引覆盖扫描，不需要回表 where a.id = b.id;// 2个表通过id做join操作，或者in select a.* from user a  inner join  (select id  from user where age = 10 LIMIT 100000,10) b  ON a.id = b.idselect * from userwhere id in (select id from user where age=10 limit 100000, 10);\n\n\n\n5.大数据下 In查询优化如果某张表包含100万条记录，要查找其中10万个ID匹配的记录，使用where in 语句可能比较慢。因为Mysql需要执行一个全表扫描，然后将表中每个记录 id 与where in语句中指定的每个 id 进行匹配，性能较低。\n为提高where in语句的性能，可以使用合适的索引来优化查询，或选择其他更合适的查询方式来实现相同的目的，比如使用JOIN或子查询等。\n具体问题如果mytable表很小，那么查询会非常快。但如果mytable表很大，该查询会变得非常慢，因为Mysql会扫描整个表来查找包含每个指定值的记录。如果您指定了大量值，则查询可能需要扫描整个表。\n解决方案1.创建索引：对mycolumn列创建索引，因为Mysql不需要扫描整个表来查找匹配的记录，而是只需扫描索引。\n2.使用子查询：将 IN子句替换为一个子查询可以显著提高查询性能。Mysql 需要扫描myothertable表来查找匹配的记录，而不需要扫描整个 mytable 表。\nselect * from mytable where mycolumn IN (1,2,3,4,5)select * from mytable where mycolumn IN     (select mycolumn from myothertable where condition)\n\n3.使用JOIN：JOIN语句可以将查询速度提高几倍，Mysql只需扫描mytable和myothertable表中的匹配记录，而不需要扫描整个表。\nselect * from mytable join myothertable ON mytable.mycolumn = myothertable.mycolumn where condition\n\n4.分批查询：将查询拆分成多个独立的查询，每次查询一部分数据，并使用 union 将结果组合在一起，这样可以降低加锁粒度，以提高查询性能。\nselect * from table where id in (100个id) union select * from table where id in (另外100个id)。\n\n\n\n\n\n","categories":["Mysql"],"tags":["Mysql"]},{"title":"Mysql底层原理","url":"/2025/05/11/A1-%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/","content":"BufferPool原理原理：对于数据的修改，Mysql不会直接去修改磁盘数据，这样做太慢了，Mysql会先记录 redo log，再改内存BufferPool，等空闲时再刷磁盘，查询时如果内存 BufferPool里没有数据就去磁盘 load；\nMysql以16KB「页」为读取和写入单位，一「页」里有多行数据，写数据时，Mysql会先写内存中的页，然后再刷新到磁盘。\n\n\n结构：BufferPool是以页(16kb)为元素的链表结构，基于LRU，和缓存一样，需要淘汰算法来管理数据；\n持久化： 宕机时，BufferPool会丢失数据（在内存中），需要重做 redo log； 执行时先写redo log, 再写BufferPool。\n\n\nChangeBuffer原理背景：Mysql查询数据时，如果内存里没有对应页的数据，会从磁盘里load；如果每次需要的页都不同（不是相邻的页），那每次都要去 load，效率会降低；\n原理：更新一个数据页时，如果数据页在内存中，就直接更新；但如果这个数据页没在内存中，InooDB会将这些更新操作缓存在 change buffer中，这样就不需要从磁盘读入这个数据页。在下次查询需要访问这个数据页时，再将数据页读入内存，执行change buffer中与这个页有关的操作，通过这种方式就能保证数据逻辑的正确性。\n使用条件：普通索引可以使用 Changebuffer，唯一索引（或主键）更新不能使用 change buffer，因为唯一索引更新操作要先判断这个操作 是否违反唯一性约束，判断表中是否存在这个数据，就必须要将数据页读入内存才能判断，已经读到内存中，直接更新内存会更快，就没必要使用change buffer。\n关系：change buffer 是 buffer pool里的内存，不能无限增大；\n使用场景适合：写多读少业务，在写完后马上被访问到的概率比较小，此时change buffer使用效果最好，业务模型常见：账单类，日志类的系统。\n不适合：读多写少（写入后马上会做查询）将更新先记录在change buffer，但由于马上要访问这个数据页，会立即触发merge操作，访问IO次数不会减少，反而增加 change buffer维护代价。\n优劣：数据库进行 Merge 时，是真正进行 数据更新的时刻，change buffer目的就是将记录的变更动作缓存下来，所以在一个数据页做merge前，change buffer 记录变更数越多（页面要更新的数据越多），收益就越大。\nmerge：ChangeBuffer –&gt; BufferPool\npurge（刷脏）: BufferPool –&gt; disk\n脏页：在更新之前，当内存数据页跟磁盘数据页内容不一致的时候\nFlush &lt;–&gt; purge过程将内存缓冲区BufferPool中的脏页写入磁盘，保障事务持久性\n触发条件：\n缓存池脏页比例超过阈值\n事务提交\nMySQL正常关闭，会把内存中的脏页都flush到磁盘上\n\nMerge触发条件\n访问这个数据页\n系统后台线程定期 merge\n数据库正常关闭（shutdown）过程中会执行merge\n\nMysql底层结构示意图\nDoublewriteBuffer原理在purge操作之前，Mysql会先把数据写到另外一个地方 DoubleWrite Buffer，写完后再开始写磁盘；Doublewrite Buffer是一个备份，当发生 crash时可以利用它来修复磁盘数据。\n\n刷数据之前宕机：内存—&gt; 磁盘，重做 redo log日志。\n刷数据时宕机：利用Doublewrite Buffer修复磁盘数据。\n\nMysql中数据存储各个“数据页(16K)”组成一个 双向链表，每个 数据页中的记录又组成一个 单向链表。每个数据页都会为存储记录 生成页目录，一个数据页内：主键查找，二分法快速定位 ； 其他非主键列查找，从最小记录开始依次遍历单链表。\n","categories":["Mysql"],"tags":["Mysql"]},{"title":"Mysql查询优化","url":"/2025/05/18/A1-%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/","content":"Explain查询语句分析主要字段含义\nselect_type：常用 SIMPLE 简单查询，UNION 联合查询，SUBQUERY子查询等\n\npossible_keys：可选择的索引 \n\nkey：实际使用的索引\n\nrows：扫描的行数  \n\n\ntype：索引查询类型，经常用到的索引查询类型\n\nconst：使用 主键或 唯一索引进行查询时，只有一行匹配\n\n**ref：使用 非唯一索引\n\nrange：使用“主键”、单个字段的辅助索引、多个字段的辅助索引的最后一个字段进行范围查询\n\nall：扫描全表\n\nindex：和 all 区别：只扫描索引树，查询字段是索引的一部分，使用主键进行排序\n\n\n\n\n查询优化技巧1.只返回必要的列&amp;行不要使用 SELECT * 语句，只返回必要的列；多使用  LIMIT 语句来限制返回的数据，只有一条数据实用 limit 1。\n2.多使用普通索引背景：写多读少，对唯一性要求不高或由业务代码来保证唯一性时，普通索引会使用Changebuffer，会把一些写操作缓存下来，在读取时做merge操作，以此避免频繁的磁盘操作。\n3.建立联合索引出现频率较高，常在一起作 where条件的字段，多考虑建立联合索引，减少建立索引的数量，并借助索引覆盖减少回表。\n4.开启 MRR（mult-range Read）此操作会在回表之前进行一个排序，把原来一个随机操作变成一个顺序操作。\n原理：根据辅助索引的叶子结点，找到主键值的集合，并存储到read_rnd_buffer中，在该buffer中对主键值进行排序，最后利用已经排序好的主键值集合，去访问表中数据，这样在第二次根据主键去回表时，由原来的随机&#x2F;O变为顺序I&#x2F;O，以提高查询速度。\n5.分解大连接查询将一个大连接查询分解成每一个表的单表查询，然后在业务代码中进行关联，优势：\n\n让缓存更高效：连接查询，如果一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然有效；\n减少锁的竞争：多表联接查询会锁住更多的数据，而在业务代码中进行关联，更容易对数据库进行拆分，加锁粒度降低，提高整体查询性能。\n\n6.分页查询优化\n控制返回的总页数； \n\n对超过特定阈值的页数进行 SQL 改写，借助主键 id 索引覆盖，对 where条件增加索引，并设置分页起始位置、页数。子查询只返回主键（不需要回表），外查询根据主键id值，直接定位到具体分页起始点。\n\nSELECT a.* \nFROM user a  \nINNER JOIN  \n    (SELECT id \n    FROM user \n    WHERE age = 10 LIMIT 100000,10) b  \nON a.id = b.id\n\n\n使用Redis 来保存lastMaxtId，下一次分页查询时直接拼接在 where 条件后边，直接跨过 offset 行数据。\n\n设置游标字段（订单号），分页查询时直接根据游标字段直接检索；\n\n\n7.索引字段调整索引选取越长，占用磁盘空间越大，相同数据页能放下的索引值就越少，增加B+树高度，搜索效率也会越低。\n1.短长度：把字段 hash为另外一个字段，缩小索引字段长度，保证hash后差异大\n2.高区分：通过函数处理增加索引区分度（倒序，删减字符等）\n如：身份证区域开头，同区域人很多，REVERSE() 函数翻转一下，提高区分度\n8.批量SQL优化\n在事务中进行插入处理\n\n​\t\t使用事务可以提高数据的插入效率，Mysql进行一个INSERT操作时，内部会建立一个事务，在事务内才进行插入操作。通过使用事务可以减少创建事务的消耗（类似线程池的思想），使得所有插入都执行后才进行提交。\n\n数据有序插入\n\n​\t\t插入记录在主键上是有序排列，由于数据库插入时，需要维护索引数据，有序插入可以有效降低索引B+tree的合并调整操作成本。如果每次插入记录都在索引的最后面，索引的定位效率很高，并且对索引调整较小；如果插入的记录在索引中间，需要B+tree进行分裂合并等处理，会消耗比较多计算资源，并且插入记录的索引定位效率会下降，数据量较大时会有频繁的磁盘操作。\n\n数据批量执行\n\n​\t\t批量执行更新sql语句的分析：\n情况一：mysql 默认autocommit＝on，默认开启自动提交事务。此时一条sql会开启一个事务，这时候同时执行一万条update，会导致实际开启一万个事务，然后一个个执行，挨个开启，挨个提交。\n缺点：同时锁住数据较少，但是数据库资源占用严重，对外提供操作性能下降。\n情况二：当autocommit＝off时，同时执行一万条update，只会开启一个事务，所有update语句一起commit。\n缺点：同时锁住数据较多，其他select查询进不来，大量连接等待获取行锁，也会影响数据库对外服务能力。\n最优方案：设置autocommit&#x3D;off，然后update时，手动分批commit，分批条数限制100，比如一万条update，按照每100条commit一次，1w个update总共需要100个事务，每次锁住100条数据，性能也会得到很大提升。\n","categories":["Mysql"],"tags":["Mysql"]},{"title":"Mysql索引","url":"/2025/05/04/A1-%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql%E7%B4%A2%E5%BC%95/","content":"InnoDB索引\n支持 事务、外键、行锁\n聚簇索引，叶子节点data域存行记录\n\nInnoDB采用 MVCC方式支持高并发，实现四个标准隔离级别(未提交读、已提交读、可重复读-默认、可串行化)。\n\n\n\n\n\n\n\n\nMyIsam索引\n不支持 事务，外键，行锁；   \n非聚簇索引，叶子节点data域中存引用地址；\n\n索引优缺点索引优点\n提高数据查询效率，降低数据库 IO成本；\n被索引的列会自动排序，包括单列索引&amp;组合索引，按照索引列排序，order by语句效率更高；\n\n索引缺点\n索引会占磁盘空间；\n索引会降低更新表的效率，每次对表增删改，不仅要更新数据，还要更新对应的索引；\n\n索引结构Hash :  不适合范围查找；无法用于排序与分组；\n二叉树：根节点的取值，容易导致 二叉树不分叉，降低查询效率；\n平衡二叉树：不支持 范围查询，范围查询时需要从根节点多次遍历，效率低；\nB树：\nB树不支持范围查询，在非叶子节点中也保存数据记录；\n每个节点的 data域存储 行记录，行的大小随着列数的增多而变大，这时页中可存储的数据量会变少，树结构会变高，磁盘IO次数就会变多；\n\nB+树结构：\n支持范围查询，只在叶子节点data域中存数据；且主键具备唯一性，不需再向后查找，&lt;&#x3D;终止；\nIO读取一页（默认16K）数据，数据存储在磁盘中，查询数据时，需要先把 磁盘中的数据加载到内存，磁盘IO操作很耗时，所以优化重点就是 尽量减少磁盘 IO 操作。B+树在非叶子中仅保存索引（不保存数据），相比B树存储同样多的数据，树的高度会更低，从而减少磁盘IO；\n\n各种索引主键索引主键索引 &#x3D;&#x3D; 聚簇索引，当一个表没有创建主键索引时，InnoDB会自动构建聚簇索引。\n\n在表上定义 主键 PRIMARY KEY，InnoDB 将 主键索引用作聚簇索引；                                                     \n如果表没有定义主键，InnoDB会选择 第一个不为NULL的唯一索引列  用作聚簇索引；\n以上两个都没有，会使用一个 6 字节长整型字段构建聚簇索引，该 ROWID字段会在插入新行时自动递增；\n\n辅助索引聚簇索引之外的所有其他索引。\n索引查询过程：非主键索引（辅助索引）的其他索引查询，需要先根据辅助索引B+树找到叶子节点data域中存储的主键索引，再根据主键索引找到实际数据。\n\n\n前缀索引定义字符串的一部分作为索引，如果创建索引的语句不指定前缀长度，索引默认包含整个字符串。\n优点：定义好长度可以做到节省空间，又不用额外增加太多的查询成本。\n注意：有前缀索引的联合索引一定会回表，虽然联合索引已包含相关信息，但还是会回表，因为有前缀索引，不确定到底是不是一个完整的信息。例如： www.aobing@mogu.com 一个完整的邮箱去查询，但无法判断后续是否有数据，不知道是否是完整的数据，所以需要回表去判断。\n联合索引联合索引设计原则\n频繁使用的列、区分度高的列放在前面；\n范围查询的列放在复合索引的最后面，例如 idx_status_create_time；\n将常需要作为 查询返回的字段，增加到联合索引中，通过联合索引上增加字段来使用覆盖索引；\n\n联合索引优势1.减少开销： 建联合索引(col1,col2,col3)，实际相当于建 (col1),(col1,col2),(col1,col2,col3)三个索引,每多一个索引，都会增加写操作的开销和磁盘空间的开销。对于大量数据的表，使用联合索引可以有效的减少开销！\n2.覆盖索引：联合索引通过遍历索引取得数据，无需回表，减少io操作，提升性能；\n3.效率高： 索引列越多，通过索引筛选出的数据越少。\n例如：有1000W条数据的表，有如下sql：select from table where col1&#x3D;1 and col2&#x3D;2 and col3&#x3D;3, 假设每个条件可以筛选出10%数据，如果只有单值索引，那么通过该索引能筛选出1000W10%&#x3D;100w条数据，然后再回表从 100w条数据中找到符合col2&#x3D;2 and col3&#x3D; 3的数据，然后再排序，再分页；\n如果是联合索引，通过索引筛选出1000w10% 10% *10%&#x3D;1w，效率明显提升。\n联合索引查询过程\n覆盖索引由多个字段组合成的联合索引，如：idx_abc(a,b,c)索引，在查询时，如果只需要 abc字段，则查询到联合索引的叶子节点就可以直接返回，不需要回表。\n注：Mysql优化器会根据联合索引字段位置，调整where 后边的查询条件，让其满足索引顺序。\n示例：创建 idx_abc(a,b,c)索引，相当于创建 (a)、（a,b）（a,b,c）三个索引，节省空间。在执行sql时，优化器会调整where后a,b,c的顺序，让其用上索引。\nSELECT * FROM table WHERE a IN (1,2,3) and b &gt; 1; 还是对(a，b)建立索引，因为 IN可视为等值引用，不会中止索引匹配，所以还是(a,b)SELECT * FROM table WHERE a &gt; 1 and b = 2 and c &gt; 3; (b,a)或者(b,c)都可以，要结合具体情况具体分析。select * from t where a=1 and b=1 and c =1;  #这样可以利用到定义的索引（a,b,c）,用上a,b,c select * from t where a=1 and b=1;           #这样可以利用到定义的索引（a,b,c）,用上a,b select * from t where b=1 and a=1;     #这样可以利用到定义的索引（a,b,c）,用上a,b（mysql有查询优化器） select * from t where a=1;             #这样也可以利用到定义的索引（a,b,c）,用上a select * from t where b=1 and c=1;     #这样不可以利用到定义的索引（a,b,c）； 最左 a 不匹配select * from t where a=1 and c=1;     #这样可以利用到定义的索引（a,b,c），但只用上a索引，b,c索引用不到 \n\n\n\n索引下推Mysql将部分过滤操作从Server层下推到存储引擎，减少数据访问层级和IO开销，在高并发或大数据量场景下效果显著。\n具体示例假设表中有100万行数据，索引为(name, age)\n\n无ICP：存储引擎返回所有 name&#x3D;’一灯’ 的1000条主键ID，Server层再筛选age&gt;20的100条，回表1000次。\n有ICP：存储引擎直接在索引中过滤 name&#x3D;’一灯’ AND age&gt;20，返回100条主键ID，回表100次，减少了900次无效回表和数据传输。\n\n最左匹配原则\n联合索引查询时，Mysql一直向右匹配，直至遇到范围查询 ( &gt;、&lt;、between、like ) 停止匹配。推荐使用联合索引替代多个单列索引使用。\n联合索引只有先确定前一个（左侧的值）后，才能确定下一个值。如果有范围查询，联合索引中使用范围查询的字段后的索引在该条 SQL 中都不会起作用。\n注意：in 和 &#x3D;  都可以乱序，比如有索引（a,b,c），语句 select * from t where c &#x3D;1 and a&#x3D;1 and b&#x3D;1，这样的语句也可以用到最左匹配，因为 MySQL优化器会分析 SQL 语句，将其优化成索引可以匹配的形式，即 select * from t where a &#x3D;1 and a&#x3D;1 and c&#x3D;1。\n\n索引设置建议\n尽量保持自增；\n差异性大的字段；\n出现频率高的字段，或常在where条件中出现的字段；\n小字段（减少所占用的空间）；\n\n破坏索引方式1.索引列 有函数运算\n2.索引列 有  !&#x3D;   &lt;&gt;    not in    not exist \n3.like 条件使索引生效，like后不能以%开头， like %字段名%、like %字段名 这类语句会使索引失效；\n4.字符型索引列；  \n5.隐式类型转换；\n示例：select * from t where id &#x3D; 1; 如果 id 是字符类型的，1是数字类型的，Mysql底层会对 比较进行转换，相当于加了 cast( id AS signed int ) 这样的函数，函数会导致走不上索引。 \n示例：FROM_UNIXTIME(create_time) &#x3D; ‘2016-06-06’ ，不会使用索引，B+树中存储的都是数据表中的字段值，但是进行检索时，需要把所有元素都应用函数才能比较；\n优化：create_time &#x3D; UNIX_TIMESTAMP(‘2016-06-06’)；\n","categories":["Mysql"],"tags":["Mysql"]},{"title":"Kafka性能优化","url":"/2025/06/08/A2-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/","content":"Kafka性能优化性能问题主要是三个方面：网络、磁盘、复杂度；\nKafka从以下六个方面来对性能进行优化。\n1.顺序IO读写磁盘一次读写磁盘IO需要经过 寻道、旋转、数据传输三个步骤，Kafka 采用顺序写文件的方式来提高磁盘写入性能，减少了磁盘寻道和旋转的操作。\nKafka每个分区是一个有序的，不可变的消息序列，新消息不断追加到 Partition末尾，Partition 只是一个逻辑概念，将 Partition划分为多个Segment，每个Segment对应一个物理文件，对 segment文件追加写入就是顺序写文件。 \n\n\n2.零拷贝网络和磁盘传统 IO流程，需要先读取网络IO，再写入磁盘IO，实际需要将数据 Copy 四次。\n\n\n主要流程\n读取 磁盘文件 到 操作系统 内核缓冲区； DMA搬运\n将 内核缓冲区数据，copy 到应用程序的 buffer； CPU \n将 应用程序 buffer中的数据，copy 到socket buffer (网络发送缓冲区);  CPU \n将 socket buffer数据，copy 到网卡，由网卡进行网络传输。  DMA\n\n总结：磁盘 —&gt; 内核 buf—&gt; 用户 buf—&gt; Socket buf—&gt; 网卡\n零拷贝：内核 buf —&gt; Socket buf —&gt; 网卡\n期间共发生 4次用户态与内核态的上下文切换，发生两次系统调用，一次是 read() ，一次是 write()，每次系统调用都得先从用户态切换到内核态，等内核完成任务后，再从内核态切换回用户态。一次上下文切换需要耗时几十纳秒到几微秒。这个过程中，存在冗余的上下文切换，要想提高文件传输的性能，就需要减少「用户态与内核态的上下文切换」和「内存拷贝」次数。\n零拷贝实现零拷贝：主要用来解决操作系统在处理 I&#x2F;O操作时，频繁复制数据的问题。实现上下文切换数量减少一倍，只有 2次copy，只有DMA进行数据搬运，而不需要CPU。\n\n\n零拷贝实现：上下文切换数量减少一倍，只有 2次copy，只有DMA进行数据搬运，而不需要CPU。\n第一次通过DMA：从 磁盘 —&gt; 内核读缓冲区\n第二次根据 Socket描述符信息，使用 DMA直接从 内核缓冲区—&gt;写入到 网卡缓冲区 \n零拷贝是尽量去减少上面数据的拷贝次数，CPU开销，减少用户态&lt;—&gt;内核态的上下文切换次数，从而优化数据传输的性能。同一份数据传输次数从 四次变成两次，并且没有通过 CPU进行数据搬运，所有的数据都是通过 DMA进行传输。没有在内存层面去复制数据，所以这个方法被称为零拷贝。 \nDMA（Direct Memory Access）技术在主板上放⼀块独立芯片，进行 内存 和 I&#x2F;O设备数据传输 时，不再通过 CPU 控制数据传输，而直接通过 DMA控制器，传统的从硬盘读取数据，然后再通过 网卡向外发送，需要进行四次数据传输，其中有两次是发生在内存里的缓冲区和对应的硬件设备之间，没法节省掉。但是还有两次，完全是通过 CPU在内存里面进行数据复制。\n在 Kafka里，通过 Java的 NIO里面 FileChannel的 transferTo方法调用，可以不用把 数据复制到应用程序的内存里面。通过DMA方式可以把 数据从内存缓冲区 直接写到 网卡的缓冲****区里面。\nDMAC就是一个 协处理器芯片，通过这个芯片，CPU 只需要告诉 DMAC，要 传输什么数据，从哪里来，到哪里去，就可以放心离开了。后续数据传输工作都会由DMAC 来完成。随着现代计算机各种外设硬件越来越多， 光一个通用的 DMAC 芯片不够了，在各个外设上都加上了 DMAC 芯片，使得 CPU 很少再需要关心数据传输的工作。\n\n\nPageCache应用\n缓存最近被访问的数据 \n预读功能\n\n如果 producer 生产与 consumer消费 速度差不多，可以只对 broker page cache 读写来完成整个生产-消费过程，磁盘访问非常少，producer 生产消息到 Broker ，Broker 按偏移量写入数据，此时数据会先写入 page cache内存区域。consumer 消费消息时，Broker 将数据从  page cache 传输到 Socket buffer，再将 Socket Buffer的数据 copy到网卡，由网卡进行网络传输。 page cache数据会随着内核中 flusher 线程的调度写回到磁盘，不用担心数据丢失。如果 consumer要消费的消息不在page cache里，再去磁盘读取。\n\n\n\n\n3.批量发送与压缩Producer 向 Broker发送消息不是一条一条发送， 而是批量发送，将消息缓存在本地，等到一定条件时发送再发送到Broker。\n具体条件：****1、消息条数；  2、固定一段时间\nProducer 执行流程如图：\n\n\n\nSerialize：序列化传递的消息 (序列化后可提高网络传输效率)\nCompress：压缩消息，提高传输速度、吞吐量，降低延迟并提高磁盘利用率\nAccumulate：消息累计器，每个 Partition维护一个双端队列，队列保存将要发送的批次数据，Accumulate将数据累计到一定数量，或在一定时间内将数据以批次的方式发送出去，主题中每个分区都有一个单独的累加器 &#x2F; 缓冲区。\n\n压缩的作用：减少传输的数据量，减轻对网络的传输压力\nProducer、Broker、Consumer 使用相同的压缩算法， producer 向 Broker 写入数据，Consumer 向 Broker 读取数据时不用解压缩，当消息发送到Consumer 后才解压，这样将  节省大量网络开销。Producer 压缩之后，Consumer 需进行解压，虽然增加 CPU的工作，但在对大数据处理上，瓶颈在网络而不是CPU，所以这个成本是值得的\n注意：「批量发送」+「数据压缩」一起使用，单条做数据压缩的话，效果不明显。\n4.Partition 并行&amp;可扩展1.提高消费并发度：每个 Partition是一个队列，同一个 Group下不同 Consumer并发消费 Paritition，Paritition分区是并行度最小单元，每增加一个 Paritition就增加一个消费并发。 Kafka具有分区分配算法—StickyAssignor，保证分配尽量均衡，每次重分配结果尽量与上一次分配结果保持一致，各个Broker和Consumer处理不至于出现太大倾斜。\n\n\n多Partition缺点\n1.客户端&#x2F;服务端 需要使用更多内存：客户端 producer有个参数 batch.size，默认是 16KB。它会为每个分区缓存消息，一旦满了就打包将消息批量发出。因为这个参数是分区级别，如果分区数量变多，则缓存所需内存也会变得更多。\n2.恢复数据慢：分区越多，每个 Broker上分配的分区也会越多，当发生 Broker 宕机，则恢复时间将会更长。\n5.高效的文件数据结构消息以 Topic为单位进行归类，各个Topic之间彼此独立，互不影响。每个 Topic可以分为一个或多个分区，每个分区各自存在一个记录消息数据的日志文件，每个分区日志在物理上按大小被分成多个 Segment。\n\n\nsegment file 组成： index file 和 data file， 2 个文件一一对应，成对出现（索引文件 .index ，数据文件 .log）partition 全局的第一个 segment 从 0 开始，后续每个 segment 文件名为上一个 segment 文件最后一条消息的 offset 值。\nindex 采用稀疏索引，每个 index文件大小有限。Kafka 采用 mmap方式，将 index文件映射到内存，这样对 index 就不需要操作磁盘 IO。\nMmap(Memory Mapped Files) 内存映射文件方法文件磁盘地址 和 进程虚拟地址空间中一段虚拟地址 一一对映关系，实现这样的映射关系后，进程可以采用指针的方式读写操作这段内存，而系统会自动回写脏页到对应的文件磁盘上，即对文件进行操作，不必调用 read、write 等系统调用函数。相反，内核空间对这段区域的修改也直接反映用户空间，从而实现不同进程间的文件共享。\nmmap将磁盘文件映射到内存，用户通过修改内存达到修改磁盘文件的效果。接收来自socket buffer的网络数据，应用进程不需要中间处理、直接进行持久化。\n原理：直接利用操作系统的 Page来实现文件到物理内存的直接映射，完成映射后对物理内存的操作会被同步到硬盘上。 通过 mmap 进程像读写硬盘一样读写内存（虚拟机内存），省去了用户空间到 内核空间复制的开销。  \nmmap缺点：不可靠，写到 mmap中的数据并没有被真正的写到硬盘，操作系统会在程序主动调用 flush的时候才把数据真正的写到硬盘。 \n6.优秀的网络模型（基于JavaNIO）Kafka 底层基于Java NIO，采用Reactor 线程模型，做的网络模型 RPC。\nReactor线程模型传统阻塞 IO模型问题1.每个连接需要 独立线程处理，当并发数大时，创建线程数多，占用资源；\n2.采用阻塞IO模型，连接建立后，若当前线程没有数据可读，线程会阻塞在读操作上，造成资源浪费；\n\n\nReactor 线程模型解决方案：基于IO复用 + 线程池\n\n基于 IO复用模型：多个连接共用同一个阻塞对象，不用等待所有连接，遍历到有新数据可以处理时，操作系统会通知程序，线程跳出阻塞状态，进行业务逻辑处理；\n基于线程池：避免为每个连接创建线程，连接完成后将业务处理交给线程池处理；\n\n实现原理：Reactor模型将所有要处理的 IO 事件注册到一个中心 I&#x2F;O多路复用器上，同时主线程&#x2F;进程阻塞在多路复用器上，一旦有 I&#x2F;O 事件到来或准备就绪 (文件描述符或 socket 可读&#x2F;写)，多路复用器返回并将事先注册的相应 I&#x2F;O 事件分发到对应的处理器中。Reactor 利用事件驱动机制实现，应用程序需提供相应接口，并注册到Reactor上，如果相应事件发生，Reactor将主动调用应用程序注册的接口。\n\n\nReactor模型主要分为三个角色\nReactor：把 IO事件分配给对应的 handler处理\nAcceptor：处理客户端连接事件，Acceptor线程用于处理新的连接\nHandler：处理非阻塞的任务，Handler线程处理业务逻辑；\n\nI&#x2F;O 多路复用可以把多个 I&#x2F;O阻塞，复用到同一个 select阻塞上，从而使得系统在单线程情况下，可以同时处理多个客户端请求，不需要创建新的线程，降低系统的资源开销。\n7.二分法查找对应 offset位置具体查询过程\n按照二分法找到小于offset的 segment 的.log 和.index；\n用目标 offset减去文件名中的 offset得到消息在这个 segment 中的偏移量；\n再次用二分法在 index 文件中找到对应的索引；\n到 log文件中，顺序查找直到找到 offset对应的消息；\n\n","categories":["消息队列MQ"],"tags":["消息队列MQ"]},{"title":"Redis基本数据结构","url":"/2025/06/15/A3-%E7%BC%93%E5%AD%98/A1-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","content":"String 结构具体结构：动态字符串，类型ArrayList，可以实现动态扩容\n1.保存数据 size，能够根据当前空间大小判断，避免存储字符串遭遇截断；\n2.空间预分配，实际存储一个对象，预先多分片free空间，避免频繁分配空间；\n3.惰性空间删除，删除对象后，空间不会立刻回收，避免再次添加数据；\n \n\nSDS与C字符串区别1.计数方式不同C字符串使用长度为 N+1 的字符数组来表示长度为 N 的字符串，字符数组最后一个元素 ’\\0‘，每次都需要遍历一遍整个数组来获取字符串长度 O(N) ；\nSDS结构自己保存 长度信息；\n2.避免缓冲区溢出C字符串在拼接或缩短操作时，可能会出现 缓冲区溢出&#x2F;内存泄漏问题。\n示例：需要在后面拼接时，但没计算好内存，结果可能因内存不足，被意外修改；\nSDS 结构存储当前长度+ free未使用长度，在做拼接操作时，会判断是否能够存下，如果长度足够直接执行，如果 不够则进行扩容。\n\n\n3.减少内存重分配次数对字符串进行频繁拼接和截断操作，在写代码时忘记重新分配内存，则可能造成缓冲区溢出，以及内存泄露等问题。\n空间预分配：SDS进行扩展操作时，Redis会为 SDS分配好内存，根据指定的计算方式分配多余的 free空间，再继续拼接时，备用的 free空间会使用上，省去这次的内存重分配，优化了内存分配的消耗。\n\n\n4.惰性空间释放当执行完一个字符串缩减操作，为防止后续继续添加，redis并不会马上收回空间。当再次操作还没用到多余空间时，Redis才会收回多余空间，防止内存浪费，如果继续添加，则这个空间就能用上，从而减少内存的重分配。\n\n\n5.二进制安全C字符串必须符合ASCII码的编码格式，中间出现 ‘\\0’ 会被判定为提前结束，因此只能保存文本数据；\nRedis保存字符串长度，不判断空字符而是判断长度， 所以保存各种二进制数据，更加安全；\n\n\n\n\nList结构具体结构\n在数据量不大时（元素数量&lt;512），使用ziplist结构，申请一片连续空间，压缩列表。ziplist是一块连续的内存地址，他们之间无需持有前后指针，能通过地址顺序寻址访问；类似一个数组结构；\n元素数量&gt; 512时，使用LinkedList 结构，是普通的双写链表，有前后指针。目标：减少每个元素增加前、后指针带来的内存消耗，也减少内存碎片化问题。\n\n应用场景：消息队列\n\n\n\n\nHash具体结构数组 + 链表，类似Java的HashMap，链地址法来解决哈希冲突，初始容量 16，2倍扩容；\nht[0]用于存放真实 key-vlaue数据； ht[1]用于扩容(rehash)；\nRedis中哈希算法和哈希冲突跟Java实现类似，差异点：Redis哈希冲突，链表头插法；JDK1.8后Java哈希冲突，链表尾插法；\n渐进式 (rehash)背景原因\nHash扩容比较耗时，需要重新申请新数组，然后将旧字典链表中的元素重新挂接到新数组O(n)，作为单线程Redis很难承受这样耗时过程；\n数据量如果过大的话，一次性rehash会有庞大的计算量，这可能导致服务器一段时间内停止服务，所以使用渐进式实现小步搬迁。\n\n具体过程rehash时保留新旧两个 hash结构；\n\n查询时先查新hash，没有再查旧hash，并搬迁至新hash;  \n增加直接加到新hash;  \n修改先改新hash，没有改旧hash，然后删除hash搬迁至新hash；\n删除先删新hash，没有再删旧hash；\n\n例如要查找一个键的话，会优先查找ht[0]，如果不存在，再查找ht[1]。此外当执行新增操作时，新的键值对**一律保存到ht[1]**，不再对ht[0]进行任何操作，以保证ht[0]的键值对数量只减不增，直至变为空表。\n扩容条件\nhash表元素个数 &#x3D;&#x3D; 数组.size() 2 倍；\n如果Redis 正在做 bgsave(持久化命令)，为减少内存，尽量不去扩容；但如果 hash表非常满，达到数组长度 5 倍，这时就会强制扩容；\n\n缩容条件hash 表中元素个数 &lt;  数组.size() * 10% ，缩容不会考虑 是否在做 bgsave；\n对哈希表进行扩展&amp;收缩操作时，reash过程并不是一次性完成的，而是 渐进式地完成。\nSet具体结构：键值对无序、唯一，类似Java 的HashSet，内部的键值对是无序、唯一，在 HashMap基础上对所有 value &#x3D; NULL，拥有去重功能；\nSortedSet(zset)具体结构：ziplist  |  跳表(skiplist)； zset按照指定排序规则对输入字段进行排序，支持随机插入、删除； \n应用场景：排行榜\nziplist结构redis为节约内存而设计开发的数据结构ziplist，它是由一系列特殊编码的连续内存块组成的顺序型数据结构。一个压缩列表可以包含任意多个节点（entry），每个节点可以保存一个字节数组或一个整数值。\n使用条件\n有序集合保存的元素 数量 &lt; 128个\n有序集合保存的所有元素的长度 &lt; 64字节\n\n\n\nskiplist结构每个节点随机出一个层数(level)，示例：一个节点随机出层数 3，把它链入到 第 1 层到第 3 层这三层链表中；每一个节点的层数（level）是随机出来的，而且新插入一个节点并不会影响到其他节点的层数。插入操作只需要 修改节点前后的指针，而不需要对多个节点都进行调整，这就降低插入操作的复杂度。 \n\n\n示例：查找 23 这个不存在的数其查找路径为：\n\n\n看似是一个支持 二分查找的有序链表，在有序链表上面增加多级索引，通过索引实现快速查找。跳表不仅能提高搜索性能，同时也可以提高插入和删除操作的性能。\n1.插入、查询时间复杂度O(logn)\n2.数据天然有序\n3.链表结构，比树结构简单，性能更高；\n每个节点都有第一层指针，节点有第i层指针，那么第i+1层出现的概率为p，节点有最大层数限制 MaxLevel(32)。\n\n\nSkip List包含多个层，每层称为一个level，level从 0开始递增。0层是最底层，包含所有的元素；每一个 level层都是一个有序的列表，level小的层包含 level大的层的元素；\n每个节点元素：1.节点key、2.节点value 、3.指向当前节点 level 指针\n随机层数新插入节点，需要调用一个随机算法分配一个合理的层数；\n期望目标是 50% 概率被分配 Level 1； 25% 的概率被分配到 Level 2； 12.5% 的概率被分配到 Level 3，以此类推…有 2^(-63) 的概率被分配到最顶层，因为每一层的晋升率都是 50%，默认允许 最大的层数是 32，当 Level[0] 有 264 个元素时，才能达到 32 层。\n插入节点：找到当前需要插入位置（包括相同 score 时的处理），创建新节点，调整前后指针指向，完成插入；\n节点删除：先找”搜索路径”，然后对每层的相关节点重排一下前向后向指针，同时更新最高层数 maxLevel；\n节点更新：如果对应 value 不存在就是插入过程；\n\n如果这个value 已经存在，调整一下 score值；\n如果新 score 值并不会带来排序上的变化，那就不需要调整位置，直接修改元素的score 值；\n如果排序位置改变，就需要调整位置，把这个元素删除再插入，需要经过两次路径搜索，调整顺序先删再插；\n\n元素排名跳跃表是有序的，skiplist为每一个 forward 指针都增加 span 属性，表示从前一个节点沿着当前层的forward 指针跳到当前这个节点 中间会跳过多少个节点。在 插入&#x2F;删除操作时，会更新 span值，所以沿着 “搜索路径”把所有经过节点的 跨度 span 值累加，就可以算出当前元素的最终 rank 值。极端情况，跳跃表中所有 score 值都是一样，zset的查找性能会退化为 O(n)；\n平衡树&amp;红黑树结构问题\n\n性能问题：高并发情况下树结构需要执行rebalance 操作，可能涉及整棵树调整，跳跃表的变化只涉及局部；\n实现成本：在复杂度与红黑树相同的情况，跳跃表实现起来更简单；\n\nBitMap位图具体结构：bitMap位图是一个由二进制位组成的数组，数组每个单元只能存储 0和1；\n\n\n应用场景1.布隆过滤器（缓存穿透）\n2.统计网页 PV &amp; UV数据，考虑使用 BitMap、HyperLogLog\n具体使用：将数组中每个 二进制位与用户 ID 一一对应，使用位图记录每个用户当日是否访问，存储 1 的个数是UV数量。以当天日期加固定前缀作为key，建立一个Bitmap，每一位二进制 offset做为一个用户 ID标识，当今天用户访问时就将Bitmap中标识此用户的二进制位从0置为1，最后统计所有bitmap 中 1 的个数，即为独立访客数量。\nset 集合统计问题：当数量庞大时，需要存储的 set集合会非常大，去重功能将耗费较高的时间复杂度，影响性能；\n","categories":["Redis缓存"],"tags":["Redis缓存"]},{"title":"缓存扩展属性","url":"/2025/07/13/A3-%E7%BC%93%E5%AD%98/A3-%E7%BC%93%E5%AD%98%E6%89%A9%E5%B1%95%E5%B1%9E%E6%80%A7/","content":"Redis缓存特点\n速度非常快\n支持丰富的数据类型 \n操作具有原子性，单线程\n\n \n\nRedis速度快原因\n数据结构简单，操作时间复杂度低；\n单线程，没有多线程来回切换的开销，避免不必要的上下文切换和锁竞争；\n所有操作都基于内存；\n多路I&#x2F;O复用模型，非阻塞IO；\n\nRedis高可用方式\n事前：Redis 高可用，主从+哨兵，避免全盘崩溃 \n事中： 本地 LocalCache 缓存 + Hystrix 限流+降级，避免MySQL被打死 \n事后： Redis 持久化 RDB+AOF，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据\n\nRedis中 IO多路复用Redis 线程不会阻塞在某一个特定的客户端请求处理上，可以同时和多个客户端连接并处理请求，从而提升并发性。因为redis底层使用 epoll 作为 I&#x2F;O 多路复用技术的实现。\nepoll 使用 一个 文件管理多个文件描述符，将每个文件描述符的事件存放在 内核的一个事件表 中，仅需在初始阶段，从用户空间到 内核空间 copy一次。epoll 使用 “事件”就绪通知的方式，为每个文件描述符指定一个回调函数，当处于就绪状态时，通过回调函数唤醒 等待队列上的等待者。相比：select、poll 方式，不需要每次调用时，从用户空间copy 文件描述符到内核空间，也不需要遍历全部的文件描述符来查找就绪的对象。\n布隆过滤器(Bloom Filter)实现方式：一个元素被加入到集合时，通过  K个散列函数 将这个元素映射成一个 位数组中的K个点，把它们置为1，检索时只要看这些点是不是为 1，就知道集合中有没有它。如果这些点有任何一个 0，则被检元素一定不在；如果都是1，则被检元素很可能在。\n布隆过滤器应用场景\n缓存穿透\n海量数据去重\n\n布隆过滤器和BitMap结构区别布隆过滤器：使用 k个哈希函数，每个字符串跟 k个bit对应，降低冲突概率；\nBitMap 只有一个hash函数，冲突率较高；\n\n\n存在的问题1.可能存在误判hash后得到的  k个位置上值都是1，但可能此值不存在；\n解决方案：通过建立一个 白名单来存储可能会误判的元素；\n2.删除困难一个放入容器的元素映射到 bit数组的k个位置上是1，删除的时候不能直接置为0，可能会影响其他元素的判断；   \n解决方案：采用Counting Bloom Filter；\nRedis分布式锁具体应用：常规锁只能适用于单机，对于分布式架构无法保证；\n分布式锁问题1.锁超时如果有两台服务 A B，其中 A 服务在 获取锁之后，由于某种原因突然挂了，那么B 服务就永远无法获取到锁；需要额外设置一个超时时间，来保证服务的可用性。如果加锁，释放锁之间的逻辑执行太长，以至于超出锁的超时限制，也会出现问题。\n解决方案：为避免这个问题，Redis分布式锁不要用于较长时间的任务；\n2.其他线程释放锁如果第一个线程加锁后，第二个线程重新上锁，结果第一个线程执行后，可能会释放第二个线程的锁；\n解决方案：标记版本号，将锁 value 值设置为一个随机数，释放锁时先匹配随机数是否一致，然后再删除 key，确保当前线程占有的锁不会被其他线程释放，除非这个锁是因为过期而被服务器自动释放的；\n3.删除-解锁方式问题如果过期释放锁后，其他线程重新获取，直接 del解锁，会删除别人建立的锁；\n解决方案：通过 lua脚本，Lua脚本可以保证多个指令的原子性执行。先进行 get，再进行 del； 外加token(一个随机数)字段，当加锁时往redis的 my:lock中存这个token，解锁时先 get一下lock中的token，如果和要删除的 token一致，说明这个锁是之前set的，否则说明这个锁已经过期，是别人set的。\n设置过期时间方式setnx 是 SET if Not exists；设置过期时间：EXPIRE name  5，EXPIRE 命令依赖于 SETNX 执行结果，而事务中没有 if-else 分支逻辑，如果 SETNX没有抢到锁，EXPIRE就不应该执行。加入SET 指令扩展参数，使 SETNX 和 EXPIRE指令一起执行：\nSET key value [EX seconds | PX milliseconds] [NX | XX] [KEEPTTL]\n\n\n\nRedis集群结构当数据量很大时，需要对 Redis进行分库分表操作。在做缓存集群时，为缓解服务器压力，会部署多台缓存服务器，把数据资源通过hash算法均匀的分配到每个服务器上，分布式数据库首先要解决把整个数据集按照分区规则映射到多个节点，即把数据集划分到多个节点上，每个节点负责整体数据的一个子集。\n\n\nHash算法问题Hash算法路由时会出现一些缺陷，在服务器数量变动时，所有缓存位置都要发生改变！例如：原本  hash(a.png) % 4 &#x3D; 2 变成 hash(a.png) % 5 &#x3D; ？，当服务器数量发生改变时，所有缓存在一定时间内是失效的。\n一致性Hash算法1.hash取模一致性Hash算法对 2^32 取模，将整个哈希值空间组织成一个虚拟的圆环，可以选择服务器IP或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置。\n2.定位位置将数据 key使用相同的函数计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其定位到的服务器。\n\n\n3.容错性（删除节点）假设Node C不幸宕机，只有C对象被重定位到节点 D。受影响的数据仅仅是此服务器到其环空间中其前的一台服务器（顺时针）之间数据，其它不会受到影响。\n4.扩展性（增加节点）如果在系统中增加一台服务器Node X，此时对象A，B，D不受影响，只有对象C需要重定位到新的Node X。增加一台服务器则受影响的数据是新服务器到其环空间中前一台服务器之间的数据，其它数据也不会受到影响。\n\n\nHash环数据倾斜问题一致性Hash算法在服务节点太少时，容易因节点分布不均匀而造成数据倾斜，缓存对象大部分集中缓存在某一台服务器上。\n解决方案引入虚拟节点：对每一个服务节点计算多个哈希值，每个计算结果位置都放置一个此服务节点，称为虚拟节点。具体做法可以在服务器IP或主机名的后面增加编号来实现。\n例如：为每台服务器计算三个虚拟节点，分别计算 “Node A#1”，“Node A#2”，“Node A#3”，“Node B#1”，“Node B#2”，“Node B#3”  哈希值，于是形成六个虚拟节点：\n\n\n将虚拟节点做为中间变量，再从虚拟节点映射到实际节点，实现数据映射。同时数据定位算法不变，只是多一步虚拟节点到实际节点的映射。\n例如：定位到“Node A#1”，“Node A#2”，“Node A#3”，三个虚拟节点的数据均定位到Node A上，这样就解决了服务节点少时数据倾斜的问题，在实际应用中，通常将虚拟节点数设置为32甚至更大，因此即使很少的服务节点也能做到相对均匀的数据分布。\n","categories":["Redis缓存"],"tags":["Redis缓存"]},{"title":"缓存常见问题","url":"/2025/06/22/A3-%E7%BC%93%E5%AD%98/A4-%E7%BC%93%E5%AD%98%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/","content":"缓存穿透原因缓存和数据库 中都没有的数据，而用户不断发起请求，导致请求不走缓存直接访问到数据库，数据库压力过大；\n通常都是请求参数非法导致的 (例如 id&#x3D;-1)\n \n\n解决方式1.接口层增加校验，比如 用户鉴权校验，参数做校验；\n2.缓存中取不到，数据库中也没有取到，此时将对应Key的Value 改写：{ null、位置错误、稍后重试 }；\n3.布隆过滤器（Bloom Filter）：利用bitMap结构和hash算法，判断出这个Key是否在数据库中存在，不存在 return，存在再去查 DB，然后更新KV；\n缓存击穿原因一个热点 Key，扛着高并发，当这个Key在失效瞬间，持续的高并发击穿缓存，直接请求到数据库；\n解决方式1.设置 热点数据永远不过期；\n2.加上互斥锁，保证 同一进程中对同一数据，不会并发请求到DB\n缓存雪崩原因同一时间多个热点 Key值大面积失效，导致同一时间内大量请求访问到DB；\n解决方式1.把每个 Key失效时间都加个随机值，保证 数据不会在同一时间大面积失效；\n2.设置 热点数据永远不过期；\n3.将 多个热点数据 均匀分布在不同的Redis库中；\n4.使用主从、集群模型，提高缓存服务的高可用；\nRedis过期策略1.惰性删除不主动删，等到查询到key时，看看有没有过期，如果过期就删除！\n2.定期删除默认100ms 随机抽一些设置了过期时间的key，去检查是否过期，如果过期了就删除；\n存在问题如果一直没随机到一些key，那里面就会存在大量的无效key！\n解决-内存淘汰策略1.noeviction:  永不删除\n2.allkeys-random:  无过期时间的数据，随机删除一部分\n3.allkeys-lru: 无过期时间的数据，删除 最近最少使用的（LRU）\n4.volatile-random:  设置过期时间的数据，随机删除一部分\n5.volatile-lru: 有过期时间的数据，删除最近最少使用的（LRU）\n6.volatile-ttl: 有过期时间的数据，删除 剩余时间最短的（TTL）\n","categories":["Redis缓存"],"tags":["Redis缓存"]},{"title":"Redis持久化&集群","url":"/2025/06/19/A3-%E7%BC%93%E5%AD%98/A2-Redis%E6%8C%81%E4%B9%85%E5%8C%96/","content":"持久化一、RDB快照持久化具体方式根据指定时间内改变 key数量来做持久化（冷备）；\n父进程调用 fork函数产生一个子进程 做数据持久化，不修改现有的内存数据结构，只是对数据结构进行遍历读取，然后序列化写到磁盘中。快照持久化 完全交给 子进程处理，父进程继续处理客户端请求，然后对内存数据结构进行不间断的修改。\n原理：使用操作系统的 COW 机制进行 数据段页面 分离，父进程对其中一个页面的数据进行修改时，将被共享的页面复制一份，并分离出来，然后对这个复制的页面进行修改。这时子进程相应的页面是 没有变化的，是一个快照的数据，然后子进程就可以遍历数据进行序列化写磁盘了。\n \n\nRDB优点\n性能影响小，网络传输快\n数据恢复速度快\n文件小\n\nRDB 缺点\n无法实时同步（无法同步增量数据），停机时会导致大量丢失数据\n兼容性差（文件需要满足指定格式）\n\n二、AOF(Append Only File)持久化具体方式记录所有对内存数据的写操作，在持久化恢复时「重放」所有修改性指令序列，恢复 Redis当前实例的内存数据结构。\nAOF 是 先执行指令再将日志存盘****，如果先写日志再操作的话，AOF日志中会出现 很多无效&#x2F;错误的命令记录，对本来就庞大的AOF文件来说就是雪上加霜；\nAOF 文件采用追加写的方式，避免IO 的随机寻址，优化磁盘写入性能；\nAOF优点\n实时持久化，可以做到秒级更新（1次&#x2F;s 通过线程 fsync操作，最多丢 1s数据）；\n文件兼容性好，不需要指定格式；\n\nAOF缺点\nAOF 文件大；\n恢复数据时需要重新执行写操作，对系统性能影响大，且恢复速度较慢；\n\nAOF日志重写原因：Redis在长期运行过程中，AOF日志会越来越大，如果宕机重启，需要重放整个AOF日志，非常耗时，所以需要对AOF日志进行“瘦身”处理。\n工作原理父进程开辟一个子进程，由子进程对内存中的 redis数据库进行遍历，转换成一系列 Redis操作指令，序列化到一个新的 AOF日志文件中，序列化完毕后，再将 操作期间发生的 增量AOF日志追加到这个新的 AOF日志文件中，立即替代旧的AOF 日志文件。\nRedis出现事故第一时间用 RDB恢复，然后AOF做数据补全，冷备热备一起用。\n突然机器宕机&#x2F;掉电取决于 AOF日志sync属性配置，如果不要求性能，在每条写指令时都sync一下磁盘，就不会丢失数据。但是在高性能的要求下每次都 sync是不现实的，一般都使用定时sync，比如：1次&#x2F;s，这个时候最多丢失1s数据\n主从复制模型具体过程1.RDB持久化第一次同步时，主节点做一次RDB持久化，并同时将后续修改操作记录到 内存buffer；\n2.复制RDB文件完成后将 RDB快照文件 全量同步到从节点，然后从节点将RDB镜像加载到内存；\n3.同步buffer数据加载完成后，再通知主节点将此期间内修改的操作记录发送过来，从节点重放这些操作；\n4.增量AOF日志同步后续的增量数据通过AOF日志同步；\n总结：主从复制模型：同时使用 RDB、AOF持久化操作，RDB快照数据生成时，缓存区也同时开始接受新请求，来保存同步期间的增量数据；\n优点高可用，提高数据读的负载能力\n缺点master 主节点故障，无法实现自动故障恢复 \n\n\n\n\n哨兵模型哨兵模型中 slaver节点间相互监听，若有故障随时替换，自动故障恢复；\n\n\n故障恢复过程1.心跳检测每个 Sentinal 节点  1次&#x2F;s 向它所关联的 主、从、其他Sentinal节点发送 ping命令；\n2.主观下线如果一个节点没有回复 ping 命令或超时，将被Sentinal 节点标记为 主观下线；\n3.客观下线如果主节点被标记主观下线，与主节点相连的其他Sentinal 节点也监测主节点，当达到一定数量的Sentinal 节点都认为主节点下线了，主节点被标记为客观下线；  \n4.选举领导哨兵节点当主节点被判断为客观下线后，其他Sentinal 节点会进行协商，选举一个领导哨兵节点，并由该领导节点对其进行故障转移操作；\n监听该主节点的所有哨兵，都有可能被选为领导者，选举算法是 先到先得：即在一轮选举中，哨兵 A 向 B 发送成为领导者的申请，如果B没有同意过其他哨兵，则会同意A成为领导者。 \n5.故障转移选举出的领导者哨兵，开始进行故障转移操作，具体分2个步骤：\n1.在从节点中选择新的主节点\n过滤：首先 过滤掉不健康的从节点（下线或断线），没有回复过哨兵ping响应的从节点；\n优先级：根据指定的优先级选择，默认情况下所有从节点 priority值为100，如果倾向于选择同机房的另一台salve节点替代现有的master节点，则可以把同机房的 从节点priority值设置低一些；\n偏移量：如果优先级无法区分，选择复制偏移量最大的从节点；\n\n2.更新主从状态通过 slaveof no one命令，让新选出来的从节点成为主节点，并通过 slaveof命令让其他节点成为其从节点，将已经下线的主节点也设置为从节点；\n投票机制Sentinal 节点数量是基数个，通过投票机制来 选出 leader哨兵（领导哨兵），如果当前 选不出来则重新进行投票；每个Sentinal 节点会把 票投给第一个请求他的 Sentinal 节点；\n优点在主从复制模型基础上，实现自动故障恢复\n缺点写操作无法实现负载，存储能力受单机限制 （集群可解决）\n集群模型\n\n具体结构集群由多个哨兵模型组成，通过一致性Hash算法进行路由，多个master节点间均分数据分片。集群支持多个Redis 的主节点对数据分片，每个master node都可以挂载多个slave node。\n各个master 节点保存 其他master 数据槽范围，当出现 数据请求不在当前范围时会返回给客户端其应该访问的具体master的 ip 信息。 整个Redis 可以横向扩容，扩容更多的master 节点，每个master 节点能存放更多数据。\n集群特点1.Redis集群是一个由 多个节点组成的分布式服务集群，具有复制、高可用和分片特性；\n2.集群没有中心节点，并且带有 复制和故障转移功能，不会因某个节点下线而影响整个集群；\n3.集群中的 主节点负责处理 槽（储存数据），从节点是主节点的 复制品；\n4.主节点只会执行自己槽有关的命令，当节点接收到不属于自己处理槽的命令时，将会把指定槽节点的地址返回给客户端，而客户端再重新向正确的节点地址发送请求；\nRedis架构总结想扩展并发读：添加Slaver从节点\n想扩展并发写(扩容)：添加Master主节点\n","categories":["Redis缓存"],"tags":["Redis缓存"]},{"title":"多种锁","url":"/2025/08/03/A4-%E5%A4%9A%E7%BA%BF%E7%A8%8B/A2-%E5%A4%9A%E7%A7%8D%E9%94%81/","content":"并发基础知识点并行&amp;并发区别1.并行指两个或多个事件在同一时刻发生； 并发指两个或多个事件在 同一时间间隔内发生；\n2.并行 是在多台处理器上同时（同一时间点）处理多个任务；并发是在一台处理器上“同时”处理多个任务；\n3.并发编程的⽬标是充分的利⽤处理器的每⼀个核，以达到最⾼的处理性能；\n \n\n\n\nJVM内存中的对象1.Mark Word（标记字段）锁标志位信息…随着锁标志位的变化而变化。Klass Point（类型指针）：指向它的类元数据的指针，虚拟机通过这个指针来确定对象是哪个类的实例。\n2.实例数据存放类的数据信息，父类的信息。\n3.对齐填充虚拟机要求对象起始地址必须是 8字节的整数倍，为了字节对齐。\n问题：一个空对象占多少个字节？ 8个字节，因为对齐填充的关系，不到8个字节对其填充会自动补齐。对象头关联一个monitor对象，当进入一个方法时，会获取当前对象所有权，monitor进入数 +1，当前线程拥有 monitor所有权。\n\n\nCAS功能CAS（Compare And Swap 比较并替换）是乐观锁的一种实现方式，线程在读取数据时不进行加锁，先保存原值，在实际修改数据的瞬间，比较此时的值，是否和原值相等。若相等则回写；若不相等，则重新执行读取流程。\ncas存在的问题一、CAS可能有 ABA问题\n线程1 读取数据A\n线程2 读取数据A，把数据A改成数据B\n线程3 读取数据B，把数据 B 又改回数据A\n线程1 通过CAS比较，发现数据还是 A没变，就写成了自己要改的值\n\n解决：加标志位（类似版本号），设置自增字段，操作一次自增+1；或搞个时间戳，比较时间戳的值；\n每次修改： 数据+版本号；版本号递增，校验时同时校验： 数据 + 版本号；\n例如：操作数据库，根据CAS原则本来只要查询原本的值，现在需要一同查出他的标志位版本字段 vision；\n从Java 1.5开始，JDK的Atomic包里提供了一个类AtomicStampedReference来解决ABA问题。这个类的compareAndSet方法的作用是首先检查当前引用是否等于预期引用，并且检查当前标志是否等于预期标志，如果全部相等，以原子方式将该引用和标志的值设置为给定的更新值。\n二、长时间循环等待CAS 长时间不成功的话，会导致一直自旋（死循环），CPU开销较大；\n三、只保证一个共享变量的原子操作CAS操作单个共享变量赋值时 可以保证原子操作，但多个变量就不行；\nAtomic相关类AtomicInteger，AtomicBoolean 等 java.util.concurrent包下面的类，只能并发修改一个属性;\nAtomicInteger类利用 CAS + volatile  和 native 方法 来保证原子操作，避免 synchronized 的高开销，执行效率大为提升。内部使用 UnSafe 类 objectFieldOffset() 一个本地方法，可以得到 “原来的值”的内存地址，返回值 valueOffset；value是一个volatile变量，在内存中可见，JVM保证任何时刻，任何线程总能拿到该变量的最新值。\nAtomicReferenceAtomicReference可以保证 对象操作的原子性；不单单仅限于 Integer、Boolean、Long等类型。和 AtomicInteger 类似，AtomicInteger是对整数封装，而 AtomicReference 则是对普通对象的引用，它可以保证在修改对象引用时的线程安全性。 AtomicReference原子性的作用是对”对象”进行原子操作，提供一种 读写都是原子性的对象引用变量。\n原理： 通过 “volatile” 和 “Unsafe 提供的 CAS函数实现”原子操作；\n使用场景：当涉及到 比较，设置等，多于一个操作时，使用AtomicReference；\n升级： AtomicStampedReference类通过引入 时间戳作为数据的版本号，来解决ABA 问题；\n线程中的阻塞场景线程执行了Thread.sleep()方法，当前线程放弃CPU，睡眠一段时间，然后再恢复执行 ;\n线程执行一段同步代码，但尚且无法获得相关的同步锁，只能进入阻塞状态，等到获取了同步锁，才能恢复执行;\n线程执行了一个对象的wait()方法，直接进入阻塞状态，等待其他线程执行 notify()或notifyAll()方法;\n线程执行某些IO操作，因为等待相关的资源而进入了阻塞状态。例：监听system.in，但是尚且没有收到键盘的输入，则进入阻塞状态。 \n各种锁类型可重入锁\n重入锁内部基于CAS实现，可以避免一些死锁的情况；\n同一个线程可以反复获得同一把锁，但申请和释放锁的次数必须一致；\n重入锁可以使用 Condition类提供的await()，singal()功能，实现线程间通信；\n重入锁是非公平的，公平的重入锁性能差；\n\n锁的等级1.方法锁synchronized修饰方法\na. 通过在方法声明中加入 synchronized 关键字来声明 synchronized 方法。 \nb. synchronized 方法控制对 类成员变量的访问： \nc. 每个类实例对应一把锁，每个 synchronized 方法都必须获得 调用该方法类实例的锁 方能执行，否则所属线程阻塞，⽅法一旦执行，就独占该锁，直到 从该方法返回时才将锁释放，此后被 阻塞线程方能获得该锁，重新进⼊可执行状态。\n这种机制确保了同一时刻对于每一个类实例，其所有声明为 synchronized 成员函数中至多只有一个处于可执行状态，从⽽有效避免类成员变量的访问冲突。\n2. 对象锁synchronized修饰方法或代码块\na. 当一个对象中有synchronized method或synchronized block的时候，调用此对象的同步方法或进入其同步区域时，必须先获得对象锁。如果对象锁已被其他调用者占用，则需要等待此锁被释放。（⽅法锁也是对象锁）\nb. java的所有对象都含有 1个互斥锁，这个锁由 JVM自动获取和释放。线程进入 synchronized⽅法时，获取该对象的锁，当然如果已经有线程获取这个对象的锁，那么当前线程会等待；synchronized方法正常返回或者抛异常而终止，JVM会⾃动释放对象锁。这里体现了用 synchronized加锁的1个好处，⽅法抛异常时，锁可以由JVM来自动释放。\n3. 类锁synchronized 修饰静态的方法或代码块\na. 由于一个class不论被实例化多少次，其中的静态⽅法和静态变量在内存中都只有一份。所以，一旦一个静态的⽅法被申明为synchronized。此类所有的实例化对象在调用此方法，共用同一把锁，我们称之为 类锁。\n对象锁 是用来控制实例方法之间的同步，类锁 是用来 控制静态方法（或静态变量互斥体）之间的同步；\n总结在某个对象的所有synchronized方法中，在某个时刻只能有一个唯一的一个线程去访问这些synchronized方法；\n如果一个方法是synchronized方法，那么 synchronized关键字表示给当前对象上锁相当于 synchronized(this){} ，如果⼀个synchronized方法是 static，那么该synchronized表示给当前对象所对应的class对象上锁(每个类不管生成多少对象,其对应的class对象只有⼀个)；\n死锁问题死锁：两个或两个以上进程在执行过程中，因争夺资源而造成一种互相等待的现象，若无外力作用，将⽆法推进；\n产生死锁必要条件1.互斥条件：进程对所分配的资源不允许其他进程进行访问，若其他进程访问该资源，只能等待，直到释放该资源；\n2.请求和保持：进程获得资源后，对其他资源发请求，但该资源可能被其他进程占有，此时请求阻塞，但它对已获得资源保持不放；\n3.不可剥夺：进程 已获得的资源，在未完成使用之前，不可被剥夺，只能在使用完后自己释放；\n4.循环等待：进程发⽣ 死锁后，若干进程之间形成⼀种 头尾相接的 循环等待资源关系；\n悲观锁悲观锁：访问共享资源前，先要上锁，认为多线程同时修改共享资源的概率高，容易出现冲突；\n互斥锁：是一种悲观锁，一个线程获得锁，其他线程无法再次获得，挂起等待锁的释放；加锁失败时，会做「线程切换」，当加锁失败的线程再次加锁成功，这一过程会有两次线程上下文切换的成本，性能损耗大。\n读写锁原理：当「写锁」没有被线程持有时，多个线程能够并发的持有读锁，提高共享资源访问效率； 读锁：是用于读取共享资源，多个线程同时持有读锁不会破坏共享资源。一旦「写锁」被线程持有，读线程获取读锁的操作会被阻塞，其他写线程获取写锁的操作也会被阻塞。\n写锁是独占锁，因为任何时刻只能有一个线程持有写锁，类似互斥锁和自旋锁；\n读锁是共享锁，因为读锁可以被多个线程同时持有。\n应用场景：在读多写少\n乐观锁乐观锁：假定冲突的概率很低，先修改共享资源，再验证这段时间 内有没有发生冲突。没有其他线程修改，则操作成功；发现有其他线程修改，则放弃本次操作。\n使用场景：在冲突概率低，加锁成本高；冲突概率上升，不适合乐观锁，因为解决冲突的重试成本非常高。\n注意：加锁代码范围尽可能的小，加锁粒度要小，这样执行速度会比较快。\n自旋锁：是一种乐观锁，加锁失败时不会主动产生线程切换，忙等待直到获得锁；如果被锁代码执行时间短，则等待的时间也短。\n公平锁和非公平锁非公平锁&amp;公平锁区别：非公平锁性能高于公平锁性能；\n非公平锁可以减少 CPU唤醒线程的开销，整体吞吐效率会高点，CPU不必唤醒所有线程，减少唤起线程的数量；\n问题：非公平锁存在线程饥饿的情况，可能某个线程一直获取不到锁；\n","categories":["多线程"],"tags":["多线程"]},{"title":"基础知识点","url":"/2025/07/25/A4-%E5%A4%9A%E7%BA%BF%E7%A8%8B/A1-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/","content":"多线程-锁Synchronized锁JDK1.6之前，Synchronized 属于重量级锁，效率低。 \nJDK1.6之后，Synchronized 锁是升级的过程：无锁–&gt;偏向锁–&gt;轻量级锁–&gt;重量级锁。随着竞争的激烈而逐渐升级（注：锁是可以升级不可降级，提高获得锁和释放锁的效率）。\n从无锁状态，首先进入的线程获得偏向锁，当前释放后，此时如果同一个线程再次获得锁，锁不升级，偏向于同一线程；此时如果其他线程获得锁，并产生锁的竞争，则将锁升级为轻量级锁。升级到轻量级锁后，同样也使用CAS操作判断，如果同一线程，CAS成功修改 monitor中计算器+1。如果CAS操作失败，则自旋，一旦可以获取资源，就直接尝试成功，直到超出自旋阈值（10）。则自旋失败，升级为重量级锁，像1.6之前版本一样，等待唤醒。\n \n\n偏向锁采用CAS操作，每次同一线程进入，虚拟机就不进行任何同步操作，对标志位+1，不同线程过来，CAS操作失败。\nCAS操作：jvm会存储 锁对象Mark Word 拷贝，然后利用 CAS比较当前的Mark Word和保存的Mark Word，相同就说明加锁成功，改变锁标志位。\n轻量级锁（自旋锁）轻量级锁通过不断自旋，来防止线程被挂起；线程等待唤醒 是 用户态和内核态 的切换，此过程很耗资源，可通过自旋减少这种消耗(短时间)。\n自旋锁注意1.自旋时不释放CPU，持有自旋锁的线程应尽快释放锁，否则等待该自旋锁的线程会一直自旋，浪费CPU时间。\n2.持有自旋锁的线程在 sleep之前应该释放自旋锁，以便其它线程可以获得自旋锁；\n4.自旋锁比较适用于锁使用者保持锁时间比较短的情况，此时效率比较高；\n5.自旋锁是一种对多处理器相当有效的机制，⽽在单处理器非抢占式的系统中，基本上没有作⽤；\n存在的问题(不可逆)例：我现在是滴滴，早上有打车高峰，代码使用了大量的synchronized，锁升级过程是不可逆的，过了高峰我们还是重量级的锁，那效率降低。需要根据具体业务场景进行选择。\nsynchronized和ReentrantLock 区别1.可重入锁同一个线程可以多次获取同一把锁，ReentrantLock和synchronized都是可重入锁。\n2.synchronized是JVM层面，ReentrantLock是 API层面synchronized由jvm负责加锁，释放锁等操作，不需要我们维护；RentrantLock 是需要 lock() 和 unlock() 方法配合 try&#x2F;finally 语句块来完成；\n3.可中断锁线程尝试获取锁的过程中，是否可以响应中断，synchronized是不可中断的，ReentrantLock 是可中断的，通过 lock.lockInterruptibly() 实现，可以使正在等待的线程选择放弃等待；\n4.公平锁多个线程 同时尝试获取同一把锁时，获取锁的顺序按照线程达到的顺序。非公平锁：允许线程“插队”，synchronized只有非公平锁；ReentrantLock 可以通过参数设置公平，非公平锁。 \n5.选择性通知（锁绑定多个条件）synchronized关键字与 wait()和 notify()&#x2F;notifyAll()方法相结合可以实现 等待&#x2F;通知机制，但被通知的线程是由 JVM 选择无法控制，如果执行 notifyAll()方法会通知所有处于等待状态的线程； \n而 ReentrantLock类结合 Condition实例可以实现“选择性通知” ，Condition 可以为不同线程 注册不同Condition实例，执行 Condition实例的 signalAll()方法时 只会唤醒注册在该Condition实例中的所有等待线程。 \nVolatile关键字1.可见性Volatile修饰的共享变量，使用缓存一致性协议，当一个线程修改 volatile修饰的变量，立即修改写回主内存，同时发信号通知其他线程将该变量的缓存行置为无效状态，当其他线程需要读取这个变量时，发现自己缓存中该变量的缓存行是无效的，就会从内存重新读取，得到最新数据。\n扩展-如何发现数据失效？嗅探： 每个处理器通过 嗅探在总线上传播的数据来检查自己缓存值是不是过期，当处理器发现自己缓存行对应的内存地址被修改，会将当前自己的缓存行设置成无效状态，当处理器对这个数据进行修改操作时，会重新从系统内存中把数据读到处理器缓存里。\n总线风暴：由于Volatile的 MESI缓存一致性协议，需要不断的从主内存嗅探和 cas 不断循环，无效交互会导致总线带宽达到峰值。 所以不要大量使用Volatile。\n工作内存和主内存关系所有共享变量都存储于主内存，线程对变量的操作(读&#x2F;写)是在 工作内存中完成，而不是直接读写主内存中的变量。不同线程之间不能直接访问对方工作内存中的变量，线程间变量值的传递需要通过主内存中转来完成。 \n\n\n多个处理器运算任务都涉及同一块主内存区域时，将可能导致各自的缓存数据不一致，那同步回到主内存时以谁的缓存数据为准呢？为解决一致性问题，需要各个处理器访问缓存时都遵循一些协议，在读写时要根据协议来进行操作。\nMESI（缓存一致性协议）：当 CPU写数据时，如果发现操作的变量是共享变量，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中该变量的缓存行是无效的，就会从内存重新读取。\n加锁解决可见性某一个线程进入 synchronized代码块，线程获得锁后会清空工作内存，从主内存拷贝共享变量最新的值到工作内存成为副本，执行代码后，将修改后的 副本值刷新回主内存中，线程释放锁。而获取不到锁的线程会阻塞等待，所以变量的值肯定一直都是最新的。\n2.有序性禁止指令重排序\n扩展-重排序\n为提高处理速度，JVM会对代码进行编译优化，也就是指令重排序优化，并发编程下指令重排序会带来一些安全隐患：如 指令重排序导致的多个线程操作之间的不可见性；\n禁止指令重排序好处-例如：创建对象需要几个步骤：1.分配内存空间;   2.调用构造器初始化实例 ;  3.返回地址给引用；在执行时可能发生指令重排序，有可能 构造函数在对象初始化完成前就赋值完成，在内存里开辟一片存储区域后直接返回内存的引用，这个时候还没真正的初始化完对象，但别的线程去判断 instance!&#x3D;null，直接拿去用，此时这个对象是个半成品，那就有空指针异常了。\n内存屏障-保证不会被重排序Volatile借助Java编译器，在生成指令系列时的适当位置插入 内存屏障 指令，来禁止特定类型的处理器重排序。\nVolatile写：在前面和后面分别插入内存屏障； \nvolatile读：在后面插入两个内存屏障；\n3.原子性-不保证Volatile无法保证原子性，要实现原子性操作，可以考虑加锁、原子类，比如 AtomicInteger；\nvolatile与synchronized区别1.修饰内容：volatile只能修饰 变量（实例变量、类变量）；synchronized可以修饰 方法，以及代码块；\n2.三性保证：volatile保证数据的 可见、有序性；synchronized能保证 可见、有序、原子性；\n3.解决问题不同：volatile解决变量在多线程之间的可见性；synchronized解决多线程之间访问资源的同步性\n4.是否阻塞：多线程访问 volatile不会阻塞；synchronized 可能会发生阻塞；\n总结：volatile可以看做是轻量版的 synchronized，volatile不保证原子性；如果一个共享变量进行多个线程的赋值，没有其他操作，那可以用volatile来代替synchronized，因为赋值本身是原子性的，而volatile又保证可见性，所以可以保证线程安全。\n使用场景\nvolatile提供可见性，任何一个线程对其修改将立马对其他线程可见，volatile属性不会被线程缓存；\nvolatile可以对一些原子性操作实现加锁的效果；\n\n线程池创建线程三种方式1.继承 Thread 类，重写run() 方法，在run() 方法里实现内部逻辑；\n2.实现 Runnable 接口， 重写 Runnable 接口中的 run 方法，在 thread 类中传入 Runnable对象；\n3.实现 Callable 接口，重写 call() 方法，通过Future 来获取返回结果；在线程池提交Callable任务后返回一个Future对象，使用它可以知道 Callable任务的状态和得到Callable返回的执⾏结果。Future提供get()方法，等待Callable结束并获取它的执行结果。\n4.通过 线程池创建线程；\nCallable 和 Runnable区别1.Runnable 不会产生任何返回值，Callable 有返回值；\n2.Callable重写 call 方法，Runnable 重写 run 方法；\n3.使用 Callable 中 call方法可以抛出异常，而 Runnable 方法不能抛出异常；\n常见线程池种类1.SingleThreadPool 单个线程：若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出顺序执行队列中的任务。\n2.FixedThreadPool 固定线程数量：线程数量始终不变。当一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，新任务会被暂存在一个任务队列中，待有线程空闲时，便处理在任务队列中的任务。\n3.CachedThreadPool 动态分配线程数量：根据具体任务数量来调整线程数量，若有空闲线程可以复用，会优先使用可复用的线程。若所有线程均在工作，又有新任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用。\n线程池核心参数1.corePoolSize :  核心线程数，定义最小可以同时运行的线程数量。核心线程数默认情况下会一直存活，但当将allowCoreThreadTimeout 设置为true时，核心线程也会超时回收。\n2.maximumPoolSize：当队列中存放的任务数量达到队列最大容量时，可以同时运行的线程数量变为最大线程数；\n3.workQueue：当新任务到来时，判断当前运行的线程数是否达到核心线程数，如果达到则将新任务添加到队列； \n4.keepAliveTime：当线程池中的线程数量大于 corePoolSize 时，此时如果没有新任务提交，核心线程外的线程 不会立即销毁，而是等待直到时间超过 keepAliveTime才会被回收销毁；\n5.unit :  keepAliveTime 参数的时间单位。\n6.handler（饱和策略）：当线程数量达到maximumPoolSize，并且workQueue中任务满时，执行饱和操作。 \n执行过程1.当线程数 &lt; corePoolSize时，创建线程执⾏任务；\n2.当线程数 &gt;&#x3D; corePoolSize并且 workQueue没有满时，放入workQueue中；\n3.线程数  &gt;&#x3D;corePoolSize并且 workQueue满时，新任务新建线程运行，线程总数要 &lt; maximumPoolSize；\n4.当线程总数 &#x3D;&#x3D;maximumPoolSize并且 workQueue满了的时候， 执行 handler的rejectedExecution 拒绝策略；\n饱和策略1.不处理新任务，直接丢弃掉；\n2.丢弃最早未处理的任务请求；\n3.抛出 RejectedExecutionException 异常，拒绝新任务的处理；\n4.增加队列容量，如果应用程序可以承受此延迟并且不允许丢弃任何一个任务请求，可以选择。这种策略会降低新任务的提交速度，影响程序的整体性能。\n阻塞队列一个支持两个附加操作的队列，这两个附加的操作支持阻塞的插入和移除方法。\n1）支持阻塞的插入方法：当队列满时，队列会阻塞插入元素的线程，直到队列不满；\n2）支持阻塞的移除方法：当队列空时，获取元素的线程会等待队列变为非空，再获取数据；\n阻塞队列常用于生产者和消费者的场景，生产者是向队列里添加元素的线程，消费者是从队列里取元素的线程。阻塞队列就是生产者用来存放元素、消费者用来获取元素的容器。\n非阻塞队列入队和出队操作均利用CAS更新，允许多个线程并发执行，并且不会因为加锁而阻塞线程，使得并发性能更好。\n线程池-线程数量设置最佳线程数目  &#x3D; （（等待时间+CPU时间）&#x2F; CPU时间 ）* CPU核数\n例如：CPU 使用率 50% （ 线程CPU时间&#x2F;(线程等待时间+线程CPU时间）），那么这段时间可以运行 2 个IO任务\nCPU密集型任务：较小线程数\nIO密集型任务：    较多线程数\nIO操作不占用CPU，不让CPU闲；但如果线程数目太多，线程切换所带来的开销也会对系统的响应时间带来影响。\n线程等待时间所占比例越高，需要越多线程。线程CPU时间 所占比例越高，需要越少线程。\nexecute和submit区别1.execute无返回值**，无法判断任务 **是否被线程池执行成功；\n2.submit有返回值**， 线程池会返回一个 Future 类型的对象，通过这个 Future 对象可以 **判断任务是否执行成功，并且通过 Future 的 get() 方法来获取返回值，get() 方法会阻塞当前线程直到任务完成。\n3.当一个线程池里面的线程异常后：\n\n执行execute时，内部处理，无异常抛出，线程池会把这个线程移除掉，并创建一个新的线程放到线程池中；\n执行submit时，堆栈异常没有输出，但调用Future.get()方法时，可以捕获到异常，不会把这个线程移除掉，也不会创建新的线程放入到线程池中，复用原来线程；\n\nstart和 run区别方法内容不同：run称为线程体，它包含这个线程要执行的内容，run()方法运行结束，此线程终止，之后CPU再运行其它线程； Thread.start 方法启动一个线程，此线程是处于就绪状态并没有运行，生成thread放在cpu中调度，获取到时间片的线程执行run方法中具体的内容，start方法是真正实现多线程运行。\n唤醒阻塞线程方式1.wait与notify：wait与notify 配合synchronized使用，wait会立即释放锁，notify同步块执行完才释放\n2.await与singal：Condition类提供，由 new ReentLock().newCondition() 获得Condition对象，与 wait和 notify相同，因为在使用 Lock锁后无法使用wait方法；\n3.park与 unpark：LockSupport 是一个线程阻塞工具，可以在 线程任意位置让线程阻塞。和 Thread.suspenf()相比，它弥补了由于 resume() 在前发生，导致线程⽆法继续执行的情况。和Object.wait()相⽐，它不需要先获得某个对象的锁，也不会抛出 IException异常，可以唤醒指定线程。\nCyclicBarrier和CountDownLatch区别CountDownLatch:  减计数，当计算 &#x3D; 0时，释放所有等待线程； 计数为0后无法重置，不可重复利用； 调用countDown()方法则计数 -1，调用await()方法只进行阻塞；\nCyclicBarrier:  加计数，当计数&#x3D;指定值时，释放所有等待线程；计数&#x3D;指定值，计数置为0重新开始，可重复利用； 调用await()方法计数+1， +1后 &lt; 指定值时，线程阻塞； \n1.CountDownLatch 是一个线程等待其他线程， CyclicBarrier多个线程互相等待。\n2.CountDownLatch  计数 -1 直到 0，CyclicBarrier 计算 +1，直到指定值。\n3.CountDownLatch 是一次性的， CyclicBarrier  可以循环利用。\nCountDownLatch作用\n允许一个或多个线程一直等待，直到 count&#x3D;0，唤醒所有线程。一个线程调用await() 时，阻塞当前线程。有线程调用一次 countDown() 时，计数 -1。当 count &#x3D; 0 时，被阻塞线程全部唤醒。\nCyclicBarrier作用\n一组线程互相等待，直到所有线程都到达一个同步点。例：一组运动员比赛 100米，当所有人都准备完成之后，才可以一起开跑。\nCondition和wait&#x2F;notify区别1.Condition 可以精准的对多个不同条件进行控制，wait&#x2F;notify 只能和 synchronized关键字一起使用，只能唤醒一个或全部的等待队列；\n2.Condition 使用Lock进行控制，使用后要unlock()，Condition有类似于 await的机制，不会因为加锁而产生死锁问题，底层实现park&#x2F; unpark 机制，不会产生死锁，但wait&#x2F;notify可能会产生先唤醒再挂起的死锁。\nConditionCondition用来替代Object的 wait()，notify() 方法，使用Condition中await()，signal()可以更加安全，高效的实现线程间协作。 \nwait()和sleep()区别wait()方法：Object类的方法，当一个线程执行到wait方法时，它就进入到一个和该对象相关的等待池，同时释放对象的锁，使得其他线程能够访问，可以通过notify，notifyAll⽅法来唤醒等待的线程；\nsleep()方法： 线程类（Thread）的静态方法，让调用线程进入睡眠状态，让出执行机会给其他线程，等到休眠时间结束后，线程进入就绪状态和 其他线程一起竞争cpu的执⾏时间。\n总结：因为 sleep() 是 static静态方法，不能改变对象的锁，当一个 synchronized 块中调⽤ sleep()方法，线程虽然进入休眠，但是对象的锁没有被释放，其他线程依然无法访问这个对象。\n线程五个状态创建、就绪、运⾏、阻塞、死亡\n1.创建状态：生成线程对象，并没有调用该对象的 start方法，这是线程处于创建状态；\n2.就绪状态：调用线程对象的 start方法后，进入就绪状态，没有获得时间片则不会执行，从等待或睡眠中醒来，也会处于就绪状态；\n3.运行状态：线程调度程序将 就绪线程设置为当前线程，此时进入运行状态，开始运行 run()函数当中的代码。\n4.阻塞状态：线程正在运行时被暂停，为等待某个事件的发生(资源就绪)之后再继续运行，sleep、suspend、wait等方法可以导致线程阻塞。\n5.死亡状态：一个线程run()方法执行结束或调用stop()方法后，该线程就会死亡，对于死亡的线程，无法再使用start⽅法使其进入就绪。\n\n\n","categories":["多线程"],"tags":["多线程"]},{"title":"学习方法论","url":"/2025/05/02/%E6%96%B9%E6%B3%95%E8%AE%BA/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E8%AE%BA/","content":"深度 – 链式学习法从一个技术点出发，不断的输入挖掘，不断的下探一步，问问自己为什么？\n宽度 – 比较学习法类似技术选项的调研，当前市面上还有哪些其他类型的技术，横向对比。\n\n\n5W1H方法what：问题的类型及标准&amp;依据\nwho：问题的主题是谁\nwhich：问题的具体表现&amp;特定的状况（定向描述）\nwhere：问题的空间范围&amp;特定领域\nwhen：问题的时间范围\nhow：问题到了何种程度（怎样、多少…定量描述）\n个人写作模板1.问题是什么？（背景）\n2.当前现状？\n3.预期效果？\n4.面临的挑战？\n5.拆分问题？（分治–实现细节）\n6.横向方案对比？\n7.复盘总结（优点、缺点、后续改进）\n时间管理精力专注1.抵制手机诱惑，固定时间看手机\n2.番茄工作法\n3.工作时间高度专注\n固定深造1.工作日：早起1h、晚睡1h\n2.周末时间选择\n3.通勤时间利用\n沉淀总结1.浅尝即止是大忌：为啥这么写，这么写有啥好处，有啥坏处，多问自己几个为什么?\n2.保持好奇心：勤于在项目中发现问题，挖掘问题，多思考（深度、宽度）。\n","categories":["学习","学习方法论"],"tags":["方法论"]},{"title":"职场工作","url":"/2025/05/02/%E6%96%B9%E6%B3%95%E8%AE%BA/%E8%81%8C%E5%9C%BA%E6%B1%87%E6%8A%A5%E6%96%B9%E6%B3%95%E8%AE%BA/","content":"接受工作–只问标准*具体化\n*可衡量\n*可实现\n*相关性\n*有时限\n\n\n请示工作–必带方案*风险\n*利益\n*差异\n*影响\n汇报工作–突出结果*结论先行\n*再讲理由\n*拿出事例\n*重述结论\n分享工作–细说流程*What：产品背景\n*Who：目标人群\n*Why：预期目标\n*Where：使用场景\n*When：需求节点\n*How：如何验证\n*How much：多少资源\n复盘工作–总结SOP*回顾目标\n*评估结果，数据验证\n*分析成功、失败原因，表层&#x2F;深层原因\n*总结方法论\n","categories":["学习","职场汇报方法论"],"tags":["方法论"]},{"title":"Kafka消息队列","url":"/2025/06/02/A2-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/","content":"Kafka消息队列结构队列topic多个生产者往同一个队列 topic丢数据，多个消费者往同一个队列(topic)拿数据。\n队列分区Partition为提高一个队列topic吞吐量，Kafka把topic进行分区 Partition，生产者往一个发布订阅的topic分区 Partition中发数据，消费者从分区Partition中取数据。每个Topic 可以有多个分区，分区是最小的读取和存储结构。每个partition对应一个消费者，多个消费者同时进行消费，以此来提高并发量。消息是发往一个主题下的某个分区中。\n\n\n每个消费组会有自己的 offset（消费点位）来标识消费到的位置， 在消费点位之前表明已经消费过。 offset是分区级别，每个消费组都会维护订阅的 Topic下的每个分区的offset。offset 表示消费者的消费进度，每次消费者消费时都会提交这个offset。一个消费者组中的某个消费者挂了，但其所在分区可能有存活的消费者，存活的消费者继续去消费，但需要知道挂掉的消费者具体消费到了哪里，就需要知道offset。\n\n\n每个 Partition都是一个文件，收到消息后 Kafka会把数据插入到文件末尾。\n缺点：没办法删除数据，所以 Kafka 是不会删除数据的，它会把所有的数据都保留下来，每个消费者对每个 Topic都有一个 offset 用来表示读取到第几条数据， offset 是由对应的消费者维护，保存到 Zookeeper 里面。 \n\n\n数据发往哪个partition？\n发送时可以指定 partition，如果有指定，则写入对应的 partition；\n没有指定partition，但设置了数据key，则会根据key的值 hash出一个partition；\n没有指定 partition，也没有指定 key ， 会随机选择一个分区，并尽可能一直使用该分区，待该分区已满或过了间隔时间，再随机一个分区进行使用；\n\n服务器BrokerKafka服务器叫 Broker，集群是由多个broker组成。分区Partition是分布在不同broker中，实现多机均匀负载。如果其中一台 broker挂了，会丢失其中 partition上的数据，但 kafka把这些 partition都做了备份。如现有三个partition，分别存在三台broker上，每个partition都会备份，这些备份散落在不同的broker上，如下图红色的 partition代表是主分区，紫色partition代表的是备份分区。\n生产者，消费者都是与主分区交互，备份分区仅用作于备份不做读写，如果某个Broker挂了，就会选举出其他 Broker的 partition来作为主分区，实现高可用。\n\n\n消费者都是属于某个消费组的，一条消息会发往多个订阅这个主题的消费组；例如：两个消费组分别是Group 1 和 Group 2，它们都订阅 Topic-a，此时有一条消息发往 Topic-a，那么这两个消费组都能接收到这条消息。这条消息实际 写入Topic中的某个分区，消费组中的某个消费者对应消费一个 Topic 的某个分区。\n\n\nBroker副本（Replica）为更好的做 负载均衡，Kafka 尽量将所有的 Partition均匀分配到整个集群上。 \n为提高Kafka的容错能力，需要将同一个 Partition的 Replica尽量分散到不同的机器。 实际上，如果所有的 Replica都在同一个Broker上，那一旦该 Broker宕机，该 Partition所有 Replica都无法工作，也就达不到 备份的效果。 同时如果某个Broker宕机了，需要保证它上面的负载可以被均匀的分配到其它幸存的所有Broker上。 \n删除数据策略目的：为避免磁盘被撑满，Kakfa 提供两种策略来删除数据\n\n基于时间 （默认七天）\n基于 Partition 文件大小\n\n消息轮询消费者组 是采用Pull 拉方式来消费消息，消费者通过轮询 API(poll) 向服务器定时请求数据。\n重新分区分配Partition 可以水平无限扩展，随着 Partition扩容， Consumer消费 Partition也会重新分配，这里涉及到消息消费分配策略，在 Kafka内部存在两种默认的分区分配策略：Range 和RoundRobin，当以下事件发生时，Kafka将会进行一次分区分配。\n\n同一个Consumer Group内新增消费者；\n订阅的主题新增Partition；\n消费者离开当前所属Group，包括Shuts Down或Crashes；\n\n消息持久化Kafka将partition数据写在磁盘，是追加写入，避免随机 I&#x2F;O操作，寻址磁盘效率低。\n持久化时，partition会先缓存一部分, 放在page cache中，等到足够多数据量&#x2F;等待一定的时间后，再批量写入(flush)。 消费者实际上也是从partition中取数据。\n生产者，消费者都可以有多个，多个消费者可以组成一个消费者组，如果一个消费者消费三个分区，消费者组就可以每个消费者去消费一个分区，消费者组中各个消费者并发消费，以此来提高吞吐量。\n如果消费者组中的某个消费者挂了，那么其中有一个消费者就要消费两个 partition；如果只有三个partition，而消费者组有4个消费者，那一个消费者会空闲。消费者组之间从逻辑上是独立的，如果多加入一个消费者组，无论是新增的消费者组，还是原本的消费者组，都能消费topic的全部数据。\n\n\n消息顺序性Kafka是分布式结构，往一个 topic中存数据，实际上是 往多个 broker的 partition中存储数据，将 partition以消息日志的方式存储起来，通过顺序访问IO和缓存，才真正把数据写到磁盘上。\n要保证全局有序只能写入一个partition；要保证消费有序则消费者也只能有一个。\n分布式无法避免 网络抖动&#x2F;机器宕机 等问题的发生，很有可能消费者A读取数据，没来得及消费就挂了，Zookeeper 发现消费者A挂了，让消费者B 去消费原本A的分区，等消费者A重连的时候，发现已经重复消费同一条数据了(或消费者超时等)。如果 业务上不允许重复消费，最好是让消费者在业务上做重复性校验。\n消息不丢失1.生产者ackKafka 支持在生产者一侧进行 本地 buffer，累积到一定数量才发送，如果这里设置不当会丢消息。当设置为async，会大幅提升性能，因为生产者会在本地缓冲消息，并适时批量发送。\n如果对可靠性要求高，设置sync同步发送，Kafka 采用至少一次保证消息不会丢，但可能会重复传输。acks默认值即为1，代表消息被partitioin接收之后才算成功发送，也可以配置 acks &#x3D; all 代表所有副本都接收到该消息之后，才算真正成功发送。\n2.队列设置（副本&#x2F;持久化）集群：一般会设置 replication.factor &gt;&#x3D; 3，这样就可以保证每个分区(partition) 至少有 3个副本，以确保消息队列的安全性。\n单机：通过持久化到磁盘来保证消息不丢失。\n3.消费者ack消费端是否异步ack设置：消息处理完成前提交offset，可能造成数据丢失；Consumer默认自动提交 offset(位移)，在后台提交位移前一定要保证消息被正常处理。 \n如果处理耗时很长，建议把逻辑放到另一个线程中去做，异步提交ack会提高消费者的响应速度，但容易造成消息丢失。为避免消息丢失，设置 enable.auto.commit&#x3D;false，关闭自动提交位移，在消息被完整处理后再手动提交位移。\n","categories":["消息队列MQ"],"tags":["消息队列MQ"]},{"title":"消息队列简介","url":"/2025/05/25/A2-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%AE%80%E4%BB%8B/","content":"消息队列作用：异步，解耦，削峰\n缺点：可用性降低，增加系统复杂性（重复消费，消息丢失，顺序消费），数据一致性问题\n\n系统可用性降低：加MQ 进来，万一 MQ 挂了，整套系统崩溃；\n系统复杂度提高：怎么限制消息重复消费？怎么处理消息丢失？怎么保证消息顺序？\n数据一致性：A系统处理完后直接返回成功，别人以为这个请求成功了；但问题是，如果有ABC 三个系统，AB两个系统写库成功，结果 C系统写库失败，会导致数据不一致。\n\n\n\n1.异步：提高处理速度\n\n2.解耦：降低模块间耦合、依赖\n\n3.削峰：削峰填谷，平衡流量\n\n如何保证消息不丢失？\n\n  \n\n1.生产消息阶段生产者发送消息到Broker，需要处理 Broker的响应 ack，如果 Broker返回写入失败，需要重试发送，当多次发送失败，需要作报警，日志记录等。\n2.存储消息阶段单机时：存储消息阶段需要在消息刷盘之后，再给生产者响应。假设消息写入缓存中就返回响应，那么机器突然断电会造成消息丢失，而生产者以为已经发送成功。\n集群部署时：有多副本机制，消息不仅要写入当前Broker，还需要写入副本中，需要配置成至少写入1台副本机子后，再给生产者响应。\n3.消费消息阶段消费者执行完业务逻辑后，再发送给 Broker消费成功的ack响应。\n个人总结\n生产者需要处理好 Broker响应，出错情况下利用 重试、报警等手段。\nBroker 需要控制响应的时机，单机：消息刷盘后返回响应； 集群多副本：发送至1个副本及以上后再返回响应。\n消费者需要在执行完真正的业务逻辑后，再返回ack响应给Broker。\n\n注意：消息可靠性增强，性能就下降，等待消息刷盘，多副本同步后返回都会影响性能，需要根据具体场景区别对待，例如：日志的传输可能丢那么一两条关系不大，因此没必要等消息刷盘再响应。\n如何处理重复消息？1.业务幂等消息重复关键点就是 幂等，在业务上处理重复消息所带来的影响。记录关键key，比如记录订单ID，假如有重复消息过来，先判断这个ID是否已经被处理过。\n2.接口幂等分场景去考虑，强校验、弱校验；如跟金钱相关场景就做强校验。\n强校验：多个操作放在一个事务里，成功一起成功，失败一起失败。每次消息过来都根据 订单号+业务场景 唯一标识去流水表查，确认有没有这条流水，有就直接return，没有则执行后面逻辑。\n弱校验：一些不重要的场景，把 id+场景唯一标识作为Redis的key，放到缓存里面（失效时间看场景），一定时间内这个消息就去 Redis判断。\n3.数据库约束唯一索引、主键，重复数据插入会失败。\n如何保证顺序消费？顺序性保证分为：全局有序，部分有序，消费方都不能开启并行消费。\n1.全局有序一个生产者，一个队列分区，一个消费者；\n全局有序只能有一个生产者往Topic发送消息，并且一个Topic内部只能有一个队列（分区），消费者必须是单线程消费这个队列，生产者通过指定 partKey的方式将消息发送到某一个集群的某一个 partition，以实现消息的全局有序，一般情况下不需要全局有序，因为会严重影响MQ的吞吐量。\n\n\n2.部分有序核心：把消息通过特定的策略发往固定的队列中，将 Topic内部划分成需要的队列数，然后每个队列对应一个单线程处理的消费者，这样即完成部分有序的需求，又可以通过 队列数量的并发，提高消息处理效率。\n使用Hash取模法，让同一个订单发送到同一个队列中，同一个订单多步操作同步进行；顺序消费由消费者业务保证!\n\n\n\n\n如何处理消息堆积？1.消费能力弱，时间长造成消息积压解决方案批量消费：本身消费能力较弱，优化消费逻辑尝试批量消费，多线程消费；\n水平扩容：增加Topic的队列数和消费者数量，队列数一定增加，不然新增加消费者是没东西消费的，一个Topic中一个队列只会分配给一个消费者；\n2.消费失败反复重试制定合理的重试策略：1,2,4,8, 2^n，最大重试次数；\n如果失败，落DB重试表，后续再进行报警、日志等处理；\n消息队列对比RabbitMQ、RocketMQ、Kafka 区别\n\n\n\n特性\nRabbitMQ\nRocketMQ\nKafka\n\n\n\n单机吞吐量\n万级\n10 万级，支撑高吞吐\n10 万级，高吞吐，一般配合大数据类的系统进行实时数据计算、日志采集等场景\n\n\ntopic 数量对吞吐量的影响\n\ntopic达几百&#x2F;几千级别，吞吐量会有较小幅度的下降，这是 RocketMQ一大优势，在同等机器下，可以支撑大量的 topic。\ntopic 从几十到几百时，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic数量不要过多。要支撑大规模 topic，需要增加更多机器资源。\n\n\n时效性\n微秒级，这是 RabbitMQ 的一大特点，延迟最低\nms 级\n延迟在 ms 级以内\n\n\n可用性\n高，基于主从架构实现高可用\n非常高，分布式架构\n非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用\n\n\n消息可靠性\n基本不丢\n经过参数优化配置，可以做到 0 丢失\n同 RocketMQ\n\n\n功能支持\n基于 erlang 开发，并发能力很强，性能极好，延时很低\nMQ 功能较为完善，还是分布式的，扩展性好\n功能较为简单，主要支持简单的 MQ功能，在大数据领域的实时计算，以及日志采集被大规模使用\n\n\n","categories":["消息队列MQ"],"tags":["消息队列MQ"]}]